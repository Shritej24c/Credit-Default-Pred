{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shritej24c/Credit-Risk/blob/main/XGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Pmg8Su6kEm",
        "outputId": "005eb58e-9604-460c-a125-96586b2fd69d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /Applications/anaconda3/lib/python3.8/site-packages (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.20.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: keras~=2.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: clang~=5.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Applications/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Applications/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: keras in /Applications/anaconda3/lib/python3.8/site-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCTw2seH6kEr",
        "outputId": "9d44f068-ef19-437f-c885-2ef591b08424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.7 in /Applications/anaconda3/lib/python3.8/site-packages (1.7.0)\r\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /Applications/anaconda3/lib/python3.8/site-packages (from scipy==1.7) (1.19.5)\r\n"
          ]
        }
      ],
      "source": [
        "|!pip install scipy==1.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "pctQ94WI6kEs"
      },
      "outputs": [],
      "source": [
        "!pip install dask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDq-RUmO6kEs"
      },
      "source": [
        "### Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "BmQyGITN6kEu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "import time as t\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# fine tuning with Grid Search\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "Q4i2eAU96kEu"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCr_eOQm6kEv"
      },
      "source": [
        "### Reading CSVs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "XhcnCiIN6kEv",
        "outputId": "2559ee4c-319b-459f-cd44-5eaa91ef9566"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>S_2</th>\n",
              "      <th>P_2</th>\n",
              "      <th>D_39</th>\n",
              "      <th>B_1</th>\n",
              "      <th>B_2</th>\n",
              "      <th>R_1</th>\n",
              "      <th>S_3</th>\n",
              "      <th>D_41</th>\n",
              "      <th>B_3</th>\n",
              "      <th>D_42</th>\n",
              "      <th>D_43</th>\n",
              "      <th>D_44</th>\n",
              "      <th>B_4</th>\n",
              "      <th>D_45</th>\n",
              "      <th>B_5</th>\n",
              "      <th>R_2</th>\n",
              "      <th>D_46</th>\n",
              "      <th>D_47</th>\n",
              "      <th>D_48</th>\n",
              "      <th>D_49</th>\n",
              "      <th>B_6</th>\n",
              "      <th>B_7</th>\n",
              "      <th>B_8</th>\n",
              "      <th>D_50</th>\n",
              "      <th>D_51</th>\n",
              "      <th>B_9</th>\n",
              "      <th>R_3</th>\n",
              "      <th>D_52</th>\n",
              "      <th>P_3</th>\n",
              "      <th>B_10</th>\n",
              "      <th>D_53</th>\n",
              "      <th>S_5</th>\n",
              "      <th>B_11</th>\n",
              "      <th>S_6</th>\n",
              "      <th>D_54</th>\n",
              "      <th>R_4</th>\n",
              "      <th>S_7</th>\n",
              "      <th>B_12</th>\n",
              "      <th>S_8</th>\n",
              "      <th>D_55</th>\n",
              "      <th>D_56</th>\n",
              "      <th>B_13</th>\n",
              "      <th>R_5</th>\n",
              "      <th>D_58</th>\n",
              "      <th>S_9</th>\n",
              "      <th>B_14</th>\n",
              "      <th>D_59</th>\n",
              "      <th>D_60</th>\n",
              "      <th>D_61</th>\n",
              "      <th>B_15</th>\n",
              "      <th>S_11</th>\n",
              "      <th>D_62</th>\n",
              "      <th>D_63</th>\n",
              "      <th>D_64</th>\n",
              "      <th>D_65</th>\n",
              "      <th>B_16</th>\n",
              "      <th>B_17</th>\n",
              "      <th>B_18</th>\n",
              "      <th>B_19</th>\n",
              "      <th>D_66</th>\n",
              "      <th>B_20</th>\n",
              "      <th>D_68</th>\n",
              "      <th>S_12</th>\n",
              "      <th>R_6</th>\n",
              "      <th>S_13</th>\n",
              "      <th>B_21</th>\n",
              "      <th>D_69</th>\n",
              "      <th>B_22</th>\n",
              "      <th>D_70</th>\n",
              "      <th>D_71</th>\n",
              "      <th>D_72</th>\n",
              "      <th>S_15</th>\n",
              "      <th>B_23</th>\n",
              "      <th>D_73</th>\n",
              "      <th>P_4</th>\n",
              "      <th>D_74</th>\n",
              "      <th>D_75</th>\n",
              "      <th>D_76</th>\n",
              "      <th>B_24</th>\n",
              "      <th>R_7</th>\n",
              "      <th>D_77</th>\n",
              "      <th>B_25</th>\n",
              "      <th>B_26</th>\n",
              "      <th>D_78</th>\n",
              "      <th>D_79</th>\n",
              "      <th>R_8</th>\n",
              "      <th>R_9</th>\n",
              "      <th>S_16</th>\n",
              "      <th>D_80</th>\n",
              "      <th>R_10</th>\n",
              "      <th>R_11</th>\n",
              "      <th>B_27</th>\n",
              "      <th>D_81</th>\n",
              "      <th>D_82</th>\n",
              "      <th>S_17</th>\n",
              "      <th>R_12</th>\n",
              "      <th>B_28</th>\n",
              "      <th>R_13</th>\n",
              "      <th>D_83</th>\n",
              "      <th>R_14</th>\n",
              "      <th>R_15</th>\n",
              "      <th>D_84</th>\n",
              "      <th>R_16</th>\n",
              "      <th>B_29</th>\n",
              "      <th>B_30</th>\n",
              "      <th>S_18</th>\n",
              "      <th>D_86</th>\n",
              "      <th>D_87</th>\n",
              "      <th>R_17</th>\n",
              "      <th>R_18</th>\n",
              "      <th>D_88</th>\n",
              "      <th>B_31</th>\n",
              "      <th>S_19</th>\n",
              "      <th>R_19</th>\n",
              "      <th>B_32</th>\n",
              "      <th>S_20</th>\n",
              "      <th>R_20</th>\n",
              "      <th>R_21</th>\n",
              "      <th>B_33</th>\n",
              "      <th>D_89</th>\n",
              "      <th>R_22</th>\n",
              "      <th>R_23</th>\n",
              "      <th>D_91</th>\n",
              "      <th>D_92</th>\n",
              "      <th>D_93</th>\n",
              "      <th>D_94</th>\n",
              "      <th>R_24</th>\n",
              "      <th>R_25</th>\n",
              "      <th>D_96</th>\n",
              "      <th>S_22</th>\n",
              "      <th>S_23</th>\n",
              "      <th>S_24</th>\n",
              "      <th>S_25</th>\n",
              "      <th>S_26</th>\n",
              "      <th>D_102</th>\n",
              "      <th>D_103</th>\n",
              "      <th>D_104</th>\n",
              "      <th>D_105</th>\n",
              "      <th>D_106</th>\n",
              "      <th>D_107</th>\n",
              "      <th>B_36</th>\n",
              "      <th>B_37</th>\n",
              "      <th>R_26</th>\n",
              "      <th>R_27</th>\n",
              "      <th>B_38</th>\n",
              "      <th>D_108</th>\n",
              "      <th>D_109</th>\n",
              "      <th>D_110</th>\n",
              "      <th>D_111</th>\n",
              "      <th>B_39</th>\n",
              "      <th>D_112</th>\n",
              "      <th>B_40</th>\n",
              "      <th>S_27</th>\n",
              "      <th>D_113</th>\n",
              "      <th>D_114</th>\n",
              "      <th>D_115</th>\n",
              "      <th>D_116</th>\n",
              "      <th>D_117</th>\n",
              "      <th>D_118</th>\n",
              "      <th>D_119</th>\n",
              "      <th>D_120</th>\n",
              "      <th>D_121</th>\n",
              "      <th>D_122</th>\n",
              "      <th>D_123</th>\n",
              "      <th>D_124</th>\n",
              "      <th>D_125</th>\n",
              "      <th>D_126</th>\n",
              "      <th>D_127</th>\n",
              "      <th>D_128</th>\n",
              "      <th>D_129</th>\n",
              "      <th>B_41</th>\n",
              "      <th>B_42</th>\n",
              "      <th>D_130</th>\n",
              "      <th>D_131</th>\n",
              "      <th>D_132</th>\n",
              "      <th>D_133</th>\n",
              "      <th>R_28</th>\n",
              "      <th>D_134</th>\n",
              "      <th>D_135</th>\n",
              "      <th>D_136</th>\n",
              "      <th>D_137</th>\n",
              "      <th>D_138</th>\n",
              "      <th>D_139</th>\n",
              "      <th>D_140</th>\n",
              "      <th>D_141</th>\n",
              "      <th>D_142</th>\n",
              "      <th>D_143</th>\n",
              "      <th>D_144</th>\n",
              "      <th>D_145</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-03-09</td>\n",
              "      <td>0.938469</td>\n",
              "      <td>0.001733</td>\n",
              "      <td>0.008724</td>\n",
              "      <td>1.006838</td>\n",
              "      <td>0.009228</td>\n",
              "      <td>0.124035</td>\n",
              "      <td>0.008771</td>\n",
              "      <td>0.004709</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.080986</td>\n",
              "      <td>0.708906</td>\n",
              "      <td>0.170600</td>\n",
              "      <td>0.006204</td>\n",
              "      <td>0.358587</td>\n",
              "      <td>0.525351</td>\n",
              "      <td>0.255736</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.063902</td>\n",
              "      <td>0.059416</td>\n",
              "      <td>0.006466</td>\n",
              "      <td>0.148698</td>\n",
              "      <td>1.335856</td>\n",
              "      <td>0.008207</td>\n",
              "      <td>0.001423</td>\n",
              "      <td>0.207334</td>\n",
              "      <td>0.736463</td>\n",
              "      <td>0.096219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.023381</td>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.008322</td>\n",
              "      <td>1.001519</td>\n",
              "      <td>0.008298</td>\n",
              "      <td>0.161345</td>\n",
              "      <td>0.148266</td>\n",
              "      <td>0.922998</td>\n",
              "      <td>0.354596</td>\n",
              "      <td>0.152025</td>\n",
              "      <td>0.118075</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>0.158612</td>\n",
              "      <td>0.065728</td>\n",
              "      <td>0.018385</td>\n",
              "      <td>0.063646</td>\n",
              "      <td>0.199617</td>\n",
              "      <td>0.308233</td>\n",
              "      <td>0.016361</td>\n",
              "      <td>0.401619</td>\n",
              "      <td>0.091071</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.007126</td>\n",
              "      <td>0.007665</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.652984</td>\n",
              "      <td>0.008520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004730</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.272008</td>\n",
              "      <td>0.008363</td>\n",
              "      <td>0.515222</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>0.009013</td>\n",
              "      <td>0.004808</td>\n",
              "      <td>0.008342</td>\n",
              "      <td>0.119403</td>\n",
              "      <td>0.004802</td>\n",
              "      <td>0.108271</td>\n",
              "      <td>0.050882</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007554</td>\n",
              "      <td>0.080422</td>\n",
              "      <td>0.069067</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004327</td>\n",
              "      <td>0.007562</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007729</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.001576</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>0.001434</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002271</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>0.007121</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.002310</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>0.506612</td>\n",
              "      <td>0.008033</td>\n",
              "      <td>1.009825</td>\n",
              "      <td>0.084683</td>\n",
              "      <td>0.003820</td>\n",
              "      <td>0.007043</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005720</td>\n",
              "      <td>0.007084</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.008907</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002537</td>\n",
              "      <td>0.005177</td>\n",
              "      <td>0.006626</td>\n",
              "      <td>0.009705</td>\n",
              "      <td>0.007782</td>\n",
              "      <td>0.002450</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>0.002665</td>\n",
              "      <td>0.007479</td>\n",
              "      <td>0.006893</td>\n",
              "      <td>1.503673</td>\n",
              "      <td>1.006133</td>\n",
              "      <td>0.003569</td>\n",
              "      <td>0.008871</td>\n",
              "      <td>0.003950</td>\n",
              "      <td>0.003647</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.894090</td>\n",
              "      <td>0.135561</td>\n",
              "      <td>0.911191</td>\n",
              "      <td>0.974539</td>\n",
              "      <td>0.001243</td>\n",
              "      <td>0.766688</td>\n",
              "      <td>1.008691</td>\n",
              "      <td>1.004587</td>\n",
              "      <td>0.893734</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.670041</td>\n",
              "      <td>0.009968</td>\n",
              "      <td>0.004572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.008949</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004326</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.007336</td>\n",
              "      <td>0.210060</td>\n",
              "      <td>0.676922</td>\n",
              "      <td>0.007871</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.238250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.232120</td>\n",
              "      <td>0.236266</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702280</td>\n",
              "      <td>0.434345</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.686516</td>\n",
              "      <td>0.008740</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.003319</td>\n",
              "      <td>1.007819</td>\n",
              "      <td>1.000080</td>\n",
              "      <td>0.006805</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002052</td>\n",
              "      <td>0.005972</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004345</td>\n",
              "      <td>0.001535</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002427</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.000610</td>\n",
              "      <td>0.002674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-04-07</td>\n",
              "      <td>0.936665</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.004923</td>\n",
              "      <td>1.000653</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>0.126750</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.069419</td>\n",
              "      <td>0.712795</td>\n",
              "      <td>0.113239</td>\n",
              "      <td>0.006206</td>\n",
              "      <td>0.353630</td>\n",
              "      <td>0.521311</td>\n",
              "      <td>0.223329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.065261</td>\n",
              "      <td>0.057744</td>\n",
              "      <td>0.001614</td>\n",
              "      <td>0.149723</td>\n",
              "      <td>1.339794</td>\n",
              "      <td>0.008373</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>0.202778</td>\n",
              "      <td>0.720886</td>\n",
              "      <td>0.099804</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030599</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.002482</td>\n",
              "      <td>1.009033</td>\n",
              "      <td>0.005136</td>\n",
              "      <td>0.140951</td>\n",
              "      <td>0.143530</td>\n",
              "      <td>0.919414</td>\n",
              "      <td>0.326757</td>\n",
              "      <td>0.156201</td>\n",
              "      <td>0.118737</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.148459</td>\n",
              "      <td>0.093935</td>\n",
              "      <td>0.013035</td>\n",
              "      <td>0.065501</td>\n",
              "      <td>0.151387</td>\n",
              "      <td>0.265026</td>\n",
              "      <td>0.017688</td>\n",
              "      <td>0.406326</td>\n",
              "      <td>0.086805</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.002413</td>\n",
              "      <td>0.007148</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.647093</td>\n",
              "      <td>0.002238</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003879</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.188970</td>\n",
              "      <td>0.004030</td>\n",
              "      <td>0.509048</td>\n",
              "      <td>0.004193</td>\n",
              "      <td>0.007842</td>\n",
              "      <td>0.001283</td>\n",
              "      <td>0.006524</td>\n",
              "      <td>0.140611</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.101018</td>\n",
              "      <td>0.040469</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004832</td>\n",
              "      <td>0.081413</td>\n",
              "      <td>0.074166</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004203</td>\n",
              "      <td>0.005304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001864</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>0.009896</td>\n",
              "      <td>0.007597</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009810</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.005966</td>\n",
              "      <td>0.000395</td>\n",
              "      <td>0.001327</td>\n",
              "      <td>0.007773</td>\n",
              "      <td>0.500855</td>\n",
              "      <td>0.000760</td>\n",
              "      <td>1.009461</td>\n",
              "      <td>0.081843</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.007789</td>\n",
              "      <td>0.004311</td>\n",
              "      <td>0.002332</td>\n",
              "      <td>0.009469</td>\n",
              "      <td>0.003753</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007584</td>\n",
              "      <td>0.006677</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001142</td>\n",
              "      <td>0.005907</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008427</td>\n",
              "      <td>0.008979</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.009924</td>\n",
              "      <td>0.005987</td>\n",
              "      <td>0.002247</td>\n",
              "      <td>1.006779</td>\n",
              "      <td>0.002508</td>\n",
              "      <td>0.006827</td>\n",
              "      <td>0.002837</td>\n",
              "      <td>1.503577</td>\n",
              "      <td>1.005791</td>\n",
              "      <td>0.000571</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.008351</td>\n",
              "      <td>0.008850</td>\n",
              "      <td>0.003180</td>\n",
              "      <td>0.902135</td>\n",
              "      <td>0.136333</td>\n",
              "      <td>0.919876</td>\n",
              "      <td>0.975624</td>\n",
              "      <td>0.004561</td>\n",
              "      <td>0.786007</td>\n",
              "      <td>1.000084</td>\n",
              "      <td>1.004118</td>\n",
              "      <td>0.906841</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.668647</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.003205</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.007653</td>\n",
              "      <td>0.184093</td>\n",
              "      <td>0.822281</td>\n",
              "      <td>0.003444</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.247217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.243532</td>\n",
              "      <td>0.241885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.707017</td>\n",
              "      <td>0.430501</td>\n",
              "      <td>0.001306</td>\n",
              "      <td>0.686414</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.008394</td>\n",
              "      <td>1.004333</td>\n",
              "      <td>1.008344</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.004838</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.004931</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003954</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>0.005032</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009576</td>\n",
              "      <td>0.005492</td>\n",
              "      <td>0.009217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-05-28</td>\n",
              "      <td>0.954180</td>\n",
              "      <td>0.091505</td>\n",
              "      <td>0.021655</td>\n",
              "      <td>1.009672</td>\n",
              "      <td>0.006815</td>\n",
              "      <td>0.123977</td>\n",
              "      <td>0.007598</td>\n",
              "      <td>0.009423</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007605</td>\n",
              "      <td>0.068839</td>\n",
              "      <td>0.720884</td>\n",
              "      <td>0.060492</td>\n",
              "      <td>0.003259</td>\n",
              "      <td>0.334650</td>\n",
              "      <td>0.524568</td>\n",
              "      <td>0.189424</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.066982</td>\n",
              "      <td>0.056647</td>\n",
              "      <td>0.005126</td>\n",
              "      <td>0.151955</td>\n",
              "      <td>1.337179</td>\n",
              "      <td>0.009355</td>\n",
              "      <td>0.007426</td>\n",
              "      <td>0.206629</td>\n",
              "      <td>0.738044</td>\n",
              "      <td>0.134073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.048367</td>\n",
              "      <td>0.010077</td>\n",
              "      <td>0.000530</td>\n",
              "      <td>1.009184</td>\n",
              "      <td>0.006961</td>\n",
              "      <td>0.112229</td>\n",
              "      <td>0.137014</td>\n",
              "      <td>1.001977</td>\n",
              "      <td>0.304124</td>\n",
              "      <td>0.153795</td>\n",
              "      <td>0.114534</td>\n",
              "      <td>0.006328</td>\n",
              "      <td>0.139504</td>\n",
              "      <td>0.084757</td>\n",
              "      <td>0.056653</td>\n",
              "      <td>0.070607</td>\n",
              "      <td>0.305883</td>\n",
              "      <td>0.212165</td>\n",
              "      <td>0.063955</td>\n",
              "      <td>0.406768</td>\n",
              "      <td>0.094001</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.001878</td>\n",
              "      <td>0.003636</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.645819</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004578</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.495308</td>\n",
              "      <td>0.006838</td>\n",
              "      <td>0.679257</td>\n",
              "      <td>0.001337</td>\n",
              "      <td>0.006025</td>\n",
              "      <td>0.009393</td>\n",
              "      <td>0.002615</td>\n",
              "      <td>0.075868</td>\n",
              "      <td>0.007152</td>\n",
              "      <td>0.103239</td>\n",
              "      <td>0.047454</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006561</td>\n",
              "      <td>0.078891</td>\n",
              "      <td>0.076510</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001782</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005419</td>\n",
              "      <td>0.006149</td>\n",
              "      <td>0.009629</td>\n",
              "      <td>0.003094</td>\n",
              "      <td>0.008295</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009362</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>0.005447</td>\n",
              "      <td>0.007345</td>\n",
              "      <td>0.007624</td>\n",
              "      <td>0.008811</td>\n",
              "      <td>0.504606</td>\n",
              "      <td>0.004056</td>\n",
              "      <td>1.004291</td>\n",
              "      <td>0.081954</td>\n",
              "      <td>0.002709</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>0.007139</td>\n",
              "      <td>0.008358</td>\n",
              "      <td>0.002325</td>\n",
              "      <td>0.007381</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005901</td>\n",
              "      <td>0.001185</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008013</td>\n",
              "      <td>0.008882</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007327</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>0.008686</td>\n",
              "      <td>0.008446</td>\n",
              "      <td>0.007291</td>\n",
              "      <td>0.007794</td>\n",
              "      <td>1.001014</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>0.009820</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>1.503359</td>\n",
              "      <td>1.005801</td>\n",
              "      <td>0.007425</td>\n",
              "      <td>0.009234</td>\n",
              "      <td>0.002471</td>\n",
              "      <td>0.009769</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.939654</td>\n",
              "      <td>0.134938</td>\n",
              "      <td>0.958699</td>\n",
              "      <td>0.974067</td>\n",
              "      <td>0.011736</td>\n",
              "      <td>0.806840</td>\n",
              "      <td>1.003014</td>\n",
              "      <td>1.009285</td>\n",
              "      <td>0.928719</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.670901</td>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.019176</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000754</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.004312</td>\n",
              "      <td>0.154837</td>\n",
              "      <td>0.853498</td>\n",
              "      <td>0.003269</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.239867</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.240768</td>\n",
              "      <td>0.239710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.704843</td>\n",
              "      <td>0.434409</td>\n",
              "      <td>0.003954</td>\n",
              "      <td>0.690101</td>\n",
              "      <td>0.009617</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.009307</td>\n",
              "      <td>1.007831</td>\n",
              "      <td>1.006878</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005681</td>\n",
              "      <td>0.005497</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009227</td>\n",
              "      <td>0.009123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003269</td>\n",
              "      <td>0.007329</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>0.006986</td>\n",
              "      <td>0.002603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-06-13</td>\n",
              "      <td>0.960384</td>\n",
              "      <td>0.002455</td>\n",
              "      <td>0.013683</td>\n",
              "      <td>1.002700</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.117169</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.005531</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006406</td>\n",
              "      <td>0.055630</td>\n",
              "      <td>0.723997</td>\n",
              "      <td>0.166782</td>\n",
              "      <td>0.009918</td>\n",
              "      <td>0.323271</td>\n",
              "      <td>0.530929</td>\n",
              "      <td>0.135586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.083720</td>\n",
              "      <td>0.049253</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.151219</td>\n",
              "      <td>1.339909</td>\n",
              "      <td>0.006782</td>\n",
              "      <td>0.003515</td>\n",
              "      <td>0.208214</td>\n",
              "      <td>0.741813</td>\n",
              "      <td>0.134437</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030063</td>\n",
              "      <td>0.009667</td>\n",
              "      <td>0.000783</td>\n",
              "      <td>1.007456</td>\n",
              "      <td>0.008706</td>\n",
              "      <td>0.102838</td>\n",
              "      <td>0.129017</td>\n",
              "      <td>0.704016</td>\n",
              "      <td>0.275055</td>\n",
              "      <td>0.155772</td>\n",
              "      <td>0.120740</td>\n",
              "      <td>0.004980</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>0.048382</td>\n",
              "      <td>0.012498</td>\n",
              "      <td>0.065926</td>\n",
              "      <td>0.273553</td>\n",
              "      <td>0.204300</td>\n",
              "      <td>0.022732</td>\n",
              "      <td>0.405175</td>\n",
              "      <td>0.094854</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.005899</td>\n",
              "      <td>0.005896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.654358</td>\n",
              "      <td>0.005897</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005207</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.508670</td>\n",
              "      <td>0.008183</td>\n",
              "      <td>0.515282</td>\n",
              "      <td>0.008716</td>\n",
              "      <td>0.005271</td>\n",
              "      <td>0.004554</td>\n",
              "      <td>0.002052</td>\n",
              "      <td>0.150209</td>\n",
              "      <td>0.005364</td>\n",
              "      <td>0.206394</td>\n",
              "      <td>0.031705</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009559</td>\n",
              "      <td>0.077490</td>\n",
              "      <td>0.071547</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005595</td>\n",
              "      <td>0.006363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.003895</td>\n",
              "      <td>0.005153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>0.005665</td>\n",
              "      <td>0.001888</td>\n",
              "      <td>0.004961</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.004652</td>\n",
              "      <td>0.508998</td>\n",
              "      <td>0.006969</td>\n",
              "      <td>1.004728</td>\n",
              "      <td>0.060634</td>\n",
              "      <td>0.009982</td>\n",
              "      <td>0.008817</td>\n",
              "      <td>0.008690</td>\n",
              "      <td>0.007364</td>\n",
              "      <td>0.005924</td>\n",
              "      <td>0.008802</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009455</td>\n",
              "      <td>0.008348</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007053</td>\n",
              "      <td>0.003909</td>\n",
              "      <td>0.002478</td>\n",
              "      <td>0.006614</td>\n",
              "      <td>0.009977</td>\n",
              "      <td>0.007686</td>\n",
              "      <td>1.002775</td>\n",
              "      <td>0.007791</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.007320</td>\n",
              "      <td>1.503701</td>\n",
              "      <td>1.007036</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.008507</td>\n",
              "      <td>0.004858</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.913205</td>\n",
              "      <td>0.140058</td>\n",
              "      <td>0.926341</td>\n",
              "      <td>0.975499</td>\n",
              "      <td>0.007571</td>\n",
              "      <td>0.808214</td>\n",
              "      <td>1.001517</td>\n",
              "      <td>1.004514</td>\n",
              "      <td>0.935383</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.672620</td>\n",
              "      <td>0.002729</td>\n",
              "      <td>0.011720</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.005338</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009703</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.002538</td>\n",
              "      <td>0.153939</td>\n",
              "      <td>0.844667</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.240910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.239400</td>\n",
              "      <td>0.240727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.711546</td>\n",
              "      <td>0.436903</td>\n",
              "      <td>0.005135</td>\n",
              "      <td>0.687779</td>\n",
              "      <td>0.004649</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.001671</td>\n",
              "      <td>1.003460</td>\n",
              "      <td>1.007573</td>\n",
              "      <td>0.007703</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007108</td>\n",
              "      <td>0.008261</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>0.002409</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006117</td>\n",
              "      <td>0.004516</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008419</td>\n",
              "      <td>0.006527</td>\n",
              "      <td>0.009600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>0.947248</td>\n",
              "      <td>0.002483</td>\n",
              "      <td>0.015193</td>\n",
              "      <td>1.000727</td>\n",
              "      <td>0.007605</td>\n",
              "      <td>0.117325</td>\n",
              "      <td>0.004653</td>\n",
              "      <td>0.009312</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007731</td>\n",
              "      <td>0.038862</td>\n",
              "      <td>0.720619</td>\n",
              "      <td>0.143630</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>0.231009</td>\n",
              "      <td>0.529305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.075900</td>\n",
              "      <td>0.048918</td>\n",
              "      <td>0.001199</td>\n",
              "      <td>0.154026</td>\n",
              "      <td>1.341735</td>\n",
              "      <td>0.000519</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.205468</td>\n",
              "      <td>0.691986</td>\n",
              "      <td>0.121518</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.054221</td>\n",
              "      <td>0.009484</td>\n",
              "      <td>0.006698</td>\n",
              "      <td>1.003738</td>\n",
              "      <td>0.003846</td>\n",
              "      <td>0.094311</td>\n",
              "      <td>0.129539</td>\n",
              "      <td>0.917133</td>\n",
              "      <td>0.231110</td>\n",
              "      <td>0.154914</td>\n",
              "      <td>0.095178</td>\n",
              "      <td>0.001653</td>\n",
              "      <td>0.126443</td>\n",
              "      <td>0.039259</td>\n",
              "      <td>0.027897</td>\n",
              "      <td>0.063697</td>\n",
              "      <td>0.233103</td>\n",
              "      <td>0.175655</td>\n",
              "      <td>0.031171</td>\n",
              "      <td>0.487460</td>\n",
              "      <td>0.093915</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.009479</td>\n",
              "      <td>0.001714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.650112</td>\n",
              "      <td>0.007773</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005851</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.216507</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>0.507712</td>\n",
              "      <td>0.006821</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.001419</td>\n",
              "      <td>0.096441</td>\n",
              "      <td>0.007972</td>\n",
              "      <td>0.106020</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008156</td>\n",
              "      <td>0.076561</td>\n",
              "      <td>0.074432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004933</td>\n",
              "      <td>0.004831</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001833</td>\n",
              "      <td>0.005738</td>\n",
              "      <td>0.003289</td>\n",
              "      <td>0.002608</td>\n",
              "      <td>0.007338</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007447</td>\n",
              "      <td>0.004465</td>\n",
              "      <td>0.006111</td>\n",
              "      <td>0.002246</td>\n",
              "      <td>0.002109</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>0.506213</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>1.000904</td>\n",
              "      <td>0.062492</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.001845</td>\n",
              "      <td>0.007816</td>\n",
              "      <td>0.002470</td>\n",
              "      <td>0.005516</td>\n",
              "      <td>0.007166</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.001504</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002019</td>\n",
              "      <td>0.002678</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007728</td>\n",
              "      <td>0.003432</td>\n",
              "      <td>0.002199</td>\n",
              "      <td>0.005511</td>\n",
              "      <td>0.004105</td>\n",
              "      <td>0.009656</td>\n",
              "      <td>1.006536</td>\n",
              "      <td>0.005158</td>\n",
              "      <td>0.003341</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>1.509905</td>\n",
              "      <td>1.002915</td>\n",
              "      <td>0.003079</td>\n",
              "      <td>0.003845</td>\n",
              "      <td>0.007190</td>\n",
              "      <td>0.002983</td>\n",
              "      <td>0.000535</td>\n",
              "      <td>0.921026</td>\n",
              "      <td>0.131620</td>\n",
              "      <td>0.933479</td>\n",
              "      <td>0.978027</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.822281</td>\n",
              "      <td>1.006125</td>\n",
              "      <td>1.005735</td>\n",
              "      <td>0.953363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.673869</td>\n",
              "      <td>0.009998</td>\n",
              "      <td>0.017598</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.003175</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000130</td>\n",
              "      <td>0.120717</td>\n",
              "      <td>0.811199</td>\n",
              "      <td>0.008724</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.247939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.244199</td>\n",
              "      <td>0.242325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.705343</td>\n",
              "      <td>0.437433</td>\n",
              "      <td>0.002849</td>\n",
              "      <td>0.688774</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.009886</td>\n",
              "      <td>1.005053</td>\n",
              "      <td>1.008132</td>\n",
              "      <td>0.009823</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009680</td>\n",
              "      <td>0.004848</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006312</td>\n",
              "      <td>0.004462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003671</td>\n",
              "      <td>0.004946</td>\n",
              "      <td>0.008889</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>0.008126</td>\n",
              "      <td>0.009827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         customer_ID         S_2       P_2  \\\n",
              "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  0.938469   \n",
              "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  0.936665   \n",
              "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  0.954180   \n",
              "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13  0.960384   \n",
              "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248   \n",
              "\n",
              "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  D_42  \\\n",
              "0  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771  0.004709   NaN   \n",
              "1  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798  0.002714   NaN   \n",
              "2  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598  0.009423   NaN   \n",
              "3  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685  0.005531   NaN   \n",
              "4  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653  0.009312   NaN   \n",
              "\n",
              "   D_43      D_44       B_4      D_45       B_5       R_2      D_46      D_47  \\\n",
              "0   NaN  0.000630  0.080986  0.708906  0.170600  0.006204  0.358587  0.525351   \n",
              "1   NaN  0.002526  0.069419  0.712795  0.113239  0.006206  0.353630  0.521311   \n",
              "2   NaN  0.007605  0.068839  0.720884  0.060492  0.003259  0.334650  0.524568   \n",
              "3   NaN  0.006406  0.055630  0.723997  0.166782  0.009918  0.323271  0.530929   \n",
              "4   NaN  0.007731  0.038862  0.720619  0.143630  0.006667  0.231009  0.529305   \n",
              "\n",
              "       D_48  D_49       B_6       B_7       B_8      D_50      D_51       B_9  \\\n",
              "0  0.255736   NaN  0.063902  0.059416  0.006466  0.148698  1.335856  0.008207   \n",
              "1  0.223329   NaN  0.065261  0.057744  0.001614  0.149723  1.339794  0.008373   \n",
              "2  0.189424   NaN  0.066982  0.056647  0.005126  0.151955  1.337179  0.009355   \n",
              "3  0.135586   NaN  0.083720  0.049253  0.001418  0.151219  1.339909  0.006782   \n",
              "4       NaN   NaN  0.075900  0.048918  0.001199  0.154026  1.341735  0.000519   \n",
              "\n",
              "        R_3      D_52       P_3      B_10  D_53       S_5      B_11       S_6  \\\n",
              "0  0.001423  0.207334  0.736463  0.096219   NaN  0.023381  0.002768  0.008322   \n",
              "1  0.001984  0.202778  0.720886  0.099804   NaN  0.030599  0.002749  0.002482   \n",
              "2  0.007426  0.206629  0.738044  0.134073   NaN  0.048367  0.010077  0.000530   \n",
              "3  0.003515  0.208214  0.741813  0.134437   NaN  0.030063  0.009667  0.000783   \n",
              "4  0.001362  0.205468  0.691986  0.121518   NaN  0.054221  0.009484  0.006698   \n",
              "\n",
              "       D_54       R_4       S_7      B_12       S_8      D_55      D_56  \\\n",
              "0  1.001519  0.008298  0.161345  0.148266  0.922998  0.354596  0.152025   \n",
              "1  1.009033  0.005136  0.140951  0.143530  0.919414  0.326757  0.156201   \n",
              "2  1.009184  0.006961  0.112229  0.137014  1.001977  0.304124  0.153795   \n",
              "3  1.007456  0.008706  0.102838  0.129017  0.704016  0.275055  0.155772   \n",
              "4  1.003738  0.003846  0.094311  0.129539  0.917133  0.231110  0.154914   \n",
              "\n",
              "       B_13       R_5      D_58       S_9      B_14      D_59      D_60  \\\n",
              "0  0.118075  0.001882  0.158612  0.065728  0.018385  0.063646  0.199617   \n",
              "1  0.118737  0.001610  0.148459  0.093935  0.013035  0.065501  0.151387   \n",
              "2  0.114534  0.006328  0.139504  0.084757  0.056653  0.070607  0.305883   \n",
              "3  0.120740  0.004980  0.138100  0.048382  0.012498  0.065926  0.273553   \n",
              "4  0.095178  0.001653  0.126443  0.039259  0.027897  0.063697  0.233103   \n",
              "\n",
              "       D_61      B_15      S_11      D_62 D_63 D_64      D_65      B_16  B_17  \\\n",
              "0  0.308233  0.016361  0.401619  0.091071   CR    O  0.007126  0.007665   NaN   \n",
              "1  0.265026  0.017688  0.406326  0.086805   CR    O  0.002413  0.007148   NaN   \n",
              "2  0.212165  0.063955  0.406768  0.094001   CR    O  0.001878  0.003636   NaN   \n",
              "3  0.204300  0.022732  0.405175  0.094854   CR    O  0.005899  0.005896   NaN   \n",
              "4  0.175655  0.031171  0.487460  0.093915   CR    O  0.009479  0.001714   NaN   \n",
              "\n",
              "       B_18      B_19  D_66      B_20  D_68      S_12       R_6      S_13  \\\n",
              "0  0.652984  0.008520   NaN  0.004730   6.0  0.272008  0.008363  0.515222   \n",
              "1  0.647093  0.002238   NaN  0.003879   6.0  0.188970  0.004030  0.509048   \n",
              "2  0.645819  0.000408   NaN  0.004578   6.0  0.495308  0.006838  0.679257   \n",
              "3  0.654358  0.005897   NaN  0.005207   6.0  0.508670  0.008183  0.515282   \n",
              "4  0.650112  0.007773   NaN  0.005851   6.0  0.216507  0.008605  0.507712   \n",
              "\n",
              "       B_21      D_69      B_22      D_70      D_71      D_72      S_15  \\\n",
              "0  0.002644  0.009013  0.004808  0.008342  0.119403  0.004802  0.108271   \n",
              "1  0.004193  0.007842  0.001283  0.006524  0.140611  0.000094  0.101018   \n",
              "2  0.001337  0.006025  0.009393  0.002615  0.075868  0.007152  0.103239   \n",
              "3  0.008716  0.005271  0.004554  0.002052  0.150209  0.005364  0.206394   \n",
              "4  0.006821  0.000152  0.000104  0.001419  0.096441  0.007972  0.106020   \n",
              "\n",
              "       B_23  D_73       P_4      D_74      D_75  D_76      B_24       R_7  \\\n",
              "0  0.050882   NaN  0.007554  0.080422  0.069067   NaN  0.004327  0.007562   \n",
              "1  0.040469   NaN  0.004832  0.081413  0.074166   NaN  0.004203  0.005304   \n",
              "2  0.047454   NaN  0.006561  0.078891  0.076510   NaN  0.001782  0.001422   \n",
              "3  0.031705   NaN  0.009559  0.077490  0.071547   NaN  0.005595  0.006363   \n",
              "4  0.032733   NaN  0.008156  0.076561  0.074432   NaN  0.004933  0.004831   \n",
              "\n",
              "   D_77      B_25      B_26      D_78      D_79       R_8  R_9      S_16  \\\n",
              "0   NaN  0.007729  0.000272  0.001576  0.004239  0.001434  NaN  0.002271   \n",
              "1   NaN  0.001864  0.000979  0.009896  0.007597  0.000509  NaN  0.009810   \n",
              "2   NaN  0.005419  0.006149  0.009629  0.003094  0.008295  NaN  0.009362   \n",
              "3   NaN  0.000646  0.009193  0.008568  0.003895  0.005153  NaN  0.004876   \n",
              "4   NaN  0.001833  0.005738  0.003289  0.002608  0.007338  NaN  0.007447   \n",
              "\n",
              "       D_80      R_10      R_11      B_27      D_81      D_82      S_17  \\\n",
              "0  0.004061  0.007121  0.002456  0.002310  0.003532  0.506612  0.008033   \n",
              "1  0.000127  0.005966  0.000395  0.001327  0.007773  0.500855  0.000760   \n",
              "2  0.000954  0.005447  0.007345  0.007624  0.008811  0.504606  0.004056   \n",
              "3  0.005665  0.001888  0.004961  0.000034  0.004652  0.508998  0.006969   \n",
              "4  0.004465  0.006111  0.002246  0.002109  0.001141  0.506213  0.001770   \n",
              "\n",
              "       R_12      B_28      R_13      D_83      R_14      R_15      D_84  \\\n",
              "0  1.009825  0.084683  0.003820  0.007043  0.000438  0.006452  0.000830   \n",
              "1  1.009461  0.081843  0.000347  0.007789  0.004311  0.002332  0.009469   \n",
              "2  1.004291  0.081954  0.002709  0.004093  0.007139  0.008358  0.002325   \n",
              "3  1.004728  0.060634  0.009982  0.008817  0.008690  0.007364  0.005924   \n",
              "4  1.000904  0.062492  0.005860  0.001845  0.007816  0.002470  0.005516   \n",
              "\n",
              "       R_16  B_29  B_30      S_18      D_86  D_87      R_17      R_18  D_88  \\\n",
              "0  0.005055   NaN   0.0  0.005720  0.007084   NaN  0.000198  0.008907   NaN   \n",
              "1  0.003753   NaN   0.0  0.007584  0.006677   NaN  0.001142  0.005907   NaN   \n",
              "2  0.007381   NaN   0.0  0.005901  0.001185   NaN  0.008013  0.008882   NaN   \n",
              "3  0.008802   NaN   0.0  0.002520  0.003324   NaN  0.009455  0.008348   NaN   \n",
              "4  0.007166   NaN   0.0  0.000155  0.001504   NaN  0.002019  0.002678   NaN   \n",
              "\n",
              "   B_31      S_19      R_19      B_32      S_20      R_20      R_21      B_33  \\\n",
              "0     1  0.002537  0.005177  0.006626  0.009705  0.007782  0.002450  1.001101   \n",
              "1     1  0.008427  0.008979  0.001854  0.009924  0.005987  0.002247  1.006779   \n",
              "2     1  0.007327  0.002016  0.008686  0.008446  0.007291  0.007794  1.001014   \n",
              "3     1  0.007053  0.003909  0.002478  0.006614  0.009977  0.007686  1.002775   \n",
              "4     1  0.007728  0.003432  0.002199  0.005511  0.004105  0.009656  1.006536   \n",
              "\n",
              "       D_89      R_22      R_23      D_91      D_92      D_93      D_94  \\\n",
              "0  0.002665  0.007479  0.006893  1.503673  1.006133  0.003569  0.008871   \n",
              "1  0.002508  0.006827  0.002837  1.503577  1.005791  0.000571  0.000391   \n",
              "2  0.009634  0.009820  0.005080  1.503359  1.005801  0.007425  0.009234   \n",
              "3  0.007791  0.000458  0.007320  1.503701  1.007036  0.000664  0.003200   \n",
              "4  0.005158  0.003341  0.000264  1.509905  1.002915  0.003079  0.003845   \n",
              "\n",
              "       R_24      R_25      D_96      S_22      S_23      S_24      S_25  \\\n",
              "0  0.003950  0.003647  0.004950  0.894090  0.135561  0.911191  0.974539   \n",
              "1  0.008351  0.008850  0.003180  0.902135  0.136333  0.919876  0.975624   \n",
              "2  0.002471  0.009769  0.005433  0.939654  0.134938  0.958699  0.974067   \n",
              "3  0.008507  0.004858  0.000063  0.913205  0.140058  0.926341  0.975499   \n",
              "4  0.007190  0.002983  0.000535  0.921026  0.131620  0.933479  0.978027   \n",
              "\n",
              "       S_26     D_102     D_103     D_104     D_105  D_106     D_107  \\\n",
              "0  0.001243  0.766688  1.008691  1.004587  0.893734    NaN  0.670041   \n",
              "1  0.004561  0.786007  1.000084  1.004118  0.906841    NaN  0.668647   \n",
              "2  0.011736  0.806840  1.003014  1.009285  0.928719    NaN  0.670901   \n",
              "3  0.007571  0.808214  1.001517  1.004514  0.935383    NaN  0.672620   \n",
              "4  0.018200  0.822281  1.006125  1.005735  0.953363    NaN  0.673869   \n",
              "\n",
              "       B_36      B_37  R_26      R_27  B_38  D_108     D_109  D_110  D_111  \\\n",
              "0  0.009968  0.004572   NaN  1.008949   2.0    NaN  0.004326    NaN    NaN   \n",
              "1  0.003921  0.004654   NaN  1.003205   2.0    NaN  0.008707    NaN    NaN   \n",
              "2  0.001264  0.019176   NaN  1.000754   2.0    NaN  0.004092    NaN    NaN   \n",
              "3  0.002729  0.011720   NaN  1.005338   2.0    NaN  0.009703    NaN    NaN   \n",
              "4  0.009998  0.017598   NaN  1.003175   2.0    NaN  0.009120    NaN    NaN   \n",
              "\n",
              "   B_39     D_112      B_40      S_27     D_113  D_114     D_115  D_116  \\\n",
              "0   NaN  1.007336  0.210060  0.676922  0.007871    1.0  0.238250    0.0   \n",
              "1   NaN  1.007653  0.184093  0.822281  0.003444    1.0  0.247217    0.0   \n",
              "2   NaN  1.004312  0.154837  0.853498  0.003269    1.0  0.239867    0.0   \n",
              "3   NaN  1.002538  0.153939  0.844667  0.000053    1.0  0.240910    0.0   \n",
              "4   NaN  1.000130  0.120717  0.811199  0.008724    1.0  0.247939    0.0   \n",
              "\n",
              "   D_117     D_118     D_119  D_120     D_121     D_122     D_123     D_124  \\\n",
              "0    4.0  0.232120  0.236266    0.0  0.702280  0.434345  0.003057  0.686516   \n",
              "1    4.0  0.243532  0.241885    0.0  0.707017  0.430501  0.001306  0.686414   \n",
              "2    4.0  0.240768  0.239710    0.0  0.704843  0.434409  0.003954  0.690101   \n",
              "3    4.0  0.239400  0.240727    0.0  0.711546  0.436903  0.005135  0.687779   \n",
              "4    4.0  0.244199  0.242325    0.0  0.705343  0.437433  0.002849  0.688774   \n",
              "\n",
              "      D_125  D_126     D_127     D_128     D_129      B_41  B_42     D_130  \\\n",
              "0  0.008740    1.0  1.003319  1.007819  1.000080  0.006805   NaN  0.002052   \n",
              "1  0.000755    1.0  1.008394  1.004333  1.008344  0.004407   NaN  0.001034   \n",
              "2  0.009617    1.0  1.009307  1.007831  1.006878  0.003221   NaN  0.005681   \n",
              "3  0.004649    1.0  1.001671  1.003460  1.007573  0.007703   NaN  0.007108   \n",
              "4  0.000097    1.0  1.009886  1.005053  1.008132  0.009823   NaN  0.009680   \n",
              "\n",
              "      D_131  D_132     D_133      R_28  D_134  D_135  D_136  D_137  D_138  \\\n",
              "0  0.005972    NaN  0.004345  0.001535    NaN    NaN    NaN    NaN    NaN   \n",
              "1  0.004838    NaN  0.007495  0.004931    NaN    NaN    NaN    NaN    NaN   \n",
              "2  0.005497    NaN  0.009227  0.009123    NaN    NaN    NaN    NaN    NaN   \n",
              "3  0.008261    NaN  0.007206  0.002409    NaN    NaN    NaN    NaN    NaN   \n",
              "4  0.004848    NaN  0.006312  0.004462    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "      D_139     D_140     D_141  D_142     D_143     D_144     D_145  \n",
              "0  0.002427  0.003706  0.003818    NaN  0.000569  0.000610  0.002674  \n",
              "1  0.003954  0.003167  0.005032    NaN  0.009576  0.005492  0.009217  \n",
              "2  0.003269  0.007329  0.000427    NaN  0.003429  0.006986  0.002603  \n",
              "3  0.006117  0.004516  0.003200    NaN  0.008419  0.006527  0.009600  \n",
              "4  0.003671  0.004946  0.008889    NaN  0.001670  0.008126  0.009827  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(\"train_data.csv\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "Z96k6fO36kEv",
        "outputId": "6311adeb-15b6-4c1b-f76b-e9d5cbc9e345"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5531451, 190)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ7tAsa86kEw",
        "outputId": "742d40fb-c7fe-454a-e725-392f459ddefd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         customer_ID  target\n",
              "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...       0\n",
              "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...       0\n",
              "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...       0\n",
              "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...       0\n",
              "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...       0"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = pd.read_csv(\"train_labels.csv\")\n",
        "labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "89WiVADa6kEw"
      },
      "outputs": [],
      "source": [
        "# Convert Date column to datetime() Data Type\n",
        "train['S_2'] = pd.to_datetime(train['S_2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8X0dIGf6kEw",
        "outputId": "a478f760-a537-44b6-85e5-e2d565ca81f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>S_2</th>\n",
              "      <th>P_2</th>\n",
              "      <th>D_39</th>\n",
              "      <th>B_1</th>\n",
              "      <th>B_2</th>\n",
              "      <th>R_1</th>\n",
              "      <th>S_3</th>\n",
              "      <th>D_41</th>\n",
              "      <th>B_3</th>\n",
              "      <th>D_42</th>\n",
              "      <th>D_43</th>\n",
              "      <th>D_44</th>\n",
              "      <th>B_4</th>\n",
              "      <th>D_45</th>\n",
              "      <th>B_5</th>\n",
              "      <th>R_2</th>\n",
              "      <th>D_46</th>\n",
              "      <th>D_47</th>\n",
              "      <th>D_48</th>\n",
              "      <th>D_49</th>\n",
              "      <th>B_6</th>\n",
              "      <th>B_7</th>\n",
              "      <th>B_8</th>\n",
              "      <th>D_50</th>\n",
              "      <th>D_51</th>\n",
              "      <th>B_9</th>\n",
              "      <th>R_3</th>\n",
              "      <th>D_52</th>\n",
              "      <th>P_3</th>\n",
              "      <th>B_10</th>\n",
              "      <th>D_53</th>\n",
              "      <th>S_5</th>\n",
              "      <th>B_11</th>\n",
              "      <th>S_6</th>\n",
              "      <th>D_54</th>\n",
              "      <th>R_4</th>\n",
              "      <th>S_7</th>\n",
              "      <th>B_12</th>\n",
              "      <th>S_8</th>\n",
              "      <th>D_55</th>\n",
              "      <th>D_56</th>\n",
              "      <th>B_13</th>\n",
              "      <th>R_5</th>\n",
              "      <th>D_58</th>\n",
              "      <th>S_9</th>\n",
              "      <th>B_14</th>\n",
              "      <th>D_59</th>\n",
              "      <th>D_60</th>\n",
              "      <th>D_61</th>\n",
              "      <th>B_15</th>\n",
              "      <th>S_11</th>\n",
              "      <th>D_62</th>\n",
              "      <th>D_63</th>\n",
              "      <th>D_64</th>\n",
              "      <th>D_65</th>\n",
              "      <th>B_16</th>\n",
              "      <th>B_17</th>\n",
              "      <th>B_18</th>\n",
              "      <th>B_19</th>\n",
              "      <th>D_66</th>\n",
              "      <th>B_20</th>\n",
              "      <th>D_68</th>\n",
              "      <th>S_12</th>\n",
              "      <th>R_6</th>\n",
              "      <th>S_13</th>\n",
              "      <th>B_21</th>\n",
              "      <th>D_69</th>\n",
              "      <th>B_22</th>\n",
              "      <th>D_70</th>\n",
              "      <th>D_71</th>\n",
              "      <th>D_72</th>\n",
              "      <th>S_15</th>\n",
              "      <th>B_23</th>\n",
              "      <th>D_73</th>\n",
              "      <th>P_4</th>\n",
              "      <th>D_74</th>\n",
              "      <th>D_75</th>\n",
              "      <th>D_76</th>\n",
              "      <th>B_24</th>\n",
              "      <th>R_7</th>\n",
              "      <th>D_77</th>\n",
              "      <th>B_25</th>\n",
              "      <th>B_26</th>\n",
              "      <th>D_78</th>\n",
              "      <th>D_79</th>\n",
              "      <th>R_8</th>\n",
              "      <th>R_9</th>\n",
              "      <th>S_16</th>\n",
              "      <th>D_80</th>\n",
              "      <th>R_10</th>\n",
              "      <th>R_11</th>\n",
              "      <th>B_27</th>\n",
              "      <th>D_81</th>\n",
              "      <th>D_82</th>\n",
              "      <th>S_17</th>\n",
              "      <th>R_12</th>\n",
              "      <th>B_28</th>\n",
              "      <th>R_13</th>\n",
              "      <th>D_83</th>\n",
              "      <th>R_14</th>\n",
              "      <th>R_15</th>\n",
              "      <th>D_84</th>\n",
              "      <th>R_16</th>\n",
              "      <th>B_29</th>\n",
              "      <th>B_30</th>\n",
              "      <th>S_18</th>\n",
              "      <th>D_86</th>\n",
              "      <th>D_87</th>\n",
              "      <th>R_17</th>\n",
              "      <th>R_18</th>\n",
              "      <th>D_88</th>\n",
              "      <th>B_31</th>\n",
              "      <th>S_19</th>\n",
              "      <th>R_19</th>\n",
              "      <th>B_32</th>\n",
              "      <th>S_20</th>\n",
              "      <th>R_20</th>\n",
              "      <th>R_21</th>\n",
              "      <th>B_33</th>\n",
              "      <th>D_89</th>\n",
              "      <th>R_22</th>\n",
              "      <th>R_23</th>\n",
              "      <th>D_91</th>\n",
              "      <th>D_92</th>\n",
              "      <th>D_93</th>\n",
              "      <th>D_94</th>\n",
              "      <th>R_24</th>\n",
              "      <th>R_25</th>\n",
              "      <th>D_96</th>\n",
              "      <th>S_22</th>\n",
              "      <th>S_23</th>\n",
              "      <th>S_24</th>\n",
              "      <th>S_25</th>\n",
              "      <th>S_26</th>\n",
              "      <th>D_102</th>\n",
              "      <th>D_103</th>\n",
              "      <th>D_104</th>\n",
              "      <th>D_105</th>\n",
              "      <th>D_106</th>\n",
              "      <th>D_107</th>\n",
              "      <th>B_36</th>\n",
              "      <th>B_37</th>\n",
              "      <th>R_26</th>\n",
              "      <th>R_27</th>\n",
              "      <th>B_38</th>\n",
              "      <th>D_108</th>\n",
              "      <th>D_109</th>\n",
              "      <th>D_110</th>\n",
              "      <th>D_111</th>\n",
              "      <th>B_39</th>\n",
              "      <th>D_112</th>\n",
              "      <th>B_40</th>\n",
              "      <th>S_27</th>\n",
              "      <th>D_113</th>\n",
              "      <th>D_114</th>\n",
              "      <th>D_115</th>\n",
              "      <th>D_116</th>\n",
              "      <th>D_117</th>\n",
              "      <th>D_118</th>\n",
              "      <th>D_119</th>\n",
              "      <th>D_120</th>\n",
              "      <th>D_121</th>\n",
              "      <th>D_122</th>\n",
              "      <th>D_123</th>\n",
              "      <th>D_124</th>\n",
              "      <th>D_125</th>\n",
              "      <th>D_126</th>\n",
              "      <th>D_127</th>\n",
              "      <th>D_128</th>\n",
              "      <th>D_129</th>\n",
              "      <th>B_41</th>\n",
              "      <th>B_42</th>\n",
              "      <th>D_130</th>\n",
              "      <th>D_131</th>\n",
              "      <th>D_132</th>\n",
              "      <th>D_133</th>\n",
              "      <th>R_28</th>\n",
              "      <th>D_134</th>\n",
              "      <th>D_135</th>\n",
              "      <th>D_136</th>\n",
              "      <th>D_137</th>\n",
              "      <th>D_138</th>\n",
              "      <th>D_139</th>\n",
              "      <th>D_140</th>\n",
              "      <th>D_141</th>\n",
              "      <th>D_142</th>\n",
              "      <th>D_143</th>\n",
              "      <th>D_144</th>\n",
              "      <th>D_145</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-03-09</td>\n",
              "      <td>0.938469</td>\n",
              "      <td>0.001733</td>\n",
              "      <td>0.008724</td>\n",
              "      <td>1.006838</td>\n",
              "      <td>0.009228</td>\n",
              "      <td>0.124035</td>\n",
              "      <td>0.008771</td>\n",
              "      <td>0.004709</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.080986</td>\n",
              "      <td>0.708906</td>\n",
              "      <td>0.170600</td>\n",
              "      <td>0.006204</td>\n",
              "      <td>0.358587</td>\n",
              "      <td>0.525351</td>\n",
              "      <td>0.255736</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.063902</td>\n",
              "      <td>0.059416</td>\n",
              "      <td>0.006466</td>\n",
              "      <td>0.148698</td>\n",
              "      <td>1.335856</td>\n",
              "      <td>0.008207</td>\n",
              "      <td>0.001423</td>\n",
              "      <td>0.207334</td>\n",
              "      <td>0.736463</td>\n",
              "      <td>0.096219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.023381</td>\n",
              "      <td>0.002768</td>\n",
              "      <td>0.008322</td>\n",
              "      <td>1.001519</td>\n",
              "      <td>0.008298</td>\n",
              "      <td>0.161345</td>\n",
              "      <td>0.148266</td>\n",
              "      <td>0.922998</td>\n",
              "      <td>0.354596</td>\n",
              "      <td>0.152025</td>\n",
              "      <td>0.118075</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>0.158612</td>\n",
              "      <td>0.065728</td>\n",
              "      <td>0.018385</td>\n",
              "      <td>0.063646</td>\n",
              "      <td>0.199617</td>\n",
              "      <td>0.308233</td>\n",
              "      <td>0.016361</td>\n",
              "      <td>0.401619</td>\n",
              "      <td>0.091071</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.007126</td>\n",
              "      <td>0.007665</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.652984</td>\n",
              "      <td>0.008520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004730</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.272008</td>\n",
              "      <td>0.008363</td>\n",
              "      <td>0.515222</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>0.009013</td>\n",
              "      <td>0.004808</td>\n",
              "      <td>0.008342</td>\n",
              "      <td>0.119403</td>\n",
              "      <td>0.004802</td>\n",
              "      <td>0.108271</td>\n",
              "      <td>0.050882</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007554</td>\n",
              "      <td>0.080422</td>\n",
              "      <td>0.069067</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004327</td>\n",
              "      <td>0.007562</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007729</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.001576</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>0.001434</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002271</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>0.007121</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.002310</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>0.506612</td>\n",
              "      <td>0.008033</td>\n",
              "      <td>1.009825</td>\n",
              "      <td>0.084683</td>\n",
              "      <td>0.003820</td>\n",
              "      <td>0.007043</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005720</td>\n",
              "      <td>0.007084</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.008907</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002537</td>\n",
              "      <td>0.005177</td>\n",
              "      <td>0.006626</td>\n",
              "      <td>0.009705</td>\n",
              "      <td>0.007782</td>\n",
              "      <td>0.002450</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>0.002665</td>\n",
              "      <td>0.007479</td>\n",
              "      <td>0.006893</td>\n",
              "      <td>1.503673</td>\n",
              "      <td>1.006133</td>\n",
              "      <td>0.003569</td>\n",
              "      <td>0.008871</td>\n",
              "      <td>0.003950</td>\n",
              "      <td>0.003647</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.894090</td>\n",
              "      <td>0.135561</td>\n",
              "      <td>0.911191</td>\n",
              "      <td>0.974539</td>\n",
              "      <td>0.001243</td>\n",
              "      <td>0.766688</td>\n",
              "      <td>1.008691</td>\n",
              "      <td>1.004587</td>\n",
              "      <td>0.893734</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.670041</td>\n",
              "      <td>0.009968</td>\n",
              "      <td>0.004572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.008949</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004326</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.007336</td>\n",
              "      <td>0.210060</td>\n",
              "      <td>0.676922</td>\n",
              "      <td>0.007871</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.238250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.232120</td>\n",
              "      <td>0.236266</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702280</td>\n",
              "      <td>0.434345</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.686516</td>\n",
              "      <td>0.008740</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.003319</td>\n",
              "      <td>1.007819</td>\n",
              "      <td>1.000080</td>\n",
              "      <td>0.006805</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002052</td>\n",
              "      <td>0.005972</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004345</td>\n",
              "      <td>0.001535</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002427</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>0.000610</td>\n",
              "      <td>0.002674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-04-07</td>\n",
              "      <td>0.936665</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.004923</td>\n",
              "      <td>1.000653</td>\n",
              "      <td>0.006151</td>\n",
              "      <td>0.126750</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.069419</td>\n",
              "      <td>0.712795</td>\n",
              "      <td>0.113239</td>\n",
              "      <td>0.006206</td>\n",
              "      <td>0.353630</td>\n",
              "      <td>0.521311</td>\n",
              "      <td>0.223329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.065261</td>\n",
              "      <td>0.057744</td>\n",
              "      <td>0.001614</td>\n",
              "      <td>0.149723</td>\n",
              "      <td>1.339794</td>\n",
              "      <td>0.008373</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>0.202778</td>\n",
              "      <td>0.720886</td>\n",
              "      <td>0.099804</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030599</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.002482</td>\n",
              "      <td>1.009033</td>\n",
              "      <td>0.005136</td>\n",
              "      <td>0.140951</td>\n",
              "      <td>0.143530</td>\n",
              "      <td>0.919414</td>\n",
              "      <td>0.326757</td>\n",
              "      <td>0.156201</td>\n",
              "      <td>0.118737</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.148459</td>\n",
              "      <td>0.093935</td>\n",
              "      <td>0.013035</td>\n",
              "      <td>0.065501</td>\n",
              "      <td>0.151387</td>\n",
              "      <td>0.265026</td>\n",
              "      <td>0.017688</td>\n",
              "      <td>0.406326</td>\n",
              "      <td>0.086805</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.002413</td>\n",
              "      <td>0.007148</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.647093</td>\n",
              "      <td>0.002238</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003879</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.188970</td>\n",
              "      <td>0.004030</td>\n",
              "      <td>0.509048</td>\n",
              "      <td>0.004193</td>\n",
              "      <td>0.007842</td>\n",
              "      <td>0.001283</td>\n",
              "      <td>0.006524</td>\n",
              "      <td>0.140611</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.101018</td>\n",
              "      <td>0.040469</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004832</td>\n",
              "      <td>0.081413</td>\n",
              "      <td>0.074166</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004203</td>\n",
              "      <td>0.005304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001864</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>0.009896</td>\n",
              "      <td>0.007597</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009810</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.005966</td>\n",
              "      <td>0.000395</td>\n",
              "      <td>0.001327</td>\n",
              "      <td>0.007773</td>\n",
              "      <td>0.500855</td>\n",
              "      <td>0.000760</td>\n",
              "      <td>1.009461</td>\n",
              "      <td>0.081843</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.007789</td>\n",
              "      <td>0.004311</td>\n",
              "      <td>0.002332</td>\n",
              "      <td>0.009469</td>\n",
              "      <td>0.003753</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007584</td>\n",
              "      <td>0.006677</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001142</td>\n",
              "      <td>0.005907</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008427</td>\n",
              "      <td>0.008979</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.009924</td>\n",
              "      <td>0.005987</td>\n",
              "      <td>0.002247</td>\n",
              "      <td>1.006779</td>\n",
              "      <td>0.002508</td>\n",
              "      <td>0.006827</td>\n",
              "      <td>0.002837</td>\n",
              "      <td>1.503577</td>\n",
              "      <td>1.005791</td>\n",
              "      <td>0.000571</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.008351</td>\n",
              "      <td>0.008850</td>\n",
              "      <td>0.003180</td>\n",
              "      <td>0.902135</td>\n",
              "      <td>0.136333</td>\n",
              "      <td>0.919876</td>\n",
              "      <td>0.975624</td>\n",
              "      <td>0.004561</td>\n",
              "      <td>0.786007</td>\n",
              "      <td>1.000084</td>\n",
              "      <td>1.004118</td>\n",
              "      <td>0.906841</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.668647</td>\n",
              "      <td>0.003921</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.003205</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.007653</td>\n",
              "      <td>0.184093</td>\n",
              "      <td>0.822281</td>\n",
              "      <td>0.003444</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.247217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.243532</td>\n",
              "      <td>0.241885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.707017</td>\n",
              "      <td>0.430501</td>\n",
              "      <td>0.001306</td>\n",
              "      <td>0.686414</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.008394</td>\n",
              "      <td>1.004333</td>\n",
              "      <td>1.008344</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.004838</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.004931</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003954</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>0.005032</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009576</td>\n",
              "      <td>0.005492</td>\n",
              "      <td>0.009217</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-05-28</td>\n",
              "      <td>0.954180</td>\n",
              "      <td>0.091505</td>\n",
              "      <td>0.021655</td>\n",
              "      <td>1.009672</td>\n",
              "      <td>0.006815</td>\n",
              "      <td>0.123977</td>\n",
              "      <td>0.007598</td>\n",
              "      <td>0.009423</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007605</td>\n",
              "      <td>0.068839</td>\n",
              "      <td>0.720884</td>\n",
              "      <td>0.060492</td>\n",
              "      <td>0.003259</td>\n",
              "      <td>0.334650</td>\n",
              "      <td>0.524568</td>\n",
              "      <td>0.189424</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.066982</td>\n",
              "      <td>0.056647</td>\n",
              "      <td>0.005126</td>\n",
              "      <td>0.151955</td>\n",
              "      <td>1.337179</td>\n",
              "      <td>0.009355</td>\n",
              "      <td>0.007426</td>\n",
              "      <td>0.206629</td>\n",
              "      <td>0.738044</td>\n",
              "      <td>0.134073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.048367</td>\n",
              "      <td>0.010077</td>\n",
              "      <td>0.000530</td>\n",
              "      <td>1.009184</td>\n",
              "      <td>0.006961</td>\n",
              "      <td>0.112229</td>\n",
              "      <td>0.137014</td>\n",
              "      <td>1.001977</td>\n",
              "      <td>0.304124</td>\n",
              "      <td>0.153795</td>\n",
              "      <td>0.114534</td>\n",
              "      <td>0.006328</td>\n",
              "      <td>0.139504</td>\n",
              "      <td>0.084757</td>\n",
              "      <td>0.056653</td>\n",
              "      <td>0.070607</td>\n",
              "      <td>0.305883</td>\n",
              "      <td>0.212165</td>\n",
              "      <td>0.063955</td>\n",
              "      <td>0.406768</td>\n",
              "      <td>0.094001</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.001878</td>\n",
              "      <td>0.003636</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.645819</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004578</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.495308</td>\n",
              "      <td>0.006838</td>\n",
              "      <td>0.679257</td>\n",
              "      <td>0.001337</td>\n",
              "      <td>0.006025</td>\n",
              "      <td>0.009393</td>\n",
              "      <td>0.002615</td>\n",
              "      <td>0.075868</td>\n",
              "      <td>0.007152</td>\n",
              "      <td>0.103239</td>\n",
              "      <td>0.047454</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006561</td>\n",
              "      <td>0.078891</td>\n",
              "      <td>0.076510</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001782</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005419</td>\n",
              "      <td>0.006149</td>\n",
              "      <td>0.009629</td>\n",
              "      <td>0.003094</td>\n",
              "      <td>0.008295</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009362</td>\n",
              "      <td>0.000954</td>\n",
              "      <td>0.005447</td>\n",
              "      <td>0.007345</td>\n",
              "      <td>0.007624</td>\n",
              "      <td>0.008811</td>\n",
              "      <td>0.504606</td>\n",
              "      <td>0.004056</td>\n",
              "      <td>1.004291</td>\n",
              "      <td>0.081954</td>\n",
              "      <td>0.002709</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>0.007139</td>\n",
              "      <td>0.008358</td>\n",
              "      <td>0.002325</td>\n",
              "      <td>0.007381</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005901</td>\n",
              "      <td>0.001185</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008013</td>\n",
              "      <td>0.008882</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007327</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>0.008686</td>\n",
              "      <td>0.008446</td>\n",
              "      <td>0.007291</td>\n",
              "      <td>0.007794</td>\n",
              "      <td>1.001014</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>0.009820</td>\n",
              "      <td>0.005080</td>\n",
              "      <td>1.503359</td>\n",
              "      <td>1.005801</td>\n",
              "      <td>0.007425</td>\n",
              "      <td>0.009234</td>\n",
              "      <td>0.002471</td>\n",
              "      <td>0.009769</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.939654</td>\n",
              "      <td>0.134938</td>\n",
              "      <td>0.958699</td>\n",
              "      <td>0.974067</td>\n",
              "      <td>0.011736</td>\n",
              "      <td>0.806840</td>\n",
              "      <td>1.003014</td>\n",
              "      <td>1.009285</td>\n",
              "      <td>0.928719</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.670901</td>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.019176</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000754</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004092</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.004312</td>\n",
              "      <td>0.154837</td>\n",
              "      <td>0.853498</td>\n",
              "      <td>0.003269</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.239867</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.240768</td>\n",
              "      <td>0.239710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.704843</td>\n",
              "      <td>0.434409</td>\n",
              "      <td>0.003954</td>\n",
              "      <td>0.690101</td>\n",
              "      <td>0.009617</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.009307</td>\n",
              "      <td>1.007831</td>\n",
              "      <td>1.006878</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005681</td>\n",
              "      <td>0.005497</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009227</td>\n",
              "      <td>0.009123</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003269</td>\n",
              "      <td>0.007329</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>0.006986</td>\n",
              "      <td>0.002603</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-06-13</td>\n",
              "      <td>0.960384</td>\n",
              "      <td>0.002455</td>\n",
              "      <td>0.013683</td>\n",
              "      <td>1.002700</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.117169</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.005531</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006406</td>\n",
              "      <td>0.055630</td>\n",
              "      <td>0.723997</td>\n",
              "      <td>0.166782</td>\n",
              "      <td>0.009918</td>\n",
              "      <td>0.323271</td>\n",
              "      <td>0.530929</td>\n",
              "      <td>0.135586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.083720</td>\n",
              "      <td>0.049253</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.151219</td>\n",
              "      <td>1.339909</td>\n",
              "      <td>0.006782</td>\n",
              "      <td>0.003515</td>\n",
              "      <td>0.208214</td>\n",
              "      <td>0.741813</td>\n",
              "      <td>0.134437</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030063</td>\n",
              "      <td>0.009667</td>\n",
              "      <td>0.000783</td>\n",
              "      <td>1.007456</td>\n",
              "      <td>0.008706</td>\n",
              "      <td>0.102838</td>\n",
              "      <td>0.129017</td>\n",
              "      <td>0.704016</td>\n",
              "      <td>0.275055</td>\n",
              "      <td>0.155772</td>\n",
              "      <td>0.120740</td>\n",
              "      <td>0.004980</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>0.048382</td>\n",
              "      <td>0.012498</td>\n",
              "      <td>0.065926</td>\n",
              "      <td>0.273553</td>\n",
              "      <td>0.204300</td>\n",
              "      <td>0.022732</td>\n",
              "      <td>0.405175</td>\n",
              "      <td>0.094854</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.005899</td>\n",
              "      <td>0.005896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.654358</td>\n",
              "      <td>0.005897</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005207</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.508670</td>\n",
              "      <td>0.008183</td>\n",
              "      <td>0.515282</td>\n",
              "      <td>0.008716</td>\n",
              "      <td>0.005271</td>\n",
              "      <td>0.004554</td>\n",
              "      <td>0.002052</td>\n",
              "      <td>0.150209</td>\n",
              "      <td>0.005364</td>\n",
              "      <td>0.206394</td>\n",
              "      <td>0.031705</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009559</td>\n",
              "      <td>0.077490</td>\n",
              "      <td>0.071547</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005595</td>\n",
              "      <td>0.006363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.003895</td>\n",
              "      <td>0.005153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004876</td>\n",
              "      <td>0.005665</td>\n",
              "      <td>0.001888</td>\n",
              "      <td>0.004961</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.004652</td>\n",
              "      <td>0.508998</td>\n",
              "      <td>0.006969</td>\n",
              "      <td>1.004728</td>\n",
              "      <td>0.060634</td>\n",
              "      <td>0.009982</td>\n",
              "      <td>0.008817</td>\n",
              "      <td>0.008690</td>\n",
              "      <td>0.007364</td>\n",
              "      <td>0.005924</td>\n",
              "      <td>0.008802</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009455</td>\n",
              "      <td>0.008348</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007053</td>\n",
              "      <td>0.003909</td>\n",
              "      <td>0.002478</td>\n",
              "      <td>0.006614</td>\n",
              "      <td>0.009977</td>\n",
              "      <td>0.007686</td>\n",
              "      <td>1.002775</td>\n",
              "      <td>0.007791</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.007320</td>\n",
              "      <td>1.503701</td>\n",
              "      <td>1.007036</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.008507</td>\n",
              "      <td>0.004858</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.913205</td>\n",
              "      <td>0.140058</td>\n",
              "      <td>0.926341</td>\n",
              "      <td>0.975499</td>\n",
              "      <td>0.007571</td>\n",
              "      <td>0.808214</td>\n",
              "      <td>1.001517</td>\n",
              "      <td>1.004514</td>\n",
              "      <td>0.935383</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.672620</td>\n",
              "      <td>0.002729</td>\n",
              "      <td>0.011720</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.005338</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009703</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.002538</td>\n",
              "      <td>0.153939</td>\n",
              "      <td>0.844667</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.240910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.239400</td>\n",
              "      <td>0.240727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.711546</td>\n",
              "      <td>0.436903</td>\n",
              "      <td>0.005135</td>\n",
              "      <td>0.687779</td>\n",
              "      <td>0.004649</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.001671</td>\n",
              "      <td>1.003460</td>\n",
              "      <td>1.007573</td>\n",
              "      <td>0.007703</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007108</td>\n",
              "      <td>0.008261</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>0.002409</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006117</td>\n",
              "      <td>0.004516</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008419</td>\n",
              "      <td>0.006527</td>\n",
              "      <td>0.009600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>0.947248</td>\n",
              "      <td>0.002483</td>\n",
              "      <td>0.015193</td>\n",
              "      <td>1.000727</td>\n",
              "      <td>0.007605</td>\n",
              "      <td>0.117325</td>\n",
              "      <td>0.004653</td>\n",
              "      <td>0.009312</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007731</td>\n",
              "      <td>0.038862</td>\n",
              "      <td>0.720619</td>\n",
              "      <td>0.143630</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>0.231009</td>\n",
              "      <td>0.529305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.075900</td>\n",
              "      <td>0.048918</td>\n",
              "      <td>0.001199</td>\n",
              "      <td>0.154026</td>\n",
              "      <td>1.341735</td>\n",
              "      <td>0.000519</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.205468</td>\n",
              "      <td>0.691986</td>\n",
              "      <td>0.121518</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.054221</td>\n",
              "      <td>0.009484</td>\n",
              "      <td>0.006698</td>\n",
              "      <td>1.003738</td>\n",
              "      <td>0.003846</td>\n",
              "      <td>0.094311</td>\n",
              "      <td>0.129539</td>\n",
              "      <td>0.917133</td>\n",
              "      <td>0.231110</td>\n",
              "      <td>0.154914</td>\n",
              "      <td>0.095178</td>\n",
              "      <td>0.001653</td>\n",
              "      <td>0.126443</td>\n",
              "      <td>0.039259</td>\n",
              "      <td>0.027897</td>\n",
              "      <td>0.063697</td>\n",
              "      <td>0.233103</td>\n",
              "      <td>0.175655</td>\n",
              "      <td>0.031171</td>\n",
              "      <td>0.487460</td>\n",
              "      <td>0.093915</td>\n",
              "      <td>CR</td>\n",
              "      <td>O</td>\n",
              "      <td>0.009479</td>\n",
              "      <td>0.001714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.650112</td>\n",
              "      <td>0.007773</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005851</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.216507</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>0.507712</td>\n",
              "      <td>0.006821</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.001419</td>\n",
              "      <td>0.096441</td>\n",
              "      <td>0.007972</td>\n",
              "      <td>0.106020</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008156</td>\n",
              "      <td>0.076561</td>\n",
              "      <td>0.074432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004933</td>\n",
              "      <td>0.004831</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001833</td>\n",
              "      <td>0.005738</td>\n",
              "      <td>0.003289</td>\n",
              "      <td>0.002608</td>\n",
              "      <td>0.007338</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007447</td>\n",
              "      <td>0.004465</td>\n",
              "      <td>0.006111</td>\n",
              "      <td>0.002246</td>\n",
              "      <td>0.002109</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>0.506213</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>1.000904</td>\n",
              "      <td>0.062492</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.001845</td>\n",
              "      <td>0.007816</td>\n",
              "      <td>0.002470</td>\n",
              "      <td>0.005516</td>\n",
              "      <td>0.007166</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.001504</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002019</td>\n",
              "      <td>0.002678</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007728</td>\n",
              "      <td>0.003432</td>\n",
              "      <td>0.002199</td>\n",
              "      <td>0.005511</td>\n",
              "      <td>0.004105</td>\n",
              "      <td>0.009656</td>\n",
              "      <td>1.006536</td>\n",
              "      <td>0.005158</td>\n",
              "      <td>0.003341</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>1.509905</td>\n",
              "      <td>1.002915</td>\n",
              "      <td>0.003079</td>\n",
              "      <td>0.003845</td>\n",
              "      <td>0.007190</td>\n",
              "      <td>0.002983</td>\n",
              "      <td>0.000535</td>\n",
              "      <td>0.921026</td>\n",
              "      <td>0.131620</td>\n",
              "      <td>0.933479</td>\n",
              "      <td>0.978027</td>\n",
              "      <td>0.018200</td>\n",
              "      <td>0.822281</td>\n",
              "      <td>1.006125</td>\n",
              "      <td>1.005735</td>\n",
              "      <td>0.953363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.673869</td>\n",
              "      <td>0.009998</td>\n",
              "      <td>0.017598</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.003175</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000130</td>\n",
              "      <td>0.120717</td>\n",
              "      <td>0.811199</td>\n",
              "      <td>0.008724</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.247939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.244199</td>\n",
              "      <td>0.242325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.705343</td>\n",
              "      <td>0.437433</td>\n",
              "      <td>0.002849</td>\n",
              "      <td>0.688774</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.009886</td>\n",
              "      <td>1.005053</td>\n",
              "      <td>1.008132</td>\n",
              "      <td>0.009823</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009680</td>\n",
              "      <td>0.004848</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006312</td>\n",
              "      <td>0.004462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003671</td>\n",
              "      <td>0.004946</td>\n",
              "      <td>0.008889</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>0.008126</td>\n",
              "      <td>0.009827</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         customer_ID        S_2       P_2  \\\n",
              "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-03-09  0.938469   \n",
              "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-04-07  0.936665   \n",
              "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-05-28  0.954180   \n",
              "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-06-13  0.960384   \n",
              "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-07-16  0.947248   \n",
              "\n",
              "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  D_42  \\\n",
              "0  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771  0.004709   NaN   \n",
              "1  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798  0.002714   NaN   \n",
              "2  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598  0.009423   NaN   \n",
              "3  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685  0.005531   NaN   \n",
              "4  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653  0.009312   NaN   \n",
              "\n",
              "   D_43      D_44       B_4      D_45       B_5       R_2      D_46      D_47  \\\n",
              "0   NaN  0.000630  0.080986  0.708906  0.170600  0.006204  0.358587  0.525351   \n",
              "1   NaN  0.002526  0.069419  0.712795  0.113239  0.006206  0.353630  0.521311   \n",
              "2   NaN  0.007605  0.068839  0.720884  0.060492  0.003259  0.334650  0.524568   \n",
              "3   NaN  0.006406  0.055630  0.723997  0.166782  0.009918  0.323271  0.530929   \n",
              "4   NaN  0.007731  0.038862  0.720619  0.143630  0.006667  0.231009  0.529305   \n",
              "\n",
              "       D_48  D_49       B_6       B_7       B_8      D_50      D_51       B_9  \\\n",
              "0  0.255736   NaN  0.063902  0.059416  0.006466  0.148698  1.335856  0.008207   \n",
              "1  0.223329   NaN  0.065261  0.057744  0.001614  0.149723  1.339794  0.008373   \n",
              "2  0.189424   NaN  0.066982  0.056647  0.005126  0.151955  1.337179  0.009355   \n",
              "3  0.135586   NaN  0.083720  0.049253  0.001418  0.151219  1.339909  0.006782   \n",
              "4       NaN   NaN  0.075900  0.048918  0.001199  0.154026  1.341735  0.000519   \n",
              "\n",
              "        R_3      D_52       P_3      B_10  D_53       S_5      B_11       S_6  \\\n",
              "0  0.001423  0.207334  0.736463  0.096219   NaN  0.023381  0.002768  0.008322   \n",
              "1  0.001984  0.202778  0.720886  0.099804   NaN  0.030599  0.002749  0.002482   \n",
              "2  0.007426  0.206629  0.738044  0.134073   NaN  0.048367  0.010077  0.000530   \n",
              "3  0.003515  0.208214  0.741813  0.134437   NaN  0.030063  0.009667  0.000783   \n",
              "4  0.001362  0.205468  0.691986  0.121518   NaN  0.054221  0.009484  0.006698   \n",
              "\n",
              "       D_54       R_4       S_7      B_12       S_8      D_55      D_56  \\\n",
              "0  1.001519  0.008298  0.161345  0.148266  0.922998  0.354596  0.152025   \n",
              "1  1.009033  0.005136  0.140951  0.143530  0.919414  0.326757  0.156201   \n",
              "2  1.009184  0.006961  0.112229  0.137014  1.001977  0.304124  0.153795   \n",
              "3  1.007456  0.008706  0.102838  0.129017  0.704016  0.275055  0.155772   \n",
              "4  1.003738  0.003846  0.094311  0.129539  0.917133  0.231110  0.154914   \n",
              "\n",
              "       B_13       R_5      D_58       S_9      B_14      D_59      D_60  \\\n",
              "0  0.118075  0.001882  0.158612  0.065728  0.018385  0.063646  0.199617   \n",
              "1  0.118737  0.001610  0.148459  0.093935  0.013035  0.065501  0.151387   \n",
              "2  0.114534  0.006328  0.139504  0.084757  0.056653  0.070607  0.305883   \n",
              "3  0.120740  0.004980  0.138100  0.048382  0.012498  0.065926  0.273553   \n",
              "4  0.095178  0.001653  0.126443  0.039259  0.027897  0.063697  0.233103   \n",
              "\n",
              "       D_61      B_15      S_11      D_62 D_63 D_64      D_65      B_16  B_17  \\\n",
              "0  0.308233  0.016361  0.401619  0.091071   CR    O  0.007126  0.007665   NaN   \n",
              "1  0.265026  0.017688  0.406326  0.086805   CR    O  0.002413  0.007148   NaN   \n",
              "2  0.212165  0.063955  0.406768  0.094001   CR    O  0.001878  0.003636   NaN   \n",
              "3  0.204300  0.022732  0.405175  0.094854   CR    O  0.005899  0.005896   NaN   \n",
              "4  0.175655  0.031171  0.487460  0.093915   CR    O  0.009479  0.001714   NaN   \n",
              "\n",
              "       B_18      B_19  D_66      B_20  D_68      S_12       R_6      S_13  \\\n",
              "0  0.652984  0.008520   NaN  0.004730   6.0  0.272008  0.008363  0.515222   \n",
              "1  0.647093  0.002238   NaN  0.003879   6.0  0.188970  0.004030  0.509048   \n",
              "2  0.645819  0.000408   NaN  0.004578   6.0  0.495308  0.006838  0.679257   \n",
              "3  0.654358  0.005897   NaN  0.005207   6.0  0.508670  0.008183  0.515282   \n",
              "4  0.650112  0.007773   NaN  0.005851   6.0  0.216507  0.008605  0.507712   \n",
              "\n",
              "       B_21      D_69      B_22      D_70      D_71      D_72      S_15  \\\n",
              "0  0.002644  0.009013  0.004808  0.008342  0.119403  0.004802  0.108271   \n",
              "1  0.004193  0.007842  0.001283  0.006524  0.140611  0.000094  0.101018   \n",
              "2  0.001337  0.006025  0.009393  0.002615  0.075868  0.007152  0.103239   \n",
              "3  0.008716  0.005271  0.004554  0.002052  0.150209  0.005364  0.206394   \n",
              "4  0.006821  0.000152  0.000104  0.001419  0.096441  0.007972  0.106020   \n",
              "\n",
              "       B_23  D_73       P_4      D_74      D_75  D_76      B_24       R_7  \\\n",
              "0  0.050882   NaN  0.007554  0.080422  0.069067   NaN  0.004327  0.007562   \n",
              "1  0.040469   NaN  0.004832  0.081413  0.074166   NaN  0.004203  0.005304   \n",
              "2  0.047454   NaN  0.006561  0.078891  0.076510   NaN  0.001782  0.001422   \n",
              "3  0.031705   NaN  0.009559  0.077490  0.071547   NaN  0.005595  0.006363   \n",
              "4  0.032733   NaN  0.008156  0.076561  0.074432   NaN  0.004933  0.004831   \n",
              "\n",
              "   D_77      B_25      B_26      D_78      D_79       R_8  R_9      S_16  \\\n",
              "0   NaN  0.007729  0.000272  0.001576  0.004239  0.001434  NaN  0.002271   \n",
              "1   NaN  0.001864  0.000979  0.009896  0.007597  0.000509  NaN  0.009810   \n",
              "2   NaN  0.005419  0.006149  0.009629  0.003094  0.008295  NaN  0.009362   \n",
              "3   NaN  0.000646  0.009193  0.008568  0.003895  0.005153  NaN  0.004876   \n",
              "4   NaN  0.001833  0.005738  0.003289  0.002608  0.007338  NaN  0.007447   \n",
              "\n",
              "       D_80      R_10      R_11      B_27      D_81      D_82      S_17  \\\n",
              "0  0.004061  0.007121  0.002456  0.002310  0.003532  0.506612  0.008033   \n",
              "1  0.000127  0.005966  0.000395  0.001327  0.007773  0.500855  0.000760   \n",
              "2  0.000954  0.005447  0.007345  0.007624  0.008811  0.504606  0.004056   \n",
              "3  0.005665  0.001888  0.004961  0.000034  0.004652  0.508998  0.006969   \n",
              "4  0.004465  0.006111  0.002246  0.002109  0.001141  0.506213  0.001770   \n",
              "\n",
              "       R_12      B_28      R_13      D_83      R_14      R_15      D_84  \\\n",
              "0  1.009825  0.084683  0.003820  0.007043  0.000438  0.006452  0.000830   \n",
              "1  1.009461  0.081843  0.000347  0.007789  0.004311  0.002332  0.009469   \n",
              "2  1.004291  0.081954  0.002709  0.004093  0.007139  0.008358  0.002325   \n",
              "3  1.004728  0.060634  0.009982  0.008817  0.008690  0.007364  0.005924   \n",
              "4  1.000904  0.062492  0.005860  0.001845  0.007816  0.002470  0.005516   \n",
              "\n",
              "       R_16  B_29  B_30      S_18      D_86  D_87      R_17      R_18  D_88  \\\n",
              "0  0.005055   NaN   0.0  0.005720  0.007084   NaN  0.000198  0.008907   NaN   \n",
              "1  0.003753   NaN   0.0  0.007584  0.006677   NaN  0.001142  0.005907   NaN   \n",
              "2  0.007381   NaN   0.0  0.005901  0.001185   NaN  0.008013  0.008882   NaN   \n",
              "3  0.008802   NaN   0.0  0.002520  0.003324   NaN  0.009455  0.008348   NaN   \n",
              "4  0.007166   NaN   0.0  0.000155  0.001504   NaN  0.002019  0.002678   NaN   \n",
              "\n",
              "   B_31      S_19      R_19      B_32      S_20      R_20      R_21      B_33  \\\n",
              "0     1  0.002537  0.005177  0.006626  0.009705  0.007782  0.002450  1.001101   \n",
              "1     1  0.008427  0.008979  0.001854  0.009924  0.005987  0.002247  1.006779   \n",
              "2     1  0.007327  0.002016  0.008686  0.008446  0.007291  0.007794  1.001014   \n",
              "3     1  0.007053  0.003909  0.002478  0.006614  0.009977  0.007686  1.002775   \n",
              "4     1  0.007728  0.003432  0.002199  0.005511  0.004105  0.009656  1.006536   \n",
              "\n",
              "       D_89      R_22      R_23      D_91      D_92      D_93      D_94  \\\n",
              "0  0.002665  0.007479  0.006893  1.503673  1.006133  0.003569  0.008871   \n",
              "1  0.002508  0.006827  0.002837  1.503577  1.005791  0.000571  0.000391   \n",
              "2  0.009634  0.009820  0.005080  1.503359  1.005801  0.007425  0.009234   \n",
              "3  0.007791  0.000458  0.007320  1.503701  1.007036  0.000664  0.003200   \n",
              "4  0.005158  0.003341  0.000264  1.509905  1.002915  0.003079  0.003845   \n",
              "\n",
              "       R_24      R_25      D_96      S_22      S_23      S_24      S_25  \\\n",
              "0  0.003950  0.003647  0.004950  0.894090  0.135561  0.911191  0.974539   \n",
              "1  0.008351  0.008850  0.003180  0.902135  0.136333  0.919876  0.975624   \n",
              "2  0.002471  0.009769  0.005433  0.939654  0.134938  0.958699  0.974067   \n",
              "3  0.008507  0.004858  0.000063  0.913205  0.140058  0.926341  0.975499   \n",
              "4  0.007190  0.002983  0.000535  0.921026  0.131620  0.933479  0.978027   \n",
              "\n",
              "       S_26     D_102     D_103     D_104     D_105  D_106     D_107  \\\n",
              "0  0.001243  0.766688  1.008691  1.004587  0.893734    NaN  0.670041   \n",
              "1  0.004561  0.786007  1.000084  1.004118  0.906841    NaN  0.668647   \n",
              "2  0.011736  0.806840  1.003014  1.009285  0.928719    NaN  0.670901   \n",
              "3  0.007571  0.808214  1.001517  1.004514  0.935383    NaN  0.672620   \n",
              "4  0.018200  0.822281  1.006125  1.005735  0.953363    NaN  0.673869   \n",
              "\n",
              "       B_36      B_37  R_26      R_27  B_38  D_108     D_109  D_110  D_111  \\\n",
              "0  0.009968  0.004572   NaN  1.008949   2.0    NaN  0.004326    NaN    NaN   \n",
              "1  0.003921  0.004654   NaN  1.003205   2.0    NaN  0.008707    NaN    NaN   \n",
              "2  0.001264  0.019176   NaN  1.000754   2.0    NaN  0.004092    NaN    NaN   \n",
              "3  0.002729  0.011720   NaN  1.005338   2.0    NaN  0.009703    NaN    NaN   \n",
              "4  0.009998  0.017598   NaN  1.003175   2.0    NaN  0.009120    NaN    NaN   \n",
              "\n",
              "   B_39     D_112      B_40      S_27     D_113  D_114     D_115  D_116  \\\n",
              "0   NaN  1.007336  0.210060  0.676922  0.007871    1.0  0.238250    0.0   \n",
              "1   NaN  1.007653  0.184093  0.822281  0.003444    1.0  0.247217    0.0   \n",
              "2   NaN  1.004312  0.154837  0.853498  0.003269    1.0  0.239867    0.0   \n",
              "3   NaN  1.002538  0.153939  0.844667  0.000053    1.0  0.240910    0.0   \n",
              "4   NaN  1.000130  0.120717  0.811199  0.008724    1.0  0.247939    0.0   \n",
              "\n",
              "   D_117     D_118     D_119  D_120     D_121     D_122     D_123     D_124  \\\n",
              "0    4.0  0.232120  0.236266    0.0  0.702280  0.434345  0.003057  0.686516   \n",
              "1    4.0  0.243532  0.241885    0.0  0.707017  0.430501  0.001306  0.686414   \n",
              "2    4.0  0.240768  0.239710    0.0  0.704843  0.434409  0.003954  0.690101   \n",
              "3    4.0  0.239400  0.240727    0.0  0.711546  0.436903  0.005135  0.687779   \n",
              "4    4.0  0.244199  0.242325    0.0  0.705343  0.437433  0.002849  0.688774   \n",
              "\n",
              "      D_125  D_126     D_127     D_128     D_129      B_41  B_42     D_130  \\\n",
              "0  0.008740    1.0  1.003319  1.007819  1.000080  0.006805   NaN  0.002052   \n",
              "1  0.000755    1.0  1.008394  1.004333  1.008344  0.004407   NaN  0.001034   \n",
              "2  0.009617    1.0  1.009307  1.007831  1.006878  0.003221   NaN  0.005681   \n",
              "3  0.004649    1.0  1.001671  1.003460  1.007573  0.007703   NaN  0.007108   \n",
              "4  0.000097    1.0  1.009886  1.005053  1.008132  0.009823   NaN  0.009680   \n",
              "\n",
              "      D_131  D_132     D_133      R_28  D_134  D_135  D_136  D_137  D_138  \\\n",
              "0  0.005972    NaN  0.004345  0.001535    NaN    NaN    NaN    NaN    NaN   \n",
              "1  0.004838    NaN  0.007495  0.004931    NaN    NaN    NaN    NaN    NaN   \n",
              "2  0.005497    NaN  0.009227  0.009123    NaN    NaN    NaN    NaN    NaN   \n",
              "3  0.008261    NaN  0.007206  0.002409    NaN    NaN    NaN    NaN    NaN   \n",
              "4  0.004848    NaN  0.006312  0.004462    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "      D_139     D_140     D_141  D_142     D_143     D_144     D_145  target  \n",
              "0  0.002427  0.003706  0.003818    NaN  0.000569  0.000610  0.002674       0  \n",
              "1  0.003954  0.003167  0.005032    NaN  0.009576  0.005492  0.009217       0  \n",
              "2  0.003269  0.007329  0.000427    NaN  0.003429  0.006986  0.002603       0  \n",
              "3  0.006117  0.004516  0.003200    NaN  0.008419  0.006527  0.009600       0  \n",
              "4  0.003671  0.004946  0.008889    NaN  0.001670  0.008126  0.009827       0  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge the Features and Labels (Target values) \n",
        "df = pd.merge(train, labels, on = 'customer_ID', how = 'left')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iioSjmzL6kEw",
        "outputId": "d43b5fbf-1a98-4145-b5e7-c26a377a0cac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5531451, 191)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape #check the shape of the final dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZMGwEmB6kEw",
        "outputId": "c11aae12-034d-47d7-abcf-527c57bc63e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "458913"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df['customer_ID'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqRk66Ds6kEx",
        "outputId": "ccd87dba-f0c0-4b0b-b32e-2af3c3250b34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13, 191)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[df['customer_ID'] == df.iloc[1,0], :].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfIuWqWp6kEx",
        "outputId": "28888957-8599-43db-f70d-0d98fecc6119"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12.053376130116165"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "5531451/458913"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BL0Np3x6kEx"
      },
      "source": [
        "### Randomly Selecting 1 month of data for each customer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJVfUn4k6kEx",
        "outputId": "41a11b4c-5a4f-4e5f-f419-40774720527c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min : 2017-03-01 00:00:00 Max:  2018-03-31 00:00:00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(458913, 191)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df12 = df.sample(frac=1, random_state = 21)  #shuffling the data\n",
        "\n",
        "#Grouping by the customer ID and selecting the first row\n",
        "df1 = df12.groupby('customer_ID',as_index=False).first()\n",
        "\n",
        "#checking the Minimum and Maximum Date for the data\n",
        "print(\"Min :\", df1['S_2'].min(), \"Max: \", df1['S_2'].max())\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5acdq7Au6kEx",
        "outputId": "085d63b5-8b2d-44e3-e598-e259749a7cdf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>P_2</th>\n",
              "      <th>D_39</th>\n",
              "      <th>B_1</th>\n",
              "      <th>B_2</th>\n",
              "      <th>R_1</th>\n",
              "      <th>S_3</th>\n",
              "      <th>D_41</th>\n",
              "      <th>B_3</th>\n",
              "      <th>D_42</th>\n",
              "      <th>D_43</th>\n",
              "      <th>D_44</th>\n",
              "      <th>B_4</th>\n",
              "      <th>D_45</th>\n",
              "      <th>B_5</th>\n",
              "      <th>R_2</th>\n",
              "      <th>D_46</th>\n",
              "      <th>D_47</th>\n",
              "      <th>D_48</th>\n",
              "      <th>D_49</th>\n",
              "      <th>B_6</th>\n",
              "      <th>B_7</th>\n",
              "      <th>B_8</th>\n",
              "      <th>D_50</th>\n",
              "      <th>D_51</th>\n",
              "      <th>B_9</th>\n",
              "      <th>R_3</th>\n",
              "      <th>D_52</th>\n",
              "      <th>P_3</th>\n",
              "      <th>B_10</th>\n",
              "      <th>D_53</th>\n",
              "      <th>S_5</th>\n",
              "      <th>B_11</th>\n",
              "      <th>S_6</th>\n",
              "      <th>D_54</th>\n",
              "      <th>R_4</th>\n",
              "      <th>S_7</th>\n",
              "      <th>B_12</th>\n",
              "      <th>S_8</th>\n",
              "      <th>D_55</th>\n",
              "      <th>D_56</th>\n",
              "      <th>B_13</th>\n",
              "      <th>R_5</th>\n",
              "      <th>D_58</th>\n",
              "      <th>S_9</th>\n",
              "      <th>B_14</th>\n",
              "      <th>D_59</th>\n",
              "      <th>D_60</th>\n",
              "      <th>D_61</th>\n",
              "      <th>B_15</th>\n",
              "      <th>S_11</th>\n",
              "      <th>D_62</th>\n",
              "      <th>D_63</th>\n",
              "      <th>D_64</th>\n",
              "      <th>D_65</th>\n",
              "      <th>B_16</th>\n",
              "      <th>B_17</th>\n",
              "      <th>B_18</th>\n",
              "      <th>B_19</th>\n",
              "      <th>D_66</th>\n",
              "      <th>B_20</th>\n",
              "      <th>D_68</th>\n",
              "      <th>S_12</th>\n",
              "      <th>R_6</th>\n",
              "      <th>S_13</th>\n",
              "      <th>B_21</th>\n",
              "      <th>D_69</th>\n",
              "      <th>B_22</th>\n",
              "      <th>D_70</th>\n",
              "      <th>D_71</th>\n",
              "      <th>D_72</th>\n",
              "      <th>S_15</th>\n",
              "      <th>B_23</th>\n",
              "      <th>D_73</th>\n",
              "      <th>P_4</th>\n",
              "      <th>D_74</th>\n",
              "      <th>D_75</th>\n",
              "      <th>D_76</th>\n",
              "      <th>B_24</th>\n",
              "      <th>R_7</th>\n",
              "      <th>D_77</th>\n",
              "      <th>B_25</th>\n",
              "      <th>B_26</th>\n",
              "      <th>D_78</th>\n",
              "      <th>D_79</th>\n",
              "      <th>R_8</th>\n",
              "      <th>R_9</th>\n",
              "      <th>S_16</th>\n",
              "      <th>D_80</th>\n",
              "      <th>R_10</th>\n",
              "      <th>R_11</th>\n",
              "      <th>B_27</th>\n",
              "      <th>D_81</th>\n",
              "      <th>D_82</th>\n",
              "      <th>S_17</th>\n",
              "      <th>R_12</th>\n",
              "      <th>B_28</th>\n",
              "      <th>R_13</th>\n",
              "      <th>D_83</th>\n",
              "      <th>R_14</th>\n",
              "      <th>R_15</th>\n",
              "      <th>D_84</th>\n",
              "      <th>R_16</th>\n",
              "      <th>B_29</th>\n",
              "      <th>B_30</th>\n",
              "      <th>S_18</th>\n",
              "      <th>D_86</th>\n",
              "      <th>D_87</th>\n",
              "      <th>R_17</th>\n",
              "      <th>R_18</th>\n",
              "      <th>D_88</th>\n",
              "      <th>B_31</th>\n",
              "      <th>S_19</th>\n",
              "      <th>R_19</th>\n",
              "      <th>B_32</th>\n",
              "      <th>S_20</th>\n",
              "      <th>R_20</th>\n",
              "      <th>R_21</th>\n",
              "      <th>B_33</th>\n",
              "      <th>D_89</th>\n",
              "      <th>R_22</th>\n",
              "      <th>R_23</th>\n",
              "      <th>D_91</th>\n",
              "      <th>D_92</th>\n",
              "      <th>D_93</th>\n",
              "      <th>D_94</th>\n",
              "      <th>R_24</th>\n",
              "      <th>R_25</th>\n",
              "      <th>D_96</th>\n",
              "      <th>S_22</th>\n",
              "      <th>S_23</th>\n",
              "      <th>S_24</th>\n",
              "      <th>S_25</th>\n",
              "      <th>S_26</th>\n",
              "      <th>D_102</th>\n",
              "      <th>D_103</th>\n",
              "      <th>D_104</th>\n",
              "      <th>D_105</th>\n",
              "      <th>D_106</th>\n",
              "      <th>D_107</th>\n",
              "      <th>B_36</th>\n",
              "      <th>B_37</th>\n",
              "      <th>R_26</th>\n",
              "      <th>R_27</th>\n",
              "      <th>B_38</th>\n",
              "      <th>D_108</th>\n",
              "      <th>D_109</th>\n",
              "      <th>D_110</th>\n",
              "      <th>D_111</th>\n",
              "      <th>B_39</th>\n",
              "      <th>D_112</th>\n",
              "      <th>B_40</th>\n",
              "      <th>S_27</th>\n",
              "      <th>D_113</th>\n",
              "      <th>D_114</th>\n",
              "      <th>D_115</th>\n",
              "      <th>D_116</th>\n",
              "      <th>D_117</th>\n",
              "      <th>D_118</th>\n",
              "      <th>D_119</th>\n",
              "      <th>D_120</th>\n",
              "      <th>D_121</th>\n",
              "      <th>D_122</th>\n",
              "      <th>D_123</th>\n",
              "      <th>D_124</th>\n",
              "      <th>D_125</th>\n",
              "      <th>D_126</th>\n",
              "      <th>D_127</th>\n",
              "      <th>D_128</th>\n",
              "      <th>D_129</th>\n",
              "      <th>B_41</th>\n",
              "      <th>B_42</th>\n",
              "      <th>D_130</th>\n",
              "      <th>D_131</th>\n",
              "      <th>D_132</th>\n",
              "      <th>D_133</th>\n",
              "      <th>R_28</th>\n",
              "      <th>D_134</th>\n",
              "      <th>D_135</th>\n",
              "      <th>D_136</th>\n",
              "      <th>D_137</th>\n",
              "      <th>D_138</th>\n",
              "      <th>D_139</th>\n",
              "      <th>D_140</th>\n",
              "      <th>D_141</th>\n",
              "      <th>D_142</th>\n",
              "      <th>D_143</th>\n",
              "      <th>D_144</th>\n",
              "      <th>D_145</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S_2</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-03-31</th>\n",
              "      <td>30730</td>\n",
              "      <td>30600</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>26787</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>4606</td>\n",
              "      <td>24965</td>\n",
              "      <td>29565</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>26658</td>\n",
              "      <td>30730</td>\n",
              "      <td>28845</td>\n",
              "      <td>3931</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30715</td>\n",
              "      <td>14705</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30676</td>\n",
              "      <td>30599</td>\n",
              "      <td>30730</td>\n",
              "      <td>10143</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>26787</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30674</td>\n",
              "      <td>17489</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>20853</td>\n",
              "      <td>30730</td>\n",
              "      <td>30680</td>\n",
              "      <td>30730</td>\n",
              "      <td>29206</td>\n",
              "      <td>30687</td>\n",
              "      <td>30730</td>\n",
              "      <td>28822</td>\n",
              "      <td>30730</td>\n",
              "      <td>30724</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>17104</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>4156</td>\n",
              "      <td>30730</td>\n",
              "      <td>30724</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30724</td>\n",
              "      <td>30730</td>\n",
              "      <td>30639</td>\n",
              "      <td>30730</td>\n",
              "      <td>30676</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>325</td>\n",
              "      <td>30730</td>\n",
              "      <td>30641</td>\n",
              "      <td>30730</td>\n",
              "      <td>4108</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>24320</td>\n",
              "      <td>30687</td>\n",
              "      <td>30730</td>\n",
              "      <td>29565</td>\n",
              "      <td>30631</td>\n",
              "      <td>30730</td>\n",
              "      <td>2442</td>\n",
              "      <td>30730</td>\n",
              "      <td>30641</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30694</td>\n",
              "      <td>9038</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30724</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30676</td>\n",
              "      <td>30730</td>\n",
              "      <td>2655</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>59</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>170</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30676</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30695</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30729</td>\n",
              "      <td>30730</td>\n",
              "      <td>30729</td>\n",
              "      <td>30726</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30631</td>\n",
              "      <td>30631</td>\n",
              "      <td>15821</td>\n",
              "      <td>3925</td>\n",
              "      <td>30631</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>3268</td>\n",
              "      <td>30329</td>\n",
              "      <td>30730</td>\n",
              "      <td>1383</td>\n",
              "      <td>30730</td>\n",
              "      <td>344</td>\n",
              "      <td>344</td>\n",
              "      <td>345</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>26216</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>30631</td>\n",
              "      <td>30631</td>\n",
              "      <td>30730</td>\n",
              "      <td>482</td>\n",
              "      <td>30631</td>\n",
              "      <td>30631</td>\n",
              "      <td>3931</td>\n",
              "      <td>30730</td>\n",
              "      <td>30730</td>\n",
              "      <td>2270</td>\n",
              "      <td>2270</td>\n",
              "      <td>2270</td>\n",
              "      <td>2270</td>\n",
              "      <td>2270</td>\n",
              "      <td>30631</td>\n",
              "      <td>30730</td>\n",
              "      <td>30631</td>\n",
              "      <td>5477</td>\n",
              "      <td>30631</td>\n",
              "      <td>30730</td>\n",
              "      <td>30631</td>\n",
              "      <td>30730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-04-30</th>\n",
              "      <td>31233</td>\n",
              "      <td>31097</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>27205</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>4907</td>\n",
              "      <td>25305</td>\n",
              "      <td>30024</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>26900</td>\n",
              "      <td>31233</td>\n",
              "      <td>29248</td>\n",
              "      <td>3970</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31216</td>\n",
              "      <td>14866</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31175</td>\n",
              "      <td>31106</td>\n",
              "      <td>31233</td>\n",
              "      <td>10274</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>27205</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31167</td>\n",
              "      <td>17580</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>21162</td>\n",
              "      <td>31233</td>\n",
              "      <td>31176</td>\n",
              "      <td>31233</td>\n",
              "      <td>29613</td>\n",
              "      <td>31186</td>\n",
              "      <td>31233</td>\n",
              "      <td>29154</td>\n",
              "      <td>31233</td>\n",
              "      <td>31226</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>17203</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>4159</td>\n",
              "      <td>31233</td>\n",
              "      <td>31226</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31226</td>\n",
              "      <td>31233</td>\n",
              "      <td>31141</td>\n",
              "      <td>31233</td>\n",
              "      <td>31175</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>362</td>\n",
              "      <td>31233</td>\n",
              "      <td>31142</td>\n",
              "      <td>31233</td>\n",
              "      <td>4087</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>24690</td>\n",
              "      <td>31186</td>\n",
              "      <td>31233</td>\n",
              "      <td>30024</td>\n",
              "      <td>31126</td>\n",
              "      <td>31233</td>\n",
              "      <td>2494</td>\n",
              "      <td>31233</td>\n",
              "      <td>31142</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31199</td>\n",
              "      <td>9012</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31226</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31175</td>\n",
              "      <td>31233</td>\n",
              "      <td>2667</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>62</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>154</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31175</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31191</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31232</td>\n",
              "      <td>31233</td>\n",
              "      <td>31232</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31126</td>\n",
              "      <td>31126</td>\n",
              "      <td>16191</td>\n",
              "      <td>3964</td>\n",
              "      <td>31126</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>3281</td>\n",
              "      <td>30830</td>\n",
              "      <td>31233</td>\n",
              "      <td>1457</td>\n",
              "      <td>31233</td>\n",
              "      <td>299</td>\n",
              "      <td>299</td>\n",
              "      <td>300</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>26683</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>31126</td>\n",
              "      <td>31126</td>\n",
              "      <td>31233</td>\n",
              "      <td>479</td>\n",
              "      <td>31126</td>\n",
              "      <td>31126</td>\n",
              "      <td>3970</td>\n",
              "      <td>31233</td>\n",
              "      <td>31233</td>\n",
              "      <td>2253</td>\n",
              "      <td>2253</td>\n",
              "      <td>2253</td>\n",
              "      <td>2253</td>\n",
              "      <td>2253</td>\n",
              "      <td>31126</td>\n",
              "      <td>31233</td>\n",
              "      <td>31126</td>\n",
              "      <td>5593</td>\n",
              "      <td>31126</td>\n",
              "      <td>31233</td>\n",
              "      <td>31126</td>\n",
              "      <td>31233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-05-31</th>\n",
              "      <td>31048</td>\n",
              "      <td>30901</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>27106</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>5182</td>\n",
              "      <td>25095</td>\n",
              "      <td>29842</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>26824</td>\n",
              "      <td>31048</td>\n",
              "      <td>29086</td>\n",
              "      <td>4030</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31029</td>\n",
              "      <td>14811</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>30987</td>\n",
              "      <td>30909</td>\n",
              "      <td>31048</td>\n",
              "      <td>10327</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>27106</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>30976</td>\n",
              "      <td>17402</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>21161</td>\n",
              "      <td>31048</td>\n",
              "      <td>30982</td>\n",
              "      <td>31048</td>\n",
              "      <td>29472</td>\n",
              "      <td>30988</td>\n",
              "      <td>31048</td>\n",
              "      <td>29031</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>17198</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>4171</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>30951</td>\n",
              "      <td>31048</td>\n",
              "      <td>30987</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>374</td>\n",
              "      <td>31048</td>\n",
              "      <td>30952</td>\n",
              "      <td>31048</td>\n",
              "      <td>4071</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>24521</td>\n",
              "      <td>30988</td>\n",
              "      <td>31048</td>\n",
              "      <td>29842</td>\n",
              "      <td>30934</td>\n",
              "      <td>31048</td>\n",
              "      <td>2563</td>\n",
              "      <td>31048</td>\n",
              "      <td>30952</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31009</td>\n",
              "      <td>8944</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>30987</td>\n",
              "      <td>31048</td>\n",
              "      <td>2327</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>67</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>144</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>30987</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31000</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31046</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>30934</td>\n",
              "      <td>30934</td>\n",
              "      <td>16014</td>\n",
              "      <td>4027</td>\n",
              "      <td>30934</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>3381</td>\n",
              "      <td>30637</td>\n",
              "      <td>31048</td>\n",
              "      <td>1431</td>\n",
              "      <td>31048</td>\n",
              "      <td>308</td>\n",
              "      <td>308</td>\n",
              "      <td>312</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>26598</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>30934</td>\n",
              "      <td>30934</td>\n",
              "      <td>31048</td>\n",
              "      <td>493</td>\n",
              "      <td>30934</td>\n",
              "      <td>30934</td>\n",
              "      <td>4030</td>\n",
              "      <td>31048</td>\n",
              "      <td>31048</td>\n",
              "      <td>2248</td>\n",
              "      <td>2248</td>\n",
              "      <td>2248</td>\n",
              "      <td>2248</td>\n",
              "      <td>2248</td>\n",
              "      <td>30934</td>\n",
              "      <td>31048</td>\n",
              "      <td>30934</td>\n",
              "      <td>5593</td>\n",
              "      <td>30934</td>\n",
              "      <td>31048</td>\n",
              "      <td>30934</td>\n",
              "      <td>31048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-30</th>\n",
              "      <td>31815</td>\n",
              "      <td>31683</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>27846</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>5885</td>\n",
              "      <td>25718</td>\n",
              "      <td>30623</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>27520</td>\n",
              "      <td>31815</td>\n",
              "      <td>29881</td>\n",
              "      <td>4187</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31793</td>\n",
              "      <td>14952</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31755</td>\n",
              "      <td>31683</td>\n",
              "      <td>31815</td>\n",
              "      <td>10632</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>27846</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31752</td>\n",
              "      <td>17718</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>21793</td>\n",
              "      <td>31815</td>\n",
              "      <td>31748</td>\n",
              "      <td>31815</td>\n",
              "      <td>30301</td>\n",
              "      <td>31755</td>\n",
              "      <td>31815</td>\n",
              "      <td>29836</td>\n",
              "      <td>31815</td>\n",
              "      <td>31809</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>17763</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>4234</td>\n",
              "      <td>31815</td>\n",
              "      <td>31807</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31812</td>\n",
              "      <td>31815</td>\n",
              "      <td>31732</td>\n",
              "      <td>31815</td>\n",
              "      <td>31755</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>446</td>\n",
              "      <td>31815</td>\n",
              "      <td>31732</td>\n",
              "      <td>31815</td>\n",
              "      <td>4069</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>25212</td>\n",
              "      <td>31755</td>\n",
              "      <td>31815</td>\n",
              "      <td>30623</td>\n",
              "      <td>31714</td>\n",
              "      <td>31815</td>\n",
              "      <td>2801</td>\n",
              "      <td>31815</td>\n",
              "      <td>31732</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31773</td>\n",
              "      <td>9042</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31812</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31755</td>\n",
              "      <td>31815</td>\n",
              "      <td>2557</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>68</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>156</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31755</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31767</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31813</td>\n",
              "      <td>31815</td>\n",
              "      <td>31813</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31713</td>\n",
              "      <td>31713</td>\n",
              "      <td>16558</td>\n",
              "      <td>4181</td>\n",
              "      <td>31713</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>3560</td>\n",
              "      <td>31439</td>\n",
              "      <td>31815</td>\n",
              "      <td>1483</td>\n",
              "      <td>31815</td>\n",
              "      <td>307</td>\n",
              "      <td>307</td>\n",
              "      <td>307</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>27327</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31812</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>31713</td>\n",
              "      <td>31713</td>\n",
              "      <td>31815</td>\n",
              "      <td>505</td>\n",
              "      <td>31713</td>\n",
              "      <td>31713</td>\n",
              "      <td>4187</td>\n",
              "      <td>31815</td>\n",
              "      <td>31815</td>\n",
              "      <td>2423</td>\n",
              "      <td>2423</td>\n",
              "      <td>2423</td>\n",
              "      <td>2423</td>\n",
              "      <td>2423</td>\n",
              "      <td>31713</td>\n",
              "      <td>31815</td>\n",
              "      <td>31713</td>\n",
              "      <td>5938</td>\n",
              "      <td>31713</td>\n",
              "      <td>31815</td>\n",
              "      <td>31713</td>\n",
              "      <td>31815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-07-31</th>\n",
              "      <td>32620</td>\n",
              "      <td>32491</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>28477</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>6541</td>\n",
              "      <td>26228</td>\n",
              "      <td>31410</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>28199</td>\n",
              "      <td>32620</td>\n",
              "      <td>30677</td>\n",
              "      <td>4321</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32594</td>\n",
              "      <td>15321</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32548</td>\n",
              "      <td>32486</td>\n",
              "      <td>32620</td>\n",
              "      <td>10505</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>28477</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32547</td>\n",
              "      <td>17996</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>22449</td>\n",
              "      <td>32620</td>\n",
              "      <td>32548</td>\n",
              "      <td>32620</td>\n",
              "      <td>31121</td>\n",
              "      <td>32549</td>\n",
              "      <td>32620</td>\n",
              "      <td>30600</td>\n",
              "      <td>32620</td>\n",
              "      <td>32609</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>17970</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>4366</td>\n",
              "      <td>32620</td>\n",
              "      <td>32609</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32614</td>\n",
              "      <td>32620</td>\n",
              "      <td>32520</td>\n",
              "      <td>32620</td>\n",
              "      <td>32548</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>489</td>\n",
              "      <td>32620</td>\n",
              "      <td>32522</td>\n",
              "      <td>32620</td>\n",
              "      <td>4049</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>26044</td>\n",
              "      <td>32549</td>\n",
              "      <td>32620</td>\n",
              "      <td>31410</td>\n",
              "      <td>32501</td>\n",
              "      <td>32620</td>\n",
              "      <td>2769</td>\n",
              "      <td>32620</td>\n",
              "      <td>32522</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32576</td>\n",
              "      <td>9192</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32614</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32548</td>\n",
              "      <td>32620</td>\n",
              "      <td>2608</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>60</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>203</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32548</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32566</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32617</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32501</td>\n",
              "      <td>32501</td>\n",
              "      <td>16889</td>\n",
              "      <td>4312</td>\n",
              "      <td>32501</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>3720</td>\n",
              "      <td>32176</td>\n",
              "      <td>32620</td>\n",
              "      <td>1629</td>\n",
              "      <td>32620</td>\n",
              "      <td>314</td>\n",
              "      <td>314</td>\n",
              "      <td>314</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>27942</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32614</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>32501</td>\n",
              "      <td>32501</td>\n",
              "      <td>32620</td>\n",
              "      <td>431</td>\n",
              "      <td>32501</td>\n",
              "      <td>32501</td>\n",
              "      <td>4319</td>\n",
              "      <td>32620</td>\n",
              "      <td>32620</td>\n",
              "      <td>2453</td>\n",
              "      <td>2453</td>\n",
              "      <td>2453</td>\n",
              "      <td>2453</td>\n",
              "      <td>2453</td>\n",
              "      <td>32501</td>\n",
              "      <td>32620</td>\n",
              "      <td>32501</td>\n",
              "      <td>6049</td>\n",
              "      <td>32501</td>\n",
              "      <td>32620</td>\n",
              "      <td>32501</td>\n",
              "      <td>32620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-31</th>\n",
              "      <td>33253</td>\n",
              "      <td>33131</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>29175</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>7147</td>\n",
              "      <td>26644</td>\n",
              "      <td>32039</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>28736</td>\n",
              "      <td>33253</td>\n",
              "      <td>31272</td>\n",
              "      <td>4480</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33239</td>\n",
              "      <td>15530</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33190</td>\n",
              "      <td>33125</td>\n",
              "      <td>33253</td>\n",
              "      <td>10861</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>29175</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33191</td>\n",
              "      <td>18210</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>23063</td>\n",
              "      <td>33253</td>\n",
              "      <td>33196</td>\n",
              "      <td>33253</td>\n",
              "      <td>31696</td>\n",
              "      <td>33201</td>\n",
              "      <td>33253</td>\n",
              "      <td>31214</td>\n",
              "      <td>33253</td>\n",
              "      <td>33235</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>18362</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>4382</td>\n",
              "      <td>33253</td>\n",
              "      <td>33237</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33247</td>\n",
              "      <td>33253</td>\n",
              "      <td>33162</td>\n",
              "      <td>33253</td>\n",
              "      <td>33190</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>523</td>\n",
              "      <td>33253</td>\n",
              "      <td>33165</td>\n",
              "      <td>33253</td>\n",
              "      <td>4130</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>26539</td>\n",
              "      <td>33201</td>\n",
              "      <td>33253</td>\n",
              "      <td>32039</td>\n",
              "      <td>33133</td>\n",
              "      <td>33253</td>\n",
              "      <td>2901</td>\n",
              "      <td>33253</td>\n",
              "      <td>33165</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33213</td>\n",
              "      <td>9393</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33247</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33190</td>\n",
              "      <td>33253</td>\n",
              "      <td>2696</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>70</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>193</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33190</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33214</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33251</td>\n",
              "      <td>33253</td>\n",
              "      <td>33251</td>\n",
              "      <td>33251</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33133</td>\n",
              "      <td>33133</td>\n",
              "      <td>17288</td>\n",
              "      <td>4474</td>\n",
              "      <td>33133</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>3954</td>\n",
              "      <td>32825</td>\n",
              "      <td>33253</td>\n",
              "      <td>1599</td>\n",
              "      <td>33253</td>\n",
              "      <td>320</td>\n",
              "      <td>320</td>\n",
              "      <td>323</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>28638</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33246</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>33133</td>\n",
              "      <td>33133</td>\n",
              "      <td>33253</td>\n",
              "      <td>473</td>\n",
              "      <td>33133</td>\n",
              "      <td>33133</td>\n",
              "      <td>4480</td>\n",
              "      <td>33253</td>\n",
              "      <td>33253</td>\n",
              "      <td>2620</td>\n",
              "      <td>2620</td>\n",
              "      <td>2620</td>\n",
              "      <td>2620</td>\n",
              "      <td>2620</td>\n",
              "      <td>33133</td>\n",
              "      <td>33253</td>\n",
              "      <td>33133</td>\n",
              "      <td>6244</td>\n",
              "      <td>33133</td>\n",
              "      <td>33253</td>\n",
              "      <td>33133</td>\n",
              "      <td>33253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-09-30</th>\n",
              "      <td>33427</td>\n",
              "      <td>33314</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>29398</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>7648</td>\n",
              "      <td>26894</td>\n",
              "      <td>32204</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>28951</td>\n",
              "      <td>33427</td>\n",
              "      <td>31441</td>\n",
              "      <td>4546</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33416</td>\n",
              "      <td>15487</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33384</td>\n",
              "      <td>33303</td>\n",
              "      <td>33427</td>\n",
              "      <td>10955</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>29398</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33381</td>\n",
              "      <td>18067</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>23206</td>\n",
              "      <td>33427</td>\n",
              "      <td>33389</td>\n",
              "      <td>33427</td>\n",
              "      <td>31941</td>\n",
              "      <td>33391</td>\n",
              "      <td>33427</td>\n",
              "      <td>31408</td>\n",
              "      <td>33427</td>\n",
              "      <td>33388</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>18540</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>4446</td>\n",
              "      <td>33427</td>\n",
              "      <td>33390</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33409</td>\n",
              "      <td>33427</td>\n",
              "      <td>33355</td>\n",
              "      <td>33427</td>\n",
              "      <td>33384</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>571</td>\n",
              "      <td>33427</td>\n",
              "      <td>33365</td>\n",
              "      <td>33427</td>\n",
              "      <td>4251</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>26975</td>\n",
              "      <td>33391</td>\n",
              "      <td>33427</td>\n",
              "      <td>32204</td>\n",
              "      <td>33338</td>\n",
              "      <td>33427</td>\n",
              "      <td>2909</td>\n",
              "      <td>33427</td>\n",
              "      <td>33365</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33396</td>\n",
              "      <td>9125</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33409</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33384</td>\n",
              "      <td>33427</td>\n",
              "      <td>2683</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>65</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>173</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33384</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33399</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33426</td>\n",
              "      <td>33427</td>\n",
              "      <td>33426</td>\n",
              "      <td>33425</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33338</td>\n",
              "      <td>33338</td>\n",
              "      <td>17432</td>\n",
              "      <td>4542</td>\n",
              "      <td>33338</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>4025</td>\n",
              "      <td>32987</td>\n",
              "      <td>33427</td>\n",
              "      <td>1548</td>\n",
              "      <td>33427</td>\n",
              "      <td>323</td>\n",
              "      <td>323</td>\n",
              "      <td>325</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>28864</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33411</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>33338</td>\n",
              "      <td>33338</td>\n",
              "      <td>33427</td>\n",
              "      <td>508</td>\n",
              "      <td>33338</td>\n",
              "      <td>33338</td>\n",
              "      <td>4546</td>\n",
              "      <td>33427</td>\n",
              "      <td>33427</td>\n",
              "      <td>2635</td>\n",
              "      <td>2635</td>\n",
              "      <td>2635</td>\n",
              "      <td>2635</td>\n",
              "      <td>2635</td>\n",
              "      <td>33338</td>\n",
              "      <td>33427</td>\n",
              "      <td>33338</td>\n",
              "      <td>6237</td>\n",
              "      <td>33338</td>\n",
              "      <td>33427</td>\n",
              "      <td>33338</td>\n",
              "      <td>33427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-31</th>\n",
              "      <td>34439</td>\n",
              "      <td>34294</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>30296</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>8438</td>\n",
              "      <td>27355</td>\n",
              "      <td>33103</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>29708</td>\n",
              "      <td>34439</td>\n",
              "      <td>32338</td>\n",
              "      <td>4724</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34417</td>\n",
              "      <td>15778</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34375</td>\n",
              "      <td>34254</td>\n",
              "      <td>34439</td>\n",
              "      <td>11028</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>30296</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34373</td>\n",
              "      <td>18595</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>23988</td>\n",
              "      <td>34439</td>\n",
              "      <td>34381</td>\n",
              "      <td>34439</td>\n",
              "      <td>32877</td>\n",
              "      <td>34384</td>\n",
              "      <td>34439</td>\n",
              "      <td>32247</td>\n",
              "      <td>34439</td>\n",
              "      <td>34395</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>18707</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>4494</td>\n",
              "      <td>34439</td>\n",
              "      <td>34396</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34425</td>\n",
              "      <td>34439</td>\n",
              "      <td>34337</td>\n",
              "      <td>34439</td>\n",
              "      <td>34375</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>637</td>\n",
              "      <td>34439</td>\n",
              "      <td>34344</td>\n",
              "      <td>34439</td>\n",
              "      <td>4355</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>27811</td>\n",
              "      <td>34384</td>\n",
              "      <td>34439</td>\n",
              "      <td>33103</td>\n",
              "      <td>34322</td>\n",
              "      <td>34439</td>\n",
              "      <td>3029</td>\n",
              "      <td>34439</td>\n",
              "      <td>34344</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34395</td>\n",
              "      <td>9432</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34425</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34375</td>\n",
              "      <td>34439</td>\n",
              "      <td>2678</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>69</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>210</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34375</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34399</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34437</td>\n",
              "      <td>34439</td>\n",
              "      <td>34437</td>\n",
              "      <td>34438</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34322</td>\n",
              "      <td>34322</td>\n",
              "      <td>17864</td>\n",
              "      <td>4718</td>\n",
              "      <td>34322</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>4150</td>\n",
              "      <td>33941</td>\n",
              "      <td>34439</td>\n",
              "      <td>1712</td>\n",
              "      <td>34439</td>\n",
              "      <td>293</td>\n",
              "      <td>293</td>\n",
              "      <td>294</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>29787</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34425</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>34322</td>\n",
              "      <td>34322</td>\n",
              "      <td>34439</td>\n",
              "      <td>486</td>\n",
              "      <td>34322</td>\n",
              "      <td>34322</td>\n",
              "      <td>4724</td>\n",
              "      <td>34439</td>\n",
              "      <td>34439</td>\n",
              "      <td>2746</td>\n",
              "      <td>2746</td>\n",
              "      <td>2746</td>\n",
              "      <td>2746</td>\n",
              "      <td>2746</td>\n",
              "      <td>34322</td>\n",
              "      <td>34439</td>\n",
              "      <td>34322</td>\n",
              "      <td>6416</td>\n",
              "      <td>34322</td>\n",
              "      <td>34439</td>\n",
              "      <td>34322</td>\n",
              "      <td>34439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-11-30</th>\n",
              "      <td>35664</td>\n",
              "      <td>35550</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>31552</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>9465</td>\n",
              "      <td>28037</td>\n",
              "      <td>34470</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>30477</td>\n",
              "      <td>35664</td>\n",
              "      <td>33620</td>\n",
              "      <td>4835</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35662</td>\n",
              "      <td>16203</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35643</td>\n",
              "      <td>35224</td>\n",
              "      <td>35664</td>\n",
              "      <td>11380</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>31552</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35645</td>\n",
              "      <td>18809</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>24996</td>\n",
              "      <td>35664</td>\n",
              "      <td>35660</td>\n",
              "      <td>35664</td>\n",
              "      <td>34193</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>33509</td>\n",
              "      <td>35664</td>\n",
              "      <td>35585</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>19466</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>4714</td>\n",
              "      <td>35664</td>\n",
              "      <td>35591</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35643</td>\n",
              "      <td>35664</td>\n",
              "      <td>35604</td>\n",
              "      <td>35664</td>\n",
              "      <td>35643</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>753</td>\n",
              "      <td>35664</td>\n",
              "      <td>35620</td>\n",
              "      <td>35664</td>\n",
              "      <td>4234</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>29005</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>34470</td>\n",
              "      <td>35588</td>\n",
              "      <td>35664</td>\n",
              "      <td>3163</td>\n",
              "      <td>35664</td>\n",
              "      <td>35620</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35647</td>\n",
              "      <td>9593</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35643</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35643</td>\n",
              "      <td>35664</td>\n",
              "      <td>2812</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>59</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>192</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35643</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35527</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35662</td>\n",
              "      <td>35664</td>\n",
              "      <td>35662</td>\n",
              "      <td>35660</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35588</td>\n",
              "      <td>35588</td>\n",
              "      <td>18460</td>\n",
              "      <td>4826</td>\n",
              "      <td>35588</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>4413</td>\n",
              "      <td>35205</td>\n",
              "      <td>35664</td>\n",
              "      <td>1702</td>\n",
              "      <td>35664</td>\n",
              "      <td>334</td>\n",
              "      <td>334</td>\n",
              "      <td>337</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>30943</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35643</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>35588</td>\n",
              "      <td>35588</td>\n",
              "      <td>35664</td>\n",
              "      <td>494</td>\n",
              "      <td>35588</td>\n",
              "      <td>35588</td>\n",
              "      <td>4835</td>\n",
              "      <td>35664</td>\n",
              "      <td>35664</td>\n",
              "      <td>2871</td>\n",
              "      <td>2871</td>\n",
              "      <td>2871</td>\n",
              "      <td>2871</td>\n",
              "      <td>2871</td>\n",
              "      <td>35588</td>\n",
              "      <td>35664</td>\n",
              "      <td>35588</td>\n",
              "      <td>6738</td>\n",
              "      <td>35588</td>\n",
              "      <td>35664</td>\n",
              "      <td>35588</td>\n",
              "      <td>35664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31</th>\n",
              "      <td>36977</td>\n",
              "      <td>36885</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>32729</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>10632</td>\n",
              "      <td>28646</td>\n",
              "      <td>35637</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>30778</td>\n",
              "      <td>36977</td>\n",
              "      <td>34708</td>\n",
              "      <td>5078</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36972</td>\n",
              "      <td>16655</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36967</td>\n",
              "      <td>35710</td>\n",
              "      <td>36977</td>\n",
              "      <td>11456</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>32729</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36963</td>\n",
              "      <td>19491</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>25836</td>\n",
              "      <td>36977</td>\n",
              "      <td>36971</td>\n",
              "      <td>36977</td>\n",
              "      <td>35400</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>34642</td>\n",
              "      <td>36977</td>\n",
              "      <td>36906</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>19753</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>4845</td>\n",
              "      <td>36977</td>\n",
              "      <td>36903</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36947</td>\n",
              "      <td>36977</td>\n",
              "      <td>36921</td>\n",
              "      <td>36977</td>\n",
              "      <td>36967</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>825</td>\n",
              "      <td>36977</td>\n",
              "      <td>36947</td>\n",
              "      <td>36977</td>\n",
              "      <td>4216</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>30060</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>35637</td>\n",
              "      <td>36919</td>\n",
              "      <td>36977</td>\n",
              "      <td>3327</td>\n",
              "      <td>36977</td>\n",
              "      <td>36947</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36968</td>\n",
              "      <td>9690</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36947</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36967</td>\n",
              "      <td>36977</td>\n",
              "      <td>2785</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>83</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>203</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36967</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36786</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36974</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36919</td>\n",
              "      <td>36919</td>\n",
              "      <td>19327</td>\n",
              "      <td>5072</td>\n",
              "      <td>36919</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>4316</td>\n",
              "      <td>35375</td>\n",
              "      <td>36977</td>\n",
              "      <td>1676</td>\n",
              "      <td>36977</td>\n",
              "      <td>291</td>\n",
              "      <td>291</td>\n",
              "      <td>291</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>32118</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36948</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>36919</td>\n",
              "      <td>36919</td>\n",
              "      <td>36977</td>\n",
              "      <td>555</td>\n",
              "      <td>36919</td>\n",
              "      <td>36919</td>\n",
              "      <td>5078</td>\n",
              "      <td>36977</td>\n",
              "      <td>36977</td>\n",
              "      <td>2847</td>\n",
              "      <td>2847</td>\n",
              "      <td>2847</td>\n",
              "      <td>2847</td>\n",
              "      <td>2847</td>\n",
              "      <td>36919</td>\n",
              "      <td>36977</td>\n",
              "      <td>36919</td>\n",
              "      <td>7058</td>\n",
              "      <td>36919</td>\n",
              "      <td>36977</td>\n",
              "      <td>36919</td>\n",
              "      <td>36977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-31</th>\n",
              "      <td>38957</td>\n",
              "      <td>38745</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>34485</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>12200</td>\n",
              "      <td>29596</td>\n",
              "      <td>37454</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>31198</td>\n",
              "      <td>38957</td>\n",
              "      <td>36525</td>\n",
              "      <td>5480</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38828</td>\n",
              "      <td>17018</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38878</td>\n",
              "      <td>36137</td>\n",
              "      <td>38957</td>\n",
              "      <td>11790</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>34485</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38712</td>\n",
              "      <td>19882</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>27302</td>\n",
              "      <td>38957</td>\n",
              "      <td>38880</td>\n",
              "      <td>38957</td>\n",
              "      <td>37301</td>\n",
              "      <td>38885</td>\n",
              "      <td>38957</td>\n",
              "      <td>36283</td>\n",
              "      <td>38957</td>\n",
              "      <td>38751</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>20313</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>5018</td>\n",
              "      <td>38957</td>\n",
              "      <td>38752</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38822</td>\n",
              "      <td>38957</td>\n",
              "      <td>38722</td>\n",
              "      <td>38957</td>\n",
              "      <td>38878</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>935</td>\n",
              "      <td>38957</td>\n",
              "      <td>38818</td>\n",
              "      <td>38957</td>\n",
              "      <td>4355</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>31730</td>\n",
              "      <td>38885</td>\n",
              "      <td>38957</td>\n",
              "      <td>37454</td>\n",
              "      <td>38804</td>\n",
              "      <td>38957</td>\n",
              "      <td>3436</td>\n",
              "      <td>38957</td>\n",
              "      <td>38818</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38904</td>\n",
              "      <td>9942</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38822</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38878</td>\n",
              "      <td>38957</td>\n",
              "      <td>3191</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>51</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>195</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38878</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>37626</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38953</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38804</td>\n",
              "      <td>38804</td>\n",
              "      <td>20155</td>\n",
              "      <td>5477</td>\n",
              "      <td>38804</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>4423</td>\n",
              "      <td>35495</td>\n",
              "      <td>38957</td>\n",
              "      <td>1800</td>\n",
              "      <td>38957</td>\n",
              "      <td>330</td>\n",
              "      <td>330</td>\n",
              "      <td>331</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>33861</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38825</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>38804</td>\n",
              "      <td>38804</td>\n",
              "      <td>38957</td>\n",
              "      <td>492</td>\n",
              "      <td>38804</td>\n",
              "      <td>38804</td>\n",
              "      <td>5480</td>\n",
              "      <td>38957</td>\n",
              "      <td>38957</td>\n",
              "      <td>2990</td>\n",
              "      <td>2990</td>\n",
              "      <td>2990</td>\n",
              "      <td>2990</td>\n",
              "      <td>2990</td>\n",
              "      <td>38804</td>\n",
              "      <td>38957</td>\n",
              "      <td>38804</td>\n",
              "      <td>7464</td>\n",
              "      <td>38804</td>\n",
              "      <td>38957</td>\n",
              "      <td>38804</td>\n",
              "      <td>38957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-02-28</th>\n",
              "      <td>41614</td>\n",
              "      <td>41336</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>37024</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>13981</td>\n",
              "      <td>30152</td>\n",
              "      <td>39995</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>31405</td>\n",
              "      <td>41614</td>\n",
              "      <td>38912</td>\n",
              "      <td>5811</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41020</td>\n",
              "      <td>18230</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41502</td>\n",
              "      <td>36220</td>\n",
              "      <td>41614</td>\n",
              "      <td>12059</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>37024</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41106</td>\n",
              "      <td>20848</td>\n",
              "      <td>41389</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>28516</td>\n",
              "      <td>41614</td>\n",
              "      <td>41032</td>\n",
              "      <td>41614</td>\n",
              "      <td>39874</td>\n",
              "      <td>41563</td>\n",
              "      <td>41614</td>\n",
              "      <td>38643</td>\n",
              "      <td>41614</td>\n",
              "      <td>40462</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>21002</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>5221</td>\n",
              "      <td>41614</td>\n",
              "      <td>40467</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>40567</td>\n",
              "      <td>41614</td>\n",
              "      <td>40908</td>\n",
              "      <td>41614</td>\n",
              "      <td>41503</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>899</td>\n",
              "      <td>41614</td>\n",
              "      <td>41432</td>\n",
              "      <td>41614</td>\n",
              "      <td>4709</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>33940</td>\n",
              "      <td>41563</td>\n",
              "      <td>41614</td>\n",
              "      <td>39995</td>\n",
              "      <td>41393</td>\n",
              "      <td>41614</td>\n",
              "      <td>3579</td>\n",
              "      <td>41614</td>\n",
              "      <td>41432</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41523</td>\n",
              "      <td>10293</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>40567</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41502</td>\n",
              "      <td>41614</td>\n",
              "      <td>3580</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>58</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>221</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41502</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>38398</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41611</td>\n",
              "      <td>41614</td>\n",
              "      <td>41611</td>\n",
              "      <td>41610</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41388</td>\n",
              "      <td>41388</td>\n",
              "      <td>21211</td>\n",
              "      <td>5808</td>\n",
              "      <td>41388</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>4429</td>\n",
              "      <td>35252</td>\n",
              "      <td>41614</td>\n",
              "      <td>1736</td>\n",
              "      <td>41614</td>\n",
              "      <td>316</td>\n",
              "      <td>316</td>\n",
              "      <td>318</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>36258</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>40570</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>41388</td>\n",
              "      <td>41388</td>\n",
              "      <td>41614</td>\n",
              "      <td>567</td>\n",
              "      <td>41388</td>\n",
              "      <td>41388</td>\n",
              "      <td>5812</td>\n",
              "      <td>41614</td>\n",
              "      <td>41614</td>\n",
              "      <td>2987</td>\n",
              "      <td>2987</td>\n",
              "      <td>2987</td>\n",
              "      <td>2987</td>\n",
              "      <td>2987</td>\n",
              "      <td>41388</td>\n",
              "      <td>41614</td>\n",
              "      <td>41388</td>\n",
              "      <td>7951</td>\n",
              "      <td>41388</td>\n",
              "      <td>41614</td>\n",
              "      <td>41388</td>\n",
              "      <td>41614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-03-31</th>\n",
              "      <td>47136</td>\n",
              "      <td>46452</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47105</td>\n",
              "      <td>47136</td>\n",
              "      <td>40237</td>\n",
              "      <td>47105</td>\n",
              "      <td>47105</td>\n",
              "      <td>16892</td>\n",
              "      <td>31203</td>\n",
              "      <td>44982</td>\n",
              "      <td>47136</td>\n",
              "      <td>47105</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>31591</td>\n",
              "      <td>47136</td>\n",
              "      <td>43544</td>\n",
              "      <td>6222</td>\n",
              "      <td>47096</td>\n",
              "      <td>47136</td>\n",
              "      <td>45033</td>\n",
              "      <td>20336</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>46690</td>\n",
              "      <td>36631</td>\n",
              "      <td>47136</td>\n",
              "      <td>12646</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47105</td>\n",
              "      <td>47136</td>\n",
              "      <td>40237</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>45948</td>\n",
              "      <td>22512</td>\n",
              "      <td>45798</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>29354</td>\n",
              "      <td>47136</td>\n",
              "      <td>44474</td>\n",
              "      <td>47136</td>\n",
              "      <td>44835</td>\n",
              "      <td>47079</td>\n",
              "      <td>47136</td>\n",
              "      <td>43174</td>\n",
              "      <td>47136</td>\n",
              "      <td>43496</td>\n",
              "      <td>47136</td>\n",
              "      <td>47105</td>\n",
              "      <td>22102</td>\n",
              "      <td>47136</td>\n",
              "      <td>47105</td>\n",
              "      <td>5570</td>\n",
              "      <td>47105</td>\n",
              "      <td>43512</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>43642</td>\n",
              "      <td>47105</td>\n",
              "      <td>44803</td>\n",
              "      <td>47136</td>\n",
              "      <td>46704</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>869</td>\n",
              "      <td>47136</td>\n",
              "      <td>46638</td>\n",
              "      <td>47136</td>\n",
              "      <td>5287</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>37378</td>\n",
              "      <td>47079</td>\n",
              "      <td>47105</td>\n",
              "      <td>44982</td>\n",
              "      <td>45991</td>\n",
              "      <td>47136</td>\n",
              "      <td>4123</td>\n",
              "      <td>47136</td>\n",
              "      <td>46638</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47105</td>\n",
              "      <td>46714</td>\n",
              "      <td>10789</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>43642</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>46690</td>\n",
              "      <td>47136</td>\n",
              "      <td>3574</td>\n",
              "      <td>47105</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>58</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>205</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47105</td>\n",
              "      <td>46690</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>39560</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>47032</td>\n",
              "      <td>47135</td>\n",
              "      <td>47033</td>\n",
              "      <td>47120</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>45984</td>\n",
              "      <td>45984</td>\n",
              "      <td>23644</td>\n",
              "      <td>6211</td>\n",
              "      <td>45984</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>4346</td>\n",
              "      <td>35434</td>\n",
              "      <td>47105</td>\n",
              "      <td>1774</td>\n",
              "      <td>47105</td>\n",
              "      <td>308</td>\n",
              "      <td>308</td>\n",
              "      <td>309</td>\n",
              "      <td>47105</td>\n",
              "      <td>47136</td>\n",
              "      <td>37941</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>43669</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>45984</td>\n",
              "      <td>45984</td>\n",
              "      <td>47136</td>\n",
              "      <td>544</td>\n",
              "      <td>45984</td>\n",
              "      <td>45984</td>\n",
              "      <td>6221</td>\n",
              "      <td>47136</td>\n",
              "      <td>47136</td>\n",
              "      <td>3213</td>\n",
              "      <td>3213</td>\n",
              "      <td>3213</td>\n",
              "      <td>3213</td>\n",
              "      <td>3213</td>\n",
              "      <td>45984</td>\n",
              "      <td>47136</td>\n",
              "      <td>45984</td>\n",
              "      <td>8822</td>\n",
              "      <td>45984</td>\n",
              "      <td>47136</td>\n",
              "      <td>45984</td>\n",
              "      <td>47136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            customer_ID    P_2   D_39    B_1    B_2    R_1    S_3   D_41  \\\n",
              "S_2                                                                        \n",
              "2017-03-31        30730  30600  30730  30730  30730  30730  26787  30730   \n",
              "2017-04-30        31233  31097  31233  31233  31233  31233  27205  31233   \n",
              "2017-05-31        31048  30901  31048  31048  31048  31048  27106  31048   \n",
              "2017-06-30        31815  31683  31815  31815  31815  31815  27846  31815   \n",
              "2017-07-31        32620  32491  32620  32620  32620  32620  28477  32620   \n",
              "2017-08-31        33253  33131  33253  33253  33253  33253  29175  33253   \n",
              "2017-09-30        33427  33314  33427  33427  33427  33427  29398  33427   \n",
              "2017-10-31        34439  34294  34439  34439  34439  34439  30296  34439   \n",
              "2017-11-30        35664  35550  35664  35664  35664  35664  31552  35664   \n",
              "2017-12-31        36977  36885  36977  36977  36977  36977  32729  36977   \n",
              "2018-01-31        38957  38745  38957  38957  38957  38957  34485  38957   \n",
              "2018-02-28        41614  41336  41614  41614  41614  41614  37024  41614   \n",
              "2018-03-31        47136  46452  47136  47136  47105  47136  40237  47105   \n",
              "\n",
              "              B_3   D_42   D_43   D_44    B_4   D_45    B_5    R_2   D_46  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730   4606  24965  29565  30730  30730  30730  30730  26658   \n",
              "2017-04-30  31233   4907  25305  30024  31233  31233  31233  31233  26900   \n",
              "2017-05-31  31048   5182  25095  29842  31048  31048  31048  31048  26824   \n",
              "2017-06-30  31815   5885  25718  30623  31815  31815  31815  31815  27520   \n",
              "2017-07-31  32620   6541  26228  31410  32620  32620  32620  32620  28199   \n",
              "2017-08-31  33253   7147  26644  32039  33253  33253  33253  33253  28736   \n",
              "2017-09-30  33427   7648  26894  32204  33427  33427  33427  33427  28951   \n",
              "2017-10-31  34439   8438  27355  33103  34439  34439  34439  34439  29708   \n",
              "2017-11-30  35664   9465  28037  34470  35664  35664  35664  35664  30477   \n",
              "2017-12-31  36977  10632  28646  35637  36977  36977  36977  36977  30778   \n",
              "2018-01-31  38957  12200  29596  37454  38957  38957  38957  38957  31198   \n",
              "2018-02-28  41614  13981  30152  39995  41614  41614  41614  41614  31405   \n",
              "2018-03-31  47105  16892  31203  44982  47136  47105  47136  47136  31591   \n",
              "\n",
              "             D_47   D_48  D_49    B_6    B_7    B_8   D_50   D_51    B_9  \\\n",
              "S_2                                                                        \n",
              "2017-03-31  30730  28845  3931  30730  30730  30715  14705  30730  30730   \n",
              "2017-04-30  31233  29248  3970  31233  31233  31216  14866  31233  31233   \n",
              "2017-05-31  31048  29086  4030  31048  31048  31029  14811  31048  31048   \n",
              "2017-06-30  31815  29881  4187  31815  31815  31793  14952  31815  31815   \n",
              "2017-07-31  32620  30677  4321  32620  32620  32594  15321  32620  32620   \n",
              "2017-08-31  33253  31272  4480  33253  33253  33239  15530  33253  33253   \n",
              "2017-09-30  33427  31441  4546  33427  33427  33416  15487  33427  33427   \n",
              "2017-10-31  34439  32338  4724  34439  34439  34417  15778  34439  34439   \n",
              "2017-11-30  35664  33620  4835  35664  35664  35662  16203  35664  35664   \n",
              "2017-12-31  36977  34708  5078  36977  36977  36972  16655  36977  36977   \n",
              "2018-01-31  38957  36525  5480  38957  38957  38828  17018  38957  38957   \n",
              "2018-02-28  41614  38912  5811  41614  41614  41020  18230  41614  41614   \n",
              "2018-03-31  47136  43544  6222  47096  47136  45033  20336  47136  47136   \n",
              "\n",
              "              R_3   D_52    P_3   B_10   D_53    S_5   B_11    S_6   D_54  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730  30676  30599  30730  10143  30730  30730  30730  30730   \n",
              "2017-04-30  31233  31175  31106  31233  10274  31233  31233  31233  31233   \n",
              "2017-05-31  31048  30987  30909  31048  10327  31048  31048  31048  31048   \n",
              "2017-06-30  31815  31755  31683  31815  10632  31815  31815  31815  31815   \n",
              "2017-07-31  32620  32548  32486  32620  10505  32620  32620  32620  32620   \n",
              "2017-08-31  33253  33190  33125  33253  10861  33253  33253  33253  33253   \n",
              "2017-09-30  33427  33384  33303  33427  10955  33427  33427  33427  33427   \n",
              "2017-10-31  34439  34375  34254  34439  11028  34439  34439  34439  34439   \n",
              "2017-11-30  35664  35643  35224  35664  11380  35664  35664  35664  35664   \n",
              "2017-12-31  36977  36967  35710  36977  11456  36977  36977  36977  36977   \n",
              "2018-01-31  38957  38878  36137  38957  11790  38957  38957  38957  38957   \n",
              "2018-02-28  41614  41502  36220  41614  12059  41614  41614  41614  41614   \n",
              "2018-03-31  47136  46690  36631  47136  12646  47136  47136  47136  47105   \n",
              "\n",
              "              R_4    S_7   B_12    S_8   D_55   D_56   B_13    R_5   D_58  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730  26787  30730  30730  30674  17489  30730  30730  30730   \n",
              "2017-04-30  31233  27205  31233  31233  31167  17580  31233  31233  31233   \n",
              "2017-05-31  31048  27106  31048  31048  30976  17402  31048  31048  31048   \n",
              "2017-06-30  31815  27846  31815  31815  31752  17718  31815  31815  31815   \n",
              "2017-07-31  32620  28477  32620  32620  32547  17996  32620  32620  32620   \n",
              "2017-08-31  33253  29175  33253  33253  33191  18210  33253  33253  33253   \n",
              "2017-09-30  33427  29398  33427  33427  33381  18067  33427  33427  33427   \n",
              "2017-10-31  34439  30296  34439  34439  34373  18595  34439  34439  34439   \n",
              "2017-11-30  35664  31552  35664  35664  35645  18809  35664  35664  35664   \n",
              "2017-12-31  36977  32729  36977  36977  36963  19491  36977  36977  36977   \n",
              "2018-01-31  38957  34485  38957  38957  38712  19882  38957  38957  38957   \n",
              "2018-02-28  41614  37024  41614  41614  41106  20848  41389  41614  41614   \n",
              "2018-03-31  47136  40237  47136  47136  45948  22512  45798  47136  47136   \n",
              "\n",
              "              S_9   B_14   D_59   D_60   D_61   B_15   S_11   D_62   D_63  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  20853  30730  30680  30730  29206  30687  30730  28822  30730   \n",
              "2017-04-30  21162  31233  31176  31233  29613  31186  31233  29154  31233   \n",
              "2017-05-31  21161  31048  30982  31048  29472  30988  31048  29031  31048   \n",
              "2017-06-30  21793  31815  31748  31815  30301  31755  31815  29836  31815   \n",
              "2017-07-31  22449  32620  32548  32620  31121  32549  32620  30600  32620   \n",
              "2017-08-31  23063  33253  33196  33253  31696  33201  33253  31214  33253   \n",
              "2017-09-30  23206  33427  33389  33427  31941  33391  33427  31408  33427   \n",
              "2017-10-31  23988  34439  34381  34439  32877  34384  34439  32247  34439   \n",
              "2017-11-30  24996  35664  35660  35664  34193  35664  35664  33509  35664   \n",
              "2017-12-31  25836  36977  36971  36977  35400  36977  36977  34642  36977   \n",
              "2018-01-31  27302  38957  38880  38957  37301  38885  38957  36283  38957   \n",
              "2018-02-28  28516  41614  41032  41614  39874  41563  41614  38643  41614   \n",
              "2018-03-31  29354  47136  44474  47136  44835  47079  47136  43174  47136   \n",
              "\n",
              "             D_64   D_65   B_16   B_17   B_18   B_19  D_66   B_20   D_68  \\\n",
              "S_2                                                                        \n",
              "2017-03-31  30724  30730  30730  17104  30730  30730  4156  30730  30724   \n",
              "2017-04-30  31226  31233  31233  17203  31233  31233  4159  31233  31226   \n",
              "2017-05-31  31048  31048  31048  17198  31048  31048  4171  31048  31048   \n",
              "2017-06-30  31809  31815  31815  17763  31815  31815  4234  31815  31807   \n",
              "2017-07-31  32609  32620  32620  17970  32620  32620  4366  32620  32609   \n",
              "2017-08-31  33235  33253  33253  18362  33253  33253  4382  33253  33237   \n",
              "2017-09-30  33388  33427  33427  18540  33427  33427  4446  33427  33390   \n",
              "2017-10-31  34395  34439  34439  18707  34439  34439  4494  34439  34396   \n",
              "2017-11-30  35585  35664  35664  19466  35664  35664  4714  35664  35591   \n",
              "2017-12-31  36906  36977  36977  19753  36977  36977  4845  36977  36903   \n",
              "2018-01-31  38751  38957  38957  20313  38957  38957  5018  38957  38752   \n",
              "2018-02-28  40462  41614  41614  21002  41614  41614  5221  41614  40467   \n",
              "2018-03-31  43496  47136  47105  22102  47136  47105  5570  47105  43512   \n",
              "\n",
              "             S_12    R_6   S_13   B_21   D_69   B_22   D_70   D_71   D_72  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730  30730  30730  30730  30724  30730  30639  30730  30676   \n",
              "2017-04-30  31233  31233  31233  31233  31226  31233  31141  31233  31175   \n",
              "2017-05-31  31048  31048  31048  31048  31048  31048  30951  31048  30987   \n",
              "2017-06-30  31815  31815  31815  31815  31812  31815  31732  31815  31755   \n",
              "2017-07-31  32620  32620  32620  32620  32614  32620  32520  32620  32548   \n",
              "2017-08-31  33253  33253  33253  33253  33247  33253  33162  33253  33190   \n",
              "2017-09-30  33427  33427  33427  33427  33409  33427  33355  33427  33384   \n",
              "2017-10-31  34439  34439  34439  34439  34425  34439  34337  34439  34375   \n",
              "2017-11-30  35664  35664  35664  35664  35643  35664  35604  35664  35643   \n",
              "2017-12-31  36977  36977  36977  36977  36947  36977  36921  36977  36967   \n",
              "2018-01-31  38957  38957  38957  38957  38822  38957  38722  38957  38878   \n",
              "2018-02-28  41614  41614  41614  41614  40567  41614  40908  41614  41503   \n",
              "2018-03-31  47136  47136  47136  47136  43642  47105  44803  47136  46704   \n",
              "\n",
              "             S_15   B_23  D_73    P_4   D_74   D_75  D_76   B_24    R_7  \\\n",
              "S_2                                                                       \n",
              "2017-03-31  30730  30730   325  30730  30641  30730  4108  30730  30730   \n",
              "2017-04-30  31233  31233   362  31233  31142  31233  4087  31233  31233   \n",
              "2017-05-31  31048  31048   374  31048  30952  31048  4071  31048  31048   \n",
              "2017-06-30  31815  31815   446  31815  31732  31815  4069  31815  31815   \n",
              "2017-07-31  32620  32620   489  32620  32522  32620  4049  32620  32620   \n",
              "2017-08-31  33253  33253   523  33253  33165  33253  4130  33253  33253   \n",
              "2017-09-30  33427  33427   571  33427  33365  33427  4251  33427  33427   \n",
              "2017-10-31  34439  34439   637  34439  34344  34439  4355  34439  34439   \n",
              "2017-11-30  35664  35664   753  35664  35620  35664  4234  35664  35664   \n",
              "2017-12-31  36977  36977   825  36977  36947  36977  4216  36977  36977   \n",
              "2018-01-31  38957  38957   935  38957  38818  38957  4355  38957  38957   \n",
              "2018-02-28  41614  41614   899  41614  41432  41614  4709  41614  41614   \n",
              "2018-03-31  47136  47136   869  47136  46638  47136  5287  47136  47136   \n",
              "\n",
              "             D_77   B_25   B_26   D_78   D_79    R_8   R_9   S_16   D_80  \\\n",
              "S_2                                                                        \n",
              "2017-03-31  24320  30687  30730  29565  30631  30730  2442  30730  30641   \n",
              "2017-04-30  24690  31186  31233  30024  31126  31233  2494  31233  31142   \n",
              "2017-05-31  24521  30988  31048  29842  30934  31048  2563  31048  30952   \n",
              "2017-06-30  25212  31755  31815  30623  31714  31815  2801  31815  31732   \n",
              "2017-07-31  26044  32549  32620  31410  32501  32620  2769  32620  32522   \n",
              "2017-08-31  26539  33201  33253  32039  33133  33253  2901  33253  33165   \n",
              "2017-09-30  26975  33391  33427  32204  33338  33427  2909  33427  33365   \n",
              "2017-10-31  27811  34384  34439  33103  34322  34439  3029  34439  34344   \n",
              "2017-11-30  29005  35664  35664  34470  35588  35664  3163  35664  35620   \n",
              "2017-12-31  30060  36977  36977  35637  36919  36977  3327  36977  36947   \n",
              "2018-01-31  31730  38885  38957  37454  38804  38957  3436  38957  38818   \n",
              "2018-02-28  33940  41563  41614  39995  41393  41614  3579  41614  41432   \n",
              "2018-03-31  37378  47079  47105  44982  45991  47136  4123  47136  46638   \n",
              "\n",
              "             R_10   R_11   B_27   D_81   D_82   S_17   R_12   B_28   R_13  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730  30730  30730  30694   9038  30730  30730  30730  30730   \n",
              "2017-04-30  31233  31233  31233  31199   9012  31233  31233  31233  31233   \n",
              "2017-05-31  31048  31048  31048  31009   8944  31048  31048  31048  31048   \n",
              "2017-06-30  31815  31815  31815  31773   9042  31815  31815  31815  31815   \n",
              "2017-07-31  32620  32620  32620  32576   9192  32620  32620  32620  32620   \n",
              "2017-08-31  33253  33253  33253  33213   9393  33253  33253  33253  33253   \n",
              "2017-09-30  33427  33427  33427  33396   9125  33427  33427  33427  33427   \n",
              "2017-10-31  34439  34439  34439  34395   9432  34439  34439  34439  34439   \n",
              "2017-11-30  35664  35664  35664  35647   9593  35664  35664  35664  35664   \n",
              "2017-12-31  36977  36977  36977  36968   9690  36977  36977  36977  36977   \n",
              "2018-01-31  38957  38957  38957  38904   9942  38957  38957  38957  38957   \n",
              "2018-02-28  41614  41614  41614  41523  10293  41614  41614  41614  41614   \n",
              "2018-03-31  47136  47136  47105  46714  10789  47136  47136  47136  47136   \n",
              "\n",
              "             D_83   R_14   R_15   D_84   R_16  B_29   B_30   S_18   D_86  \\\n",
              "S_2                                                                        \n",
              "2017-03-31  30724  30730  30730  30676  30730  2655  30730  30730  30730   \n",
              "2017-04-30  31226  31233  31233  31175  31233  2667  31233  31233  31233   \n",
              "2017-05-31  31048  31048  31048  30987  31048  2327  31048  31048  31048   \n",
              "2017-06-30  31812  31815  31815  31755  31815  2557  31815  31815  31815   \n",
              "2017-07-31  32614  32620  32620  32548  32620  2608  32620  32620  32620   \n",
              "2017-08-31  33247  33253  33253  33190  33253  2696  33253  33253  33253   \n",
              "2017-09-30  33409  33427  33427  33384  33427  2683  33427  33427  33427   \n",
              "2017-10-31  34425  34439  34439  34375  34439  2678  34439  34439  34439   \n",
              "2017-11-30  35643  35664  35664  35643  35664  2812  35664  35664  35664   \n",
              "2017-12-31  36947  36977  36977  36967  36977  2785  36977  36977  36977   \n",
              "2018-01-31  38822  38957  38957  38878  38957  3191  38957  38957  38957   \n",
              "2018-02-28  40567  41614  41614  41502  41614  3580  41614  41614  41614   \n",
              "2018-03-31  43642  47136  47136  46690  47136  3574  47105  47136  47136   \n",
              "\n",
              "            D_87   R_17   R_18  D_88   B_31   S_19   R_19   B_32   S_20  \\\n",
              "S_2                                                                       \n",
              "2017-03-31    59  30730  30730   170  30730  30730  30730  30730  30730   \n",
              "2017-04-30    62  31233  31233   154  31233  31233  31233  31233  31233   \n",
              "2017-05-31    67  31048  31048   144  31048  31048  31048  31048  31048   \n",
              "2017-06-30    68  31815  31815   156  31815  31815  31815  31815  31815   \n",
              "2017-07-31    60  32620  32620   203  32620  32620  32620  32620  32620   \n",
              "2017-08-31    70  33253  33253   193  33253  33253  33253  33253  33253   \n",
              "2017-09-30    65  33427  33427   173  33427  33427  33427  33427  33427   \n",
              "2017-10-31    69  34439  34439   210  34439  34439  34439  34439  34439   \n",
              "2017-11-30    59  35664  35664   192  35664  35664  35664  35664  35664   \n",
              "2017-12-31    83  36977  36977   203  36977  36977  36977  36977  36977   \n",
              "2018-01-31    51  38957  38957   195  38957  38957  38957  38957  38957   \n",
              "2018-02-28    58  41614  41614   221  41614  41614  41614  41614  41614   \n",
              "2018-03-31    58  47136  47136   205  47136  47136  47136  47136  47136   \n",
              "\n",
              "             R_20   R_21   B_33   D_89   R_22   R_23   D_91   D_92   D_93  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730  30730  30730  30676  30730  30730  30695  30730  30730   \n",
              "2017-04-30  31233  31233  31233  31175  31233  31233  31191  31233  31233   \n",
              "2017-05-31  31048  31048  31048  30987  31048  31048  31000  31048  31048   \n",
              "2017-06-30  31815  31815  31815  31755  31815  31815  31767  31815  31815   \n",
              "2017-07-31  32620  32620  32620  32548  32620  32620  32566  32620  32620   \n",
              "2017-08-31  33253  33253  33253  33190  33253  33253  33214  33253  33253   \n",
              "2017-09-30  33427  33427  33427  33384  33427  33427  33399  33427  33427   \n",
              "2017-10-31  34439  34439  34439  34375  34439  34439  34399  34439  34439   \n",
              "2017-11-30  35664  35664  35664  35643  35664  35664  35527  35664  35664   \n",
              "2017-12-31  36977  36977  36977  36967  36977  36977  36786  36977  36977   \n",
              "2018-01-31  38957  38957  38957  38878  38957  38957  37626  38957  38957   \n",
              "2018-02-28  41614  41614  41614  41502  41614  41614  38398  41614  41614   \n",
              "2018-03-31  47136  47136  47105  46690  47136  47136  39560  47136  47136   \n",
              "\n",
              "             D_94   R_24   R_25   D_96   S_22   S_23   S_24   S_25   S_26  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730  30730  30730  30730  30729  30730  30729  30726  30730   \n",
              "2017-04-30  31233  31233  31233  31233  31232  31233  31232  31233  31233   \n",
              "2017-05-31  31048  31048  31048  31048  31048  31048  31048  31046  31048   \n",
              "2017-06-30  31815  31815  31815  31815  31813  31815  31813  31815  31815   \n",
              "2017-07-31  32620  32620  32620  32620  32620  32620  32620  32617  32620   \n",
              "2017-08-31  33253  33253  33253  33253  33251  33253  33251  33251  33253   \n",
              "2017-09-30  33427  33427  33427  33427  33426  33427  33426  33425  33427   \n",
              "2017-10-31  34439  34439  34439  34439  34437  34439  34437  34438  34439   \n",
              "2017-11-30  35664  35664  35664  35664  35662  35664  35662  35660  35664   \n",
              "2017-12-31  36977  36977  36977  36977  36977  36977  36977  36974  36977   \n",
              "2018-01-31  38957  38957  38957  38957  38957  38957  38957  38953  38957   \n",
              "2018-02-28  41614  41614  41614  41614  41611  41614  41611  41610  41614   \n",
              "2018-03-31  47136  47136  47136  47136  47032  47135  47033  47120  47136   \n",
              "\n",
              "            D_102  D_103  D_104  D_105  D_106  D_107   B_36   B_37  R_26  \\\n",
              "S_2                                                                        \n",
              "2017-03-31  30730  30631  30631  15821   3925  30631  30730  30730  3268   \n",
              "2017-04-30  31233  31126  31126  16191   3964  31126  31233  31233  3281   \n",
              "2017-05-31  31048  30934  30934  16014   4027  30934  31048  31048  3381   \n",
              "2017-06-30  31815  31713  31713  16558   4181  31713  31815  31815  3560   \n",
              "2017-07-31  32620  32501  32501  16889   4312  32501  32620  32620  3720   \n",
              "2017-08-31  33253  33133  33133  17288   4474  33133  33253  33253  3954   \n",
              "2017-09-30  33427  33338  33338  17432   4542  33338  33427  33427  4025   \n",
              "2017-10-31  34439  34322  34322  17864   4718  34322  34439  34439  4150   \n",
              "2017-11-30  35664  35588  35588  18460   4826  35588  35664  35664  4413   \n",
              "2017-12-31  36977  36919  36919  19327   5072  36919  36977  36977  4316   \n",
              "2018-01-31  38957  38804  38804  20155   5477  38804  38957  38957  4423   \n",
              "2018-02-28  41614  41388  41388  21211   5808  41388  41614  41614  4429   \n",
              "2018-03-31  47136  45984  45984  23644   6211  45984  47136  47136  4346   \n",
              "\n",
              "             R_27   B_38  D_108  D_109  D_110  D_111  B_39  D_112   B_40  \\\n",
              "S_2                                                                        \n",
              "2017-03-31  30329  30730   1383  30730    344    344   345  30730  30730   \n",
              "2017-04-30  30830  31233   1457  31233    299    299   300  31233  31233   \n",
              "2017-05-31  30637  31048   1431  31048    308    308   312  31048  31048   \n",
              "2017-06-30  31439  31815   1483  31815    307    307   307  31815  31815   \n",
              "2017-07-31  32176  32620   1629  32620    314    314   314  32620  32620   \n",
              "2017-08-31  32825  33253   1599  33253    320    320   323  33253  33253   \n",
              "2017-09-30  32987  33427   1548  33427    323    323   325  33427  33427   \n",
              "2017-10-31  33941  34439   1712  34439    293    293   294  34439  34439   \n",
              "2017-11-30  35205  35664   1702  35664    334    334   337  35664  35664   \n",
              "2017-12-31  35375  36977   1676  36977    291    291   291  36977  36977   \n",
              "2018-01-31  35495  38957   1800  38957    330    330   331  38957  38957   \n",
              "2018-02-28  35252  41614   1736  41614    316    316   318  41614  41614   \n",
              "2018-03-31  35434  47105   1774  47105    308    308   309  47105  47136   \n",
              "\n",
              "             S_27  D_113  D_114  D_115  D_116  D_117  D_118  D_119  D_120  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  26216  30730  30730  30730  30730  30730  30730  30730  30730   \n",
              "2017-04-30  26683  31233  31233  31233  31233  31233  31233  31233  31233   \n",
              "2017-05-31  26598  31048  31048  31048  31048  31048  31048  31048  31048   \n",
              "2017-06-30  27327  31812  31812  31812  31812  31812  31812  31812  31812   \n",
              "2017-07-31  27942  32614  32614  32614  32614  32614  32614  32614  32614   \n",
              "2017-08-31  28638  33246  33246  33246  33246  33246  33246  33246  33246   \n",
              "2017-09-30  28864  33411  33411  33411  33411  33411  33411  33411  33411   \n",
              "2017-10-31  29787  34425  34425  34425  34425  34425  34425  34425  34425   \n",
              "2017-11-30  30943  35643  35643  35643  35643  35643  35643  35643  35643   \n",
              "2017-12-31  32118  36948  36948  36948  36948  36948  36948  36948  36948   \n",
              "2018-01-31  33861  38825  38825  38825  38825  38825  38825  38825  38825   \n",
              "2018-02-28  36258  40570  40570  40570  40570  40570  40570  40570  40570   \n",
              "2018-03-31  37941  43669  43669  43669  43669  43669  43669  43669  43669   \n",
              "\n",
              "            D_121  D_122  D_123  D_124  D_125  D_126  D_127  D_128  D_129  \\\n",
              "S_2                                                                         \n",
              "2017-03-31  30730  30730  30730  30730  30730  30730  30730  30631  30631   \n",
              "2017-04-30  31233  31233  31233  31233  31233  31233  31233  31126  31126   \n",
              "2017-05-31  31048  31048  31048  31048  31048  31048  31048  30934  30934   \n",
              "2017-06-30  31812  31812  31812  31812  31812  31815  31815  31713  31713   \n",
              "2017-07-31  32614  32614  32614  32614  32614  32620  32620  32501  32501   \n",
              "2017-08-31  33246  33246  33246  33246  33246  33253  33253  33133  33133   \n",
              "2017-09-30  33411  33411  33411  33411  33411  33427  33427  33338  33338   \n",
              "2017-10-31  34425  34425  34425  34425  34425  34439  34439  34322  34322   \n",
              "2017-11-30  35643  35643  35643  35643  35643  35664  35664  35588  35588   \n",
              "2017-12-31  36948  36948  36948  36948  36948  36977  36977  36919  36919   \n",
              "2018-01-31  38825  38825  38825  38825  38825  38957  38957  38804  38804   \n",
              "2018-02-28  40570  40570  40570  40570  40570  41614  41614  41388  41388   \n",
              "2018-03-31  43669  43669  43669  43669  43669  47136  47136  45984  45984   \n",
              "\n",
              "             B_41  B_42  D_130  D_131  D_132  D_133   R_28  D_134  D_135  \\\n",
              "S_2                                                                        \n",
              "2017-03-31  30730   482  30631  30631   3931  30730  30730   2270   2270   \n",
              "2017-04-30  31233   479  31126  31126   3970  31233  31233   2253   2253   \n",
              "2017-05-31  31048   493  30934  30934   4030  31048  31048   2248   2248   \n",
              "2017-06-30  31815   505  31713  31713   4187  31815  31815   2423   2423   \n",
              "2017-07-31  32620   431  32501  32501   4319  32620  32620   2453   2453   \n",
              "2017-08-31  33253   473  33133  33133   4480  33253  33253   2620   2620   \n",
              "2017-09-30  33427   508  33338  33338   4546  33427  33427   2635   2635   \n",
              "2017-10-31  34439   486  34322  34322   4724  34439  34439   2746   2746   \n",
              "2017-11-30  35664   494  35588  35588   4835  35664  35664   2871   2871   \n",
              "2017-12-31  36977   555  36919  36919   5078  36977  36977   2847   2847   \n",
              "2018-01-31  38957   492  38804  38804   5480  38957  38957   2990   2990   \n",
              "2018-02-28  41614   567  41388  41388   5812  41614  41614   2987   2987   \n",
              "2018-03-31  47136   544  45984  45984   6221  47136  47136   3213   3213   \n",
              "\n",
              "            D_136  D_137  D_138  D_139  D_140  D_141  D_142  D_143  D_144  \\\n",
              "S_2                                                                         \n",
              "2017-03-31   2270   2270   2270  30631  30730  30631   5477  30631  30730   \n",
              "2017-04-30   2253   2253   2253  31126  31233  31126   5593  31126  31233   \n",
              "2017-05-31   2248   2248   2248  30934  31048  30934   5593  30934  31048   \n",
              "2017-06-30   2423   2423   2423  31713  31815  31713   5938  31713  31815   \n",
              "2017-07-31   2453   2453   2453  32501  32620  32501   6049  32501  32620   \n",
              "2017-08-31   2620   2620   2620  33133  33253  33133   6244  33133  33253   \n",
              "2017-09-30   2635   2635   2635  33338  33427  33338   6237  33338  33427   \n",
              "2017-10-31   2746   2746   2746  34322  34439  34322   6416  34322  34439   \n",
              "2017-11-30   2871   2871   2871  35588  35664  35588   6738  35588  35664   \n",
              "2017-12-31   2847   2847   2847  36919  36977  36919   7058  36919  36977   \n",
              "2018-01-31   2990   2990   2990  38804  38957  38804   7464  38804  38957   \n",
              "2018-02-28   2987   2987   2987  41388  41614  41388   7951  41388  41614   \n",
              "2018-03-31   3213   3213   3213  45984  47136  45984   8822  45984  47136   \n",
              "\n",
              "            D_145  target  \n",
              "S_2                        \n",
              "2017-03-31  30631   30730  \n",
              "2017-04-30  31126   31233  \n",
              "2017-05-31  30934   31048  \n",
              "2017-06-30  31713   31815  \n",
              "2017-07-31  32501   32620  \n",
              "2017-08-31  33133   33253  \n",
              "2017-09-30  33338   33427  \n",
              "2017-10-31  34322   34439  \n",
              "2017-11-30  35588   35664  \n",
              "2017-12-31  36919   36977  \n",
              "2018-01-31  38804   38957  \n",
              "2018-02-28  41388   41614  \n",
              "2018-03-31  45984   47136  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Grouping by the Month and counting the rows in each of them \n",
        "df1.set_index('S_2').groupby(pd.Grouper(freq = 'M')).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16WVCYZD6kEy",
        "outputId": "3dba8b68-de0f-46be-94dc-6c979b087332"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "customer_ID         0\n",
              "S_2                 0\n",
              "P_2              2434\n",
              "D_39                0\n",
              "B_1                 0\n",
              "                ...  \n",
              "D_142          373333\n",
              "D_143            2532\n",
              "D_144               0\n",
              "D_145            2532\n",
              "target              0\n",
              "Length: 191, dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking Null Values in each columns \n",
        "# Target column shouldn't have any null value\n",
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "iK6Ze98x6kEy",
        "outputId": "e6271874-41ea-4df3-80bc-ea74b5304863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customer_ID object\n",
            "S_2 datetime64[ns]\n",
            "D_63 object\n",
            "D_64 object\n",
            "B_31 int64\n",
            "target int64\n"
          ]
        }
      ],
      "source": [
        "# Run the loop through each column and check it's datatype\n",
        "# If Data Type not equal to Float64, then print\n",
        "\n",
        "for i in df1.columns:\n",
        "    if df1[i].dtypes != 'float64':\n",
        "        print(i, df1[i].dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXWUin5-6kEy",
        "outputId": "a49963b4-63b2-4ded-a56f-575cb8c33824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['CR', 'CO', 'CL', 'XZ', 'XM', 'XL'], dtype=object)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check unique values in D_63 columns\n",
        "df1['D_63'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws8gK4Ed6kEy",
        "outputId": "39cf3b55-3666-4f9c-b956-08bee0394fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['O', 'R', 'U', '-1', None], dtype=object)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check unique values in D_64 columns\n",
        "df1['D_64'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wBtuUkH6kEy"
      },
      "source": [
        "#### Converting Categorical Variables to dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zjZRETd6kEy",
        "outputId": "e0f745db-0c37-40e5-9a1f-c9ea5bf8c741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  2017-03-01 00:00:00 Max:  2018-03-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "print(\"Min: \", df1['S_2'].min(), \"Max: \", df1['S_2'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KGiBEg76kEz"
      },
      "outputs": [],
      "source": [
        "# fn converts categorical values to dummy values and drops the og columns\n",
        "df_new1 = pd.get_dummies(df1, columns = ['D_63', 'D_64'], drop_first = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FJhbSXU6kEz",
        "outputId": "5567ec64-da32-476f-ff4b-f1ef87786bdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(458913, 197)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "eZLvkTr06kEz"
      },
      "outputs": [],
      "source": [
        "# Save the final dataframe in csv\n",
        "df_new1.to_csv('final_df.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "U3VvHUxP6kEz",
        "outputId": "3ca57fdf-fa5d-431f-d140-1c74ba775a3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(183720, 197)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df_new = pd.read_csv('final_df.csv', index_col = False)\n",
        "df_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.set_index('S_2').groupby(pd.Grouper(freq = 'M')).count()"
      ],
      "metadata": {
        "id": "QQA0RD4RZUl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "angW9cY66kEz",
        "outputId": "bef3927a-6078-433b-9a07-8fef91b60014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customer_ID\n",
            "S_2\n",
            "P_2\n",
            "D_39\n",
            "B_1\n",
            "B_2\n",
            "R_1\n",
            "S_3\n",
            "D_41\n",
            "B_3\n",
            "D_42\n",
            "D_43\n",
            "D_44\n",
            "B_4\n",
            "D_45\n",
            "B_5\n",
            "R_2\n",
            "D_46\n",
            "D_47\n",
            "D_48\n",
            "D_49\n",
            "B_6\n",
            "B_7\n",
            "B_8\n",
            "D_50\n",
            "D_51\n",
            "B_9\n",
            "R_3\n",
            "D_52\n",
            "P_3\n",
            "B_10\n",
            "D_53\n",
            "S_5\n",
            "B_11\n",
            "S_6\n",
            "D_54\n",
            "R_4\n",
            "S_7\n",
            "B_12\n",
            "S_8\n",
            "D_55\n",
            "D_56\n",
            "B_13\n",
            "R_5\n",
            "D_58\n",
            "S_9\n",
            "B_14\n",
            "D_59\n",
            "D_60\n",
            "D_61\n",
            "B_15\n",
            "S_11\n",
            "D_62\n",
            "D_65\n",
            "B_16\n",
            "B_17\n",
            "B_18\n",
            "B_19\n",
            "D_66\n",
            "B_20\n",
            "D_68\n",
            "S_12\n",
            "R_6\n",
            "S_13\n",
            "B_21\n",
            "D_69\n",
            "B_22\n",
            "D_70\n",
            "D_71\n",
            "D_72\n",
            "S_15\n",
            "B_23\n",
            "D_73\n",
            "P_4\n",
            "D_74\n",
            "D_75\n",
            "D_76\n",
            "B_24\n",
            "R_7\n",
            "D_77\n",
            "B_25\n",
            "B_26\n",
            "D_78\n",
            "D_79\n",
            "R_8\n",
            "R_9\n",
            "S_16\n",
            "D_80\n",
            "R_10\n",
            "R_11\n",
            "B_27\n",
            "D_81\n",
            "D_82\n",
            "S_17\n",
            "R_12\n",
            "B_28\n",
            "R_13\n",
            "D_83\n",
            "R_14\n",
            "R_15\n",
            "D_84\n",
            "R_16\n",
            "B_29\n",
            "B_30\n",
            "S_18\n",
            "D_86\n",
            "D_87\n",
            "R_17\n",
            "R_18\n",
            "D_88\n",
            "B_31\n",
            "S_19\n",
            "R_19\n",
            "B_32\n",
            "S_20\n",
            "R_20\n",
            "R_21\n",
            "B_33\n",
            "D_89\n",
            "R_22\n",
            "R_23\n",
            "D_91\n",
            "D_92\n",
            "D_93\n",
            "D_94\n",
            "R_24\n",
            "R_25\n",
            "D_96\n",
            "S_22\n",
            "S_23\n",
            "S_24\n",
            "S_25\n",
            "S_26\n",
            "D_102\n",
            "D_103\n",
            "D_104\n",
            "D_105\n",
            "D_106\n",
            "D_107\n",
            "B_36\n",
            "B_37\n",
            "R_26\n",
            "R_27\n",
            "B_38\n",
            "D_108\n",
            "D_109\n",
            "D_110\n",
            "D_111\n",
            "B_39\n",
            "D_112\n",
            "B_40\n",
            "S_27\n",
            "D_113\n",
            "D_114\n",
            "D_115\n",
            "D_116\n",
            "D_117\n",
            "D_118\n",
            "D_119\n",
            "D_120\n",
            "D_121\n",
            "D_122\n",
            "D_123\n",
            "D_124\n",
            "D_125\n",
            "D_126\n",
            "D_127\n",
            "D_128\n",
            "D_129\n",
            "B_41\n",
            "B_42\n",
            "D_130\n",
            "D_131\n",
            "D_132\n",
            "D_133\n",
            "R_28\n",
            "D_134\n",
            "D_135\n",
            "D_136\n",
            "D_137\n",
            "D_138\n",
            "D_139\n",
            "D_140\n",
            "D_141\n",
            "D_142\n",
            "D_143\n",
            "D_144\n",
            "D_145\n",
            "target\n",
            "D_63_CO\n",
            "D_63_CR\n",
            "D_63_XL\n",
            "D_63_XM\n",
            "D_63_XZ\n",
            "D_64_O\n",
            "D_64_R\n",
            "D_64_U\n"
          ]
        }
      ],
      "source": [
        "for i in df_new.columns:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTWozQWf6kE0"
      },
      "source": [
        "### Split Dataset in Train, Test1 & Test2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "tYv-bNY56kE0"
      },
      "outputs": [],
      "source": [
        "train_df = df_new.loc[(df_new['S_2'] >= '2017-05') & (df_new['S_2'] <= '2018-01'), :]\n",
        "test1_df = df_new.loc[(df_new['S_2'] <= '2017-04') , :]\n",
        "test2_df = df_new.loc[ (df_new['S_2'] >= '2018-02'), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzHocTG36kE0",
        "outputId": "ebe523a6-c04f-4137-c327-3bd5f96b786b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(269243, 197)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROpOKG4U6kE0"
      },
      "outputs": [],
      "source": [
        "xtrain = train_df.drop(columns = ['target', 'customer_ID', 'S_2']) \n",
        "ytrain = train_df['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRgql1Bt6kE0",
        "outputId": "dcbeb2fa-4169-4bba-b35f-dc5ad828288e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(269243, 194)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "i9m68zew6kE0",
        "outputId": "0e737842-3ebf-4c7c-a482-7ec41bf7aa76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "218.29219317436218\n"
          ]
        }
      ],
      "source": [
        "### MODEL 1\n",
        "t1 = t.time()\n",
        "m1 = xgb.XGBClassifier(random_state = 21)\n",
        "m1.fit(xtrain, ytrain)\n",
        "feat_imp = pd.DataFrame({'columns': xtrain.columns, 'feat_imp': m1.feature_importances_}) # creating table to rank feature importances\n",
        "feat_imp.loc[feat_imp['feat_imp'] > 0.005,:].sort_values(['feat_imp'], ascending = False)\n",
        "feat_imp.to_csv('feat_imp.csv')\n",
        "t2 = t.time()\n",
        "print(t2-t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "r4odv9bx6kE1",
        "outputId": "1fcbb827-a799-44d1-b220-d80281f58700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146.99498295783997\n"
          ]
        }
      ],
      "source": [
        "# MODEL 2 - with some parameters as defined by professor\n",
        "t1 = t.time() #max_dept = max number of nodes, subsample = % of rows considered from the total data in the main tree at once, colsample_bytree = % of columns considered from the total data in the main tree at once\n",
        "m2 = xgb.XGBClassifier(n_estimators = 300, learning_rate = 0.5, \n",
        "                       max_depth = 4, subsample = .5, colsample_bytree = 0.5, scale_pos_weight = 5, random_state =21 )\n",
        "m2.fit(xtrain, ytrain)\n",
        "feat_imp1 = pd.DataFrame({'columns': xtrain.columns, 'feat_imp': m2.feature_importances_})\n",
        "feat_imp1.loc[feat_imp1['feat_imp'] > 0.005,:].sort_values(['feat_imp'], ascending = False)\n",
        "feat_imp1.to_csv('feat_imp1.csv')\n",
        "t2 = t.time()\n",
        "print(t2-t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFTCEWr56kE1",
        "outputId": "de149434-ca9c-403b-86d0-64210e91de9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(415602, 190)\n",
            "31.137080669403076\n"
          ]
        }
      ],
      "source": [
        "#the total time taken to run the code\n",
        "start = t.time()\n",
        "df_rnd1 = train.loc[(train['S_2'].dt.year == 2017) & (train['S_2'].dt.month == 7), :]\n",
        "print(df_rnd1.shape)\n",
        "end = t.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLTtkh_Z6kE1",
        "outputId": "8329ab50-c4cc-40ac-f968-6242366a41a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>columns</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>P_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>R_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>S_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>D_41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>B_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>D_42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>D_43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>D_44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>B_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>D_45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>15</td>\n",
              "      <td>D_46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>17</td>\n",
              "      <td>D_48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>18</td>\n",
              "      <td>D_49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>21</td>\n",
              "      <td>B_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22</td>\n",
              "      <td>D_50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>23</td>\n",
              "      <td>D_51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>28</td>\n",
              "      <td>B_10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>29</td>\n",
              "      <td>D_53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>35</td>\n",
              "      <td>S_7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>53</td>\n",
              "      <td>B_17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>56</td>\n",
              "      <td>D_66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>72</td>\n",
              "      <td>D_74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>73</td>\n",
              "      <td>D_75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>74</td>\n",
              "      <td>D_76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>77</td>\n",
              "      <td>D_77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>107</td>\n",
              "      <td>D_88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>127</td>\n",
              "      <td>S_23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>139</td>\n",
              "      <td>R_26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>141</td>\n",
              "      <td>B_38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>144</td>\n",
              "      <td>D_110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>145</td>\n",
              "      <td>D_111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>146</td>\n",
              "      <td>B_39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>171</td>\n",
              "      <td>D_132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>191</td>\n",
              "      <td>D_64_O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index columns\n",
              "0       0     P_2\n",
              "1       2     B_1\n",
              "2       3     B_2\n",
              "3       4     R_1\n",
              "4       5     S_3\n",
              "5       6    D_41\n",
              "6       7     B_3\n",
              "7       8    D_42\n",
              "8       9    D_43\n",
              "9      10    D_44\n",
              "10     11     B_4\n",
              "11     12    D_45\n",
              "12     15    D_46\n",
              "13     17    D_48\n",
              "14     18    D_49\n",
              "15     21     B_8\n",
              "16     22    D_50\n",
              "17     23    D_51\n",
              "18     28    B_10\n",
              "19     29    D_53\n",
              "20     35     S_7\n",
              "21     53    B_17\n",
              "22     56    D_66\n",
              "23     72    D_74\n",
              "24     73    D_75\n",
              "25     74    D_76\n",
              "26     77    D_77\n",
              "27    107    D_88\n",
              "28    127    S_23\n",
              "29    139    R_26\n",
              "30    141    B_38\n",
              "31    144   D_110\n",
              "32    145   D_111\n",
              "33    146    B_39\n",
              "34    171   D_132\n",
              "35    191  D_64_O"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#segregated the features based on their feature importance > 0.005 for model imp1\n",
        "feat_imp1.loc[feat_imp1['feat_imp'] > 0.005, 'columns'].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlpvGnIv6kE1",
        "outputId": "cfb04dd3-9eee-4d81-982c-02bafd4964f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>columns</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>P_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>R_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>S_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>D_41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>B_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>D_42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>D_43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>D_44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>B_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>D_45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>15</td>\n",
              "      <td>D_46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>17</td>\n",
              "      <td>D_48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>18</td>\n",
              "      <td>D_49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>21</td>\n",
              "      <td>B_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22</td>\n",
              "      <td>D_50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>23</td>\n",
              "      <td>D_51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>28</td>\n",
              "      <td>B_10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>29</td>\n",
              "      <td>D_53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>35</td>\n",
              "      <td>S_7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>53</td>\n",
              "      <td>B_17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>56</td>\n",
              "      <td>D_66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>72</td>\n",
              "      <td>D_74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>73</td>\n",
              "      <td>D_75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>74</td>\n",
              "      <td>D_76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>77</td>\n",
              "      <td>D_77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>107</td>\n",
              "      <td>D_88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>127</td>\n",
              "      <td>S_23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>139</td>\n",
              "      <td>R_26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>141</td>\n",
              "      <td>B_38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>144</td>\n",
              "      <td>D_110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>145</td>\n",
              "      <td>D_111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>146</td>\n",
              "      <td>B_39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>171</td>\n",
              "      <td>D_132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>191</td>\n",
              "      <td>D_64_O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index columns\n",
              "0       0     P_2\n",
              "1       2     B_1\n",
              "2       3     B_2\n",
              "3       4     R_1\n",
              "4       5     S_3\n",
              "5       6    D_41\n",
              "6       7     B_3\n",
              "7       8    D_42\n",
              "8       9    D_43\n",
              "9      10    D_44\n",
              "10     11     B_4\n",
              "11     12    D_45\n",
              "12     15    D_46\n",
              "13     17    D_48\n",
              "14     18    D_49\n",
              "15     21     B_8\n",
              "16     22    D_50\n",
              "17     23    D_51\n",
              "18     28    B_10\n",
              "19     29    D_53\n",
              "20     35     S_7\n",
              "21     53    B_17\n",
              "22     56    D_66\n",
              "23     72    D_74\n",
              "24     73    D_75\n",
              "25     74    D_76\n",
              "26     77    D_77\n",
              "27    107    D_88\n",
              "28    127    S_23\n",
              "29    139    R_26\n",
              "30    141    B_38\n",
              "31    144   D_110\n",
              "32    145   D_111\n",
              "33    146    B_39\n",
              "34    171   D_132\n",
              "35    191  D_64_O"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#segregated the features based on their feature importance > 0.005 for model imp1\n",
        "feat_imp.loc[feat_imp1['feat_imp'] > 0.005, 'columns'].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r84npl326kE1",
        "outputId": "e44504cd-309e-4fa1-d283-fd21c101fa2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['D_50', 'R_27', 'S_3', 'B_17', 'B_39', 'D_48', 'D_77', 'D_75', 'D_53', 'D_132', 'B_1', 'B_3', 'D_44', 'B_2', 'D_42', 'B_9', 'D_49', 'D_111', 'D_45', 'D_88', 'B_5', 'D_66', 'B_38', 'S_23', 'D_43', 'D_63_CO', 'D_41', 'D_51', 'P_2', 'B_7', 'R_26', 'D_74', 'D_62', 'B_4', 'D_56', 'B_10', 'B_8', 'D_46', 'D_76', 'D_110', 'P_3', 'D_64_O', 'S_7', 'R_1']\n"
          ]
        }
      ],
      "source": [
        "#union the above two chunk's output based on the filter by ignoring values that occur twice. Eg : A B C A D E - here we consider 5 values\n",
        "col = list(set(feat_imp1.loc[feat_imp1['feat_imp'] > 0.005, 'columns'].to_list()).union(set(feat_imp.loc[feat_imp['feat_imp'] > 0.005, 'columns'].to_list())))\n",
        "print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaKUBT-h6kE2",
        "outputId": "903d07ad-9ec4-4e6d-c8c0-d8c5b160b077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctkQmVbL6kE2",
        "outputId": "84ecbb1a-67b1-4d87-c2cf-a32768d37893"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(458913, 44)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df_new.loc[:, col]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03GWmt2w6kE2",
        "outputId": "ee51d663-0573-46fb-ed4c-9cd4f1e66c27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(269243, 197)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPpicyBD6kE2"
      },
      "outputs": [],
      "source": [
        "#Refer section \"Split Dataset in Train, Test1 & Test2\".\n",
        "#train_df contains 197 columns within the range of dates assigned to it. Now, after we assign the [col] to it, we are only choosing the columns that are in the col variable i.e. there are 44\n",
        "xtrain = train_df[col]\n",
        "xtest1 = test1_df[col]\n",
        "xtest2 = test2_df[col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BqeZKCm6kE2"
      },
      "outputs": [],
      "source": [
        "#refer the same train_df variable output\n",
        "ytrain = train_df['target']\n",
        "ytest1 = test1_df['target']\n",
        "ytest2 = test2_df['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmTUa3za6kE2"
      },
      "outputs": [],
      "source": [
        "#saving it to csv\n",
        "xtrain.to_csv('xtrain.csv', index = False)\n",
        "xtest1.to_csv('xtest1.csv', index = False)\n",
        "xtest2.to_csv('xtest2.csv', index = False)\n",
        "ytest1.to_csv('ytest1.csv', index = False)\n",
        "ytest2.to_csv('ytest2.csv', index = False)\n",
        "ytrain.to_csv('ytrain.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb5vAzji6kE3",
        "outputId": "4296b36f-3b98-4562-f4de-949c0f74e19b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['customer_ID', 'S_2', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41',\n",
              "       'B_3',\n",
              "       ...\n",
              "       'D_145', 'target', 'D_63_CO', 'D_63_CR', 'D_63_XL', 'D_63_XM',\n",
              "       'D_63_XZ', 'D_64_O', 'D_64_R', 'D_64_U'],\n",
              "      dtype='object', length=197)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test2_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bRhcZlXQ6kE3",
        "outputId": "8b1acec8-cfb0-472a-92e8-6f58e1e9fbd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(269243, 44)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-afYAh76kE3",
        "outputId": "4d550461-be3e-4077-a4c2-f98e1b4a170d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(269243,)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ytrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cpeZt3x6kE3",
        "outputId": "7f350b16-c4a8-4ec1-f01e-1d6e2f0c2d5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "5724.6286079883575\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No. of Trees</th>\n",
              "      <th>LR</th>\n",
              "      <th>Subsample</th>\n",
              "      <th>%features</th>\n",
              "      <th>Default Weight</th>\n",
              "      <th>AUC Train</th>\n",
              "      <th>AUC Test1</th>\n",
              "      <th>AUC Test2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.930578</td>\n",
              "      <td>0.918653</td>\n",
              "      <td>0.93205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.928086</td>\n",
              "      <td>0.91662</td>\n",
              "      <td>0.928584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10</td>\n",
              "      <td>0.926039</td>\n",
              "      <td>0.914617</td>\n",
              "      <td>0.925916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.925662</td>\n",
              "      <td>0.912498</td>\n",
              "      <td>0.929065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.92363</td>\n",
              "      <td>0.911914</td>\n",
              "      <td>0.9262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.961602</td>\n",
              "      <td>0.930949</td>\n",
              "      <td>0.941255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10</td>\n",
              "      <td>0.960659</td>\n",
              "      <td>0.929978</td>\n",
              "      <td>0.940514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.96475</td>\n",
              "      <td>0.93116</td>\n",
              "      <td>0.942132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.963798</td>\n",
              "      <td>0.930387</td>\n",
              "      <td>0.941157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0.962328</td>\n",
              "      <td>0.929791</td>\n",
              "      <td>0.939917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   No. of Trees    LR Subsample %features Default Weight AUC Train AUC Test1  \\\n",
              "0            50  0.01       0.5       0.5              1  0.930578  0.918653   \n",
              "1            50  0.01       0.5       0.5              5  0.928086   0.91662   \n",
              "2            50  0.01       0.5       0.5             10  0.926039  0.914617   \n",
              "3            50  0.01       0.5         1              1  0.925662  0.912498   \n",
              "4            50  0.01       0.5         1              5   0.92363  0.911914   \n",
              "..          ...   ...       ...       ...            ...       ...       ...   \n",
              "67          500   0.1       0.8       0.5              5  0.961602  0.930949   \n",
              "68          500   0.1       0.8       0.5             10  0.960659  0.929978   \n",
              "69          500   0.1       0.8         1              1   0.96475   0.93116   \n",
              "70          500   0.1       0.8         1              5  0.963798  0.930387   \n",
              "71          500   0.1       0.8         1             10  0.962328  0.929791   \n",
              "\n",
              "   AUC Test2  \n",
              "0    0.93205  \n",
              "1   0.928584  \n",
              "2   0.925916  \n",
              "3   0.929065  \n",
              "4     0.9262  \n",
              "..       ...  \n",
              "67  0.941255  \n",
              "68  0.940514  \n",
              "69  0.942132  \n",
              "70  0.941157  \n",
              "71  0.939917  \n",
              "\n",
              "[72 rows x 8 columns]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1 = t.time()\n",
        "grid_search = pd.DataFrame(columns = ['No. of Trees', 'LR', 'Subsample', '%features', 'Default Weight', 'AUC Train', 'AUC Test1', 'AUC Test2'])\n",
        "num_trees = [50, 100, 300]\n",
        "lr = [0.01, .1]\n",
        "subsample = [.5, .8]\n",
        "feat = [.5, 1]\n",
        "def_w = [1, 5, 10]\n",
        "\n",
        "row = 0\n",
        "for i in num_trees:\n",
        "    for j in lr:\n",
        "        for k in subsample:\n",
        "            for f in feat:\n",
        "                for d in def_w:\n",
        "                    xgb_inst = xgb.XGBClassifier(n_estimators = i, learning_rate = j, subsample = k, colsample_bytree = f, scale_pos_weight = d, random_state = 21)\n",
        "                    model = xgb_inst.fit(xtrain, ytrain)\n",
        "                    print(row)\n",
        "                    grid_search.loc[row, 'No. of Trees'] = i \n",
        "                    grid_search.loc[row, 'LR'] = j \n",
        "                    grid_search.loc[row, 'Subsample'] = k \n",
        "                    grid_search.loc[row, '%features'] = f \n",
        "                    grid_search.loc[row, 'Default Weight'] = d \n",
        "                    grid_search.loc[row,\"AUC Train\"] = roc_auc_score(ytrain, model.predict_proba(xtrain)[:,1])\n",
        "                    grid_search.loc[row,\"AUC Test1\"] = roc_auc_score(ytest1, model.predict_proba(xtest1)[:,1])\n",
        "                    grid_search.loc[row,\"AUC Test2\"] = roc_auc_score(ytest2, model.predict_proba(xtest2)[:,1])\n",
        "                    row += 1\n",
        "                    \n",
        "t2 = t.time()  \n",
        "print(t2-t1)\n",
        "grid_search\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNho8SVs6kE3"
      },
      "outputs": [],
      "source": [
        "grid_search.to_csv(\"grid_search.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERdSDYYi6kE3",
        "outputId": "164d4d50-1e58-4d85-f366-db37ae8ec67a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.loc[0, '%features']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhX9y6Hp6kE4",
        "outputId": "bc97470f-c29c-4c22-9a90-7aded9efe80a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9305782740137187"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.iloc[0, -3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEzkRfeb6kE4",
        "outputId": "c583893f-e84f-4689-be1a-cbf9f6513b6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(72, 8)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09oQnlC96kE4"
      },
      "outputs": [],
      "source": [
        "xgb_inst = xgb.XGBClassifier(n_estimators = 300, learning_rate = 0.1, subsample = 0.8, colsample_bytree = 1, scale_pos_weight = 1, random_state = 21)\n",
        "final_xgb = xgb_inst.fit(xtrain, ytrain)\n",
        "final_xgb.save_model(\"final_xgb.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(ytrain, final_xgb.predict_proba(xtrain)[:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI-c8p2co3OZ",
        "outputId": "2c69d10b-7703-4efb-ef51-3eeb98928cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9584672254547199"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12xALGlO6kE4"
      },
      "source": [
        "### Neural Network "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest1 = pd.read_csv('xtest1.csv', index_col = False)\n",
        "xtest2 = pd.read_csv('xtest2.csv', index_col = False)\n",
        "ytest1 = pd.read_csv('ytest1.csv', index_col = False)\n",
        "ytest2 = pd.read_csv('ytest2.csv', index_col = False)\n",
        "ytrain = pd.read_csv('ytrain.csv', index_col = False)\n",
        "xtrain = pd.read_csv('xtrain.csv', index_col = False)"
      ],
      "metadata": {
        "id": "DVA-rh8U6-SS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtest1.shape, xtest2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX5KaBqf7w9p",
        "outputId": "e509b55c-27c4-427c-88cc-decade7e7e6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(61963, 46) (88750, 46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgoZGTsT6kE4"
      },
      "source": [
        "### Outlier Treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nP8_mPi76kE5",
        "outputId": "10808761-31cd-43b1-d975-5cae7dcfa14c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count      mean       std           min        1%       50%  \\\n",
              "D_132    41679.0  0.185275  0.265836 -1.454371e-02  0.001291  0.121890   \n",
              "P_3     302831.0  0.598577  0.173675 -1.165741e+00  0.000127  0.617261   \n",
              "D_44    296782.0  0.117314  0.218479  4.728746e-08  0.000153  0.007684   \n",
              "D_64_O  308200.0  0.534137  0.498834  0.000000e+00  0.000000  1.000000   \n",
              "D_52    307727.0  0.176831  0.173926 -7.016962e-03  0.003918  0.140216   \n",
              "P_2     306994.0  0.650984  0.242253 -3.842365e-01  0.020771  0.682384   \n",
              "D_56    166170.0  0.196983  0.216196 -1.698373e-02  0.002303  0.142647   \n",
              "B_23    308200.0  0.171912  0.229551  2.531639e-07  0.001415  0.061454   \n",
              "D_88      1669.0  0.188527  0.238895  3.874467e-04  0.002545  0.097316   \n",
              "R_1     308200.0  0.078054  0.223272  1.917514e-08  0.000114  0.005787   \n",
              "D_76     37730.0  0.138011  0.276755  2.859264e-06  0.000930  0.057812   \n",
              "D_110     2820.0  0.741713  0.307209 -2.361460e-02  0.004403  0.885398   \n",
              "D_77    247897.0  0.216554  0.223745  9.836166e-07  0.002064  0.156487   \n",
              "D_62    288770.0  0.186338  0.229363 -2.373225e-03  0.003425  0.090969   \n",
              "B_11    308200.0  0.111238  0.207826  3.709072e-08  0.000312  0.020457   \n",
              "B_2     308200.0  0.622262  0.399363  4.737755e-07  0.003043  0.814274   \n",
              "D_51    308200.0  0.140837  0.238865  5.615784e-08  0.000146  0.007198   \n",
              "D_108    14580.0  0.056500  0.269965  5.256835e-07  0.000102  0.005250   \n",
              "S_3     271064.0  0.230520  0.193320 -5.420518e-01  0.009092  0.167233   \n",
              "D_50    141755.0  0.173395  0.584548 -5.450931e+00  0.001183  0.106347   \n",
              "R_3     308200.0  0.129858  0.222064  8.656186e-08  0.000198  0.009781   \n",
              "B_3     308200.0  0.128139  0.230726  1.498946e-07  0.000251  0.009654   \n",
              "D_49     41681.0  0.180330  0.365557  6.079387e-06  0.001914  0.118355   \n",
              "D_66     40670.0  0.892796  0.309377  0.000000e+00  0.000000  1.000000   \n",
              "B_38    308200.0  2.674666  1.580032  1.000000e+00  1.000000  2.000000   \n",
              "D_75    308200.0  0.170488  0.222861  1.921960e-07  0.000264  0.074466   \n",
              "D_53     98934.0  0.074736  0.192430  1.134726e-07  0.000266  0.014120   \n",
              "B_1     308200.0  0.124854  0.211851 -1.024709e+00  0.000498  0.032656   \n",
              "B_4     308200.0  0.168940  0.218007  2.796505e-07  0.000722  0.081179   \n",
              "D_111     2820.0  0.870069  0.273924  3.187095e-05  0.001344  1.003597   \n",
              "D_134    23833.0  0.331953  0.298286 -1.027506e-02  0.004554  0.218477   \n",
              "D_41    308200.0  0.053876  0.185027  6.039876e-08  0.000111  0.005688   \n",
              "B_17    168072.0  0.683584  0.415239  1.197814e-06  0.000453  0.942914   \n",
              "D_46    262391.0  0.476523  0.167404 -6.931337e+00  0.026468  0.460216   \n",
              "B_5     308200.0  0.081539  0.388099  8.843823e-08  0.000396  0.014784   \n",
              "D_43    244213.0  0.153635  0.214677  1.154550e-07  0.002268  0.087308   \n",
              "S_23    308200.0  0.177946  0.844857 -1.305714e+02  0.009549  0.136207   \n",
              "B_9     308200.0  0.192058  0.284357  3.926994e-08  0.000233  0.028829   \n",
              "D_48    289548.0  0.369760  0.325287 -9.608557e-03  0.000365  0.267662   \n",
              "R_27    300080.0  0.888676  0.318401 -1.645560e-02  0.004130  1.004330   \n",
              "B_18    308200.0  0.598438  0.362492  5.891222e-08  0.003774  0.646939   \n",
              "D_112   308200.0  0.848987  0.362036  4.567701e-07  0.001928  1.004055   \n",
              "D_47    308200.0  0.399712  0.236432 -2.661874e-02 -0.003691  0.374927   \n",
              "D_45    308200.0  0.242433  0.242739  7.336260e-07  0.003059  0.163758   \n",
              "D_42     73138.0  0.180582  0.226577 -3.155777e-04  0.002601  0.116797   \n",
              "S_24    308191.0  0.734830  0.999126 -9.048063e+01  0.005351  0.949905   \n",
              "\n",
              "             99%         max  \n",
              "D_132   1.053642    5.934922  \n",
              "P_3     1.007184    2.100572  \n",
              "D_44    1.004810    5.634724  \n",
              "D_64_O  1.000000    1.000000  \n",
              "D_52    1.005973    1.009999  \n",
              "P_2     1.005636    1.009999  \n",
              "D_56    0.993570   10.956514  \n",
              "B_23    1.019665    1.471304  \n",
              "D_88    1.077990    2.669250  \n",
              "R_1     1.008829    2.758340  \n",
              "D_76    0.957633   15.131427  \n",
              "D_110   1.009673    1.009997  \n",
              "D_77    0.998713   10.009623  \n",
              "D_62    0.990181   10.857220  \n",
              "B_11    1.003614    1.559352  \n",
              "B_2     1.009678    1.010000  \n",
              "D_51    1.006524    2.673389  \n",
              "D_108   1.008881    7.000904  \n",
              "S_3     1.011838    4.882418  \n",
              "D_50    1.027824  103.129809  \n",
              "R_3     1.006301    9.709850  \n",
              "B_3     0.995186    1.513551  \n",
              "D_49    0.966067   45.840118  \n",
              "D_66    1.000000    1.000000  \n",
              "B_38    7.000000    7.000000  \n",
              "D_75    1.003377    4.270527  \n",
              "D_53    0.946242    6.171899  \n",
              "B_1     1.005669    1.324058  \n",
              "B_4     0.987586    3.591951  \n",
              "D_111   1.009883    1.009998  \n",
              "D_134   1.008763    1.009998  \n",
              "D_41    0.901434    7.139698  \n",
              "B_17    1.009729    1.010000  \n",
              "D_46    0.993105   16.319901  \n",
              "B_5     0.996049   68.707425  \n",
              "D_43    1.011034    9.343202  \n",
              "S_23    0.985121  423.436222  \n",
              "B_9     1.007330   13.974121  \n",
              "D_48    1.000338    8.964546  \n",
              "R_27    1.009884    1.010000  \n",
              "B_18    1.009723    1.010000  \n",
              "D_112   1.009885    1.010000  \n",
              "D_47    1.002942    1.639532  \n",
              "D_45    1.002119    1.594811  \n",
              "D_42    0.997904    4.190794  \n",
              "S_24    1.006088    1.054287  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-819621bd-1930-4c00-86fa-24f815299627\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>1%</th>\n",
              "      <th>50%</th>\n",
              "      <th>99%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D_132</th>\n",
              "      <td>41679.0</td>\n",
              "      <td>0.185275</td>\n",
              "      <td>0.265836</td>\n",
              "      <td>-1.454371e-02</td>\n",
              "      <td>0.001291</td>\n",
              "      <td>0.121890</td>\n",
              "      <td>1.053642</td>\n",
              "      <td>5.934922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_3</th>\n",
              "      <td>302831.0</td>\n",
              "      <td>0.598577</td>\n",
              "      <td>0.173675</td>\n",
              "      <td>-1.165741e+00</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.617261</td>\n",
              "      <td>1.007184</td>\n",
              "      <td>2.100572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_44</th>\n",
              "      <td>296782.0</td>\n",
              "      <td>0.117314</td>\n",
              "      <td>0.218479</td>\n",
              "      <td>4.728746e-08</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.007684</td>\n",
              "      <td>1.004810</td>\n",
              "      <td>5.634724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_64_O</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.534137</td>\n",
              "      <td>0.498834</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_52</th>\n",
              "      <td>307727.0</td>\n",
              "      <td>0.176831</td>\n",
              "      <td>0.173926</td>\n",
              "      <td>-7.016962e-03</td>\n",
              "      <td>0.003918</td>\n",
              "      <td>0.140216</td>\n",
              "      <td>1.005973</td>\n",
              "      <td>1.009999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>306994.0</td>\n",
              "      <td>0.650984</td>\n",
              "      <td>0.242253</td>\n",
              "      <td>-3.842365e-01</td>\n",
              "      <td>0.020771</td>\n",
              "      <td>0.682384</td>\n",
              "      <td>1.005636</td>\n",
              "      <td>1.009999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_56</th>\n",
              "      <td>166170.0</td>\n",
              "      <td>0.196983</td>\n",
              "      <td>0.216196</td>\n",
              "      <td>-1.698373e-02</td>\n",
              "      <td>0.002303</td>\n",
              "      <td>0.142647</td>\n",
              "      <td>0.993570</td>\n",
              "      <td>10.956514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_23</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.171912</td>\n",
              "      <td>0.229551</td>\n",
              "      <td>2.531639e-07</td>\n",
              "      <td>0.001415</td>\n",
              "      <td>0.061454</td>\n",
              "      <td>1.019665</td>\n",
              "      <td>1.471304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_88</th>\n",
              "      <td>1669.0</td>\n",
              "      <td>0.188527</td>\n",
              "      <td>0.238895</td>\n",
              "      <td>3.874467e-04</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>0.097316</td>\n",
              "      <td>1.077990</td>\n",
              "      <td>2.669250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_1</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.078054</td>\n",
              "      <td>0.223272</td>\n",
              "      <td>1.917514e-08</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.005787</td>\n",
              "      <td>1.008829</td>\n",
              "      <td>2.758340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_76</th>\n",
              "      <td>37730.0</td>\n",
              "      <td>0.138011</td>\n",
              "      <td>0.276755</td>\n",
              "      <td>2.859264e-06</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.057812</td>\n",
              "      <td>0.957633</td>\n",
              "      <td>15.131427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_110</th>\n",
              "      <td>2820.0</td>\n",
              "      <td>0.741713</td>\n",
              "      <td>0.307209</td>\n",
              "      <td>-2.361460e-02</td>\n",
              "      <td>0.004403</td>\n",
              "      <td>0.885398</td>\n",
              "      <td>1.009673</td>\n",
              "      <td>1.009997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_77</th>\n",
              "      <td>247897.0</td>\n",
              "      <td>0.216554</td>\n",
              "      <td>0.223745</td>\n",
              "      <td>9.836166e-07</td>\n",
              "      <td>0.002064</td>\n",
              "      <td>0.156487</td>\n",
              "      <td>0.998713</td>\n",
              "      <td>10.009623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_62</th>\n",
              "      <td>288770.0</td>\n",
              "      <td>0.186338</td>\n",
              "      <td>0.229363</td>\n",
              "      <td>-2.373225e-03</td>\n",
              "      <td>0.003425</td>\n",
              "      <td>0.090969</td>\n",
              "      <td>0.990181</td>\n",
              "      <td>10.857220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_11</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.111238</td>\n",
              "      <td>0.207826</td>\n",
              "      <td>3.709072e-08</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.020457</td>\n",
              "      <td>1.003614</td>\n",
              "      <td>1.559352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_2</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.622262</td>\n",
              "      <td>0.399363</td>\n",
              "      <td>4.737755e-07</td>\n",
              "      <td>0.003043</td>\n",
              "      <td>0.814274</td>\n",
              "      <td>1.009678</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_51</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.140837</td>\n",
              "      <td>0.238865</td>\n",
              "      <td>5.615784e-08</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.007198</td>\n",
              "      <td>1.006524</td>\n",
              "      <td>2.673389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_108</th>\n",
              "      <td>14580.0</td>\n",
              "      <td>0.056500</td>\n",
              "      <td>0.269965</td>\n",
              "      <td>5.256835e-07</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.005250</td>\n",
              "      <td>1.008881</td>\n",
              "      <td>7.000904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S_3</th>\n",
              "      <td>271064.0</td>\n",
              "      <td>0.230520</td>\n",
              "      <td>0.193320</td>\n",
              "      <td>-5.420518e-01</td>\n",
              "      <td>0.009092</td>\n",
              "      <td>0.167233</td>\n",
              "      <td>1.011838</td>\n",
              "      <td>4.882418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_50</th>\n",
              "      <td>141755.0</td>\n",
              "      <td>0.173395</td>\n",
              "      <td>0.584548</td>\n",
              "      <td>-5.450931e+00</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.106347</td>\n",
              "      <td>1.027824</td>\n",
              "      <td>103.129809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_3</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.129858</td>\n",
              "      <td>0.222064</td>\n",
              "      <td>8.656186e-08</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.009781</td>\n",
              "      <td>1.006301</td>\n",
              "      <td>9.709850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_3</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.128139</td>\n",
              "      <td>0.230726</td>\n",
              "      <td>1.498946e-07</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.009654</td>\n",
              "      <td>0.995186</td>\n",
              "      <td>1.513551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_49</th>\n",
              "      <td>41681.0</td>\n",
              "      <td>0.180330</td>\n",
              "      <td>0.365557</td>\n",
              "      <td>6.079387e-06</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.118355</td>\n",
              "      <td>0.966067</td>\n",
              "      <td>45.840118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_66</th>\n",
              "      <td>40670.0</td>\n",
              "      <td>0.892796</td>\n",
              "      <td>0.309377</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_38</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>2.674666</td>\n",
              "      <td>1.580032</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_75</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.170488</td>\n",
              "      <td>0.222861</td>\n",
              "      <td>1.921960e-07</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.074466</td>\n",
              "      <td>1.003377</td>\n",
              "      <td>4.270527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_53</th>\n",
              "      <td>98934.0</td>\n",
              "      <td>0.074736</td>\n",
              "      <td>0.192430</td>\n",
              "      <td>1.134726e-07</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.014120</td>\n",
              "      <td>0.946242</td>\n",
              "      <td>6.171899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_1</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.124854</td>\n",
              "      <td>0.211851</td>\n",
              "      <td>-1.024709e+00</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.032656</td>\n",
              "      <td>1.005669</td>\n",
              "      <td>1.324058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_4</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.168940</td>\n",
              "      <td>0.218007</td>\n",
              "      <td>2.796505e-07</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.081179</td>\n",
              "      <td>0.987586</td>\n",
              "      <td>3.591951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_111</th>\n",
              "      <td>2820.0</td>\n",
              "      <td>0.870069</td>\n",
              "      <td>0.273924</td>\n",
              "      <td>3.187095e-05</td>\n",
              "      <td>0.001344</td>\n",
              "      <td>1.003597</td>\n",
              "      <td>1.009883</td>\n",
              "      <td>1.009998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_134</th>\n",
              "      <td>23833.0</td>\n",
              "      <td>0.331953</td>\n",
              "      <td>0.298286</td>\n",
              "      <td>-1.027506e-02</td>\n",
              "      <td>0.004554</td>\n",
              "      <td>0.218477</td>\n",
              "      <td>1.008763</td>\n",
              "      <td>1.009998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_41</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.053876</td>\n",
              "      <td>0.185027</td>\n",
              "      <td>6.039876e-08</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.005688</td>\n",
              "      <td>0.901434</td>\n",
              "      <td>7.139698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_17</th>\n",
              "      <td>168072.0</td>\n",
              "      <td>0.683584</td>\n",
              "      <td>0.415239</td>\n",
              "      <td>1.197814e-06</td>\n",
              "      <td>0.000453</td>\n",
              "      <td>0.942914</td>\n",
              "      <td>1.009729</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_46</th>\n",
              "      <td>262391.0</td>\n",
              "      <td>0.476523</td>\n",
              "      <td>0.167404</td>\n",
              "      <td>-6.931337e+00</td>\n",
              "      <td>0.026468</td>\n",
              "      <td>0.460216</td>\n",
              "      <td>0.993105</td>\n",
              "      <td>16.319901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_5</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.081539</td>\n",
              "      <td>0.388099</td>\n",
              "      <td>8.843823e-08</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.014784</td>\n",
              "      <td>0.996049</td>\n",
              "      <td>68.707425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_43</th>\n",
              "      <td>244213.0</td>\n",
              "      <td>0.153635</td>\n",
              "      <td>0.214677</td>\n",
              "      <td>1.154550e-07</td>\n",
              "      <td>0.002268</td>\n",
              "      <td>0.087308</td>\n",
              "      <td>1.011034</td>\n",
              "      <td>9.343202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S_23</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.177946</td>\n",
              "      <td>0.844857</td>\n",
              "      <td>-1.305714e+02</td>\n",
              "      <td>0.009549</td>\n",
              "      <td>0.136207</td>\n",
              "      <td>0.985121</td>\n",
              "      <td>423.436222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_9</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.192058</td>\n",
              "      <td>0.284357</td>\n",
              "      <td>3.926994e-08</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.028829</td>\n",
              "      <td>1.007330</td>\n",
              "      <td>13.974121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_48</th>\n",
              "      <td>289548.0</td>\n",
              "      <td>0.369760</td>\n",
              "      <td>0.325287</td>\n",
              "      <td>-9.608557e-03</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.267662</td>\n",
              "      <td>1.000338</td>\n",
              "      <td>8.964546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_27</th>\n",
              "      <td>300080.0</td>\n",
              "      <td>0.888676</td>\n",
              "      <td>0.318401</td>\n",
              "      <td>-1.645560e-02</td>\n",
              "      <td>0.004130</td>\n",
              "      <td>1.004330</td>\n",
              "      <td>1.009884</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_18</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.598438</td>\n",
              "      <td>0.362492</td>\n",
              "      <td>5.891222e-08</td>\n",
              "      <td>0.003774</td>\n",
              "      <td>0.646939</td>\n",
              "      <td>1.009723</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_112</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.848987</td>\n",
              "      <td>0.362036</td>\n",
              "      <td>4.567701e-07</td>\n",
              "      <td>0.001928</td>\n",
              "      <td>1.004055</td>\n",
              "      <td>1.009885</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_47</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.399712</td>\n",
              "      <td>0.236432</td>\n",
              "      <td>-2.661874e-02</td>\n",
              "      <td>-0.003691</td>\n",
              "      <td>0.374927</td>\n",
              "      <td>1.002942</td>\n",
              "      <td>1.639532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_45</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.242433</td>\n",
              "      <td>0.242739</td>\n",
              "      <td>7.336260e-07</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.163758</td>\n",
              "      <td>1.002119</td>\n",
              "      <td>1.594811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_42</th>\n",
              "      <td>73138.0</td>\n",
              "      <td>0.180582</td>\n",
              "      <td>0.226577</td>\n",
              "      <td>-3.155777e-04</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.116797</td>\n",
              "      <td>0.997904</td>\n",
              "      <td>4.190794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S_24</th>\n",
              "      <td>308191.0</td>\n",
              "      <td>0.734830</td>\n",
              "      <td>0.999126</td>\n",
              "      <td>-9.048063e+01</td>\n",
              "      <td>0.005351</td>\n",
              "      <td>0.949905</td>\n",
              "      <td>1.006088</td>\n",
              "      <td>1.054287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-819621bd-1930-4c00-86fa-24f815299627')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-819621bd-1930-4c00-86fa-24f815299627 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-819621bd-1930-4c00-86fa-24f815299627');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "xtrain.describe(percentiles = [.01, .99]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgkifXh96kE5",
        "outputId": "f6763c43-7e0d-485b-a889-11135b242a57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "D_132     1.053642\n",
              "P_3       1.007184\n",
              "D_44      1.004810\n",
              "D_64_O    1.000000\n",
              "D_52      1.005973\n",
              "P_2       1.005636\n",
              "D_56      0.993570\n",
              "B_23      1.019665\n",
              "D_88      1.077990\n",
              "R_1       1.008829\n",
              "D_76      0.957633\n",
              "D_110     1.009673\n",
              "D_77      0.998713\n",
              "D_62      0.990181\n",
              "B_11      1.003614\n",
              "B_2       1.009678\n",
              "D_51      1.006524\n",
              "D_108     1.008881\n",
              "S_3       1.011838\n",
              "D_50      1.027824\n",
              "R_3       1.006301\n",
              "B_3       0.995186\n",
              "D_49      0.966067\n",
              "D_66      1.000000\n",
              "B_38      7.000000\n",
              "D_75      1.003377\n",
              "D_53      0.946242\n",
              "B_1       1.005669\n",
              "B_4       0.987586\n",
              "D_111     1.009883\n",
              "D_134     1.008763\n",
              "D_41      0.901434\n",
              "B_17      1.009729\n",
              "D_46      0.993105\n",
              "B_5       0.996049\n",
              "D_43      1.011034\n",
              "S_23      0.985121\n",
              "B_9       1.007330\n",
              "D_48      1.000338\n",
              "R_27      1.009884\n",
              "B_18      1.009723\n",
              "D_112     1.009885\n",
              "D_47      1.002942\n",
              "D_45      1.002119\n",
              "D_42      0.997904\n",
              "S_24      1.006088\n",
              "Name: 0.99, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "xtrain.quantile(0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p3Vu7rKX6kE5"
      },
      "outputs": [],
      "source": [
        "for i in xtrain.columns:\n",
        "    xtrain[i] = np.where(xtrain[i] > xtrain[i].quantile(0.99), xtrain[i].quantile(0.99), xtrain[i] )\n",
        "    xtrain[i] = np.where(xtrain[i] < xtrain[i].quantile(0.01), xtrain[i].quantile(0.01), xtrain[i] )\n",
        "\n",
        "for i in xtest1.columns:\n",
        "    xtest1[i] = np.where(xtest1[i] > xtest1[i].quantile(0.99), xtest1[i].quantile(0.99), xtest1[i] )\n",
        "    xtest1[i] = np.where(xtest1[i] < xtest1[i].quantile(0.01), xtest1[i].quantile(0.01), xtest1[i] )\n",
        "\n",
        "for i in xtest2.columns:\n",
        "    xtest2[i] = np.where(xtest2[i] > xtest2[i].quantile(0.99), xtest2[i].quantile(0.99), xtest2[i] )\n",
        "    xtest2[i] = np.where(xtest2[i] < xtest2[i].quantile(0.01), xtest2[i].quantile(0.01), xtest2[i] )\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y4gGE6Jj6kE5",
        "outputId": "28318fe4-2cb0-4a4b-df17-c119cdbc92a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count      mean       std       min        1%       50%       99%  \\\n",
              "D_132    41679.0  0.174952  0.178497  0.001291  0.001295  0.121890  1.053607   \n",
              "P_3     302831.0  0.599173  0.161003  0.000127  0.000132  0.617261  1.007183   \n",
              "D_44    296782.0  0.114555  0.202797  0.000153  0.000153  0.007684  1.004808   \n",
              "D_64_O  308200.0  0.534137  0.498834  0.000000  0.000000  1.000000  1.000000   \n",
              "D_52    307727.0  0.176842  0.173802  0.003918  0.003918  0.140216  1.005973   \n",
              "P_2     306994.0  0.651830  0.239698  0.020771  0.020772  0.682384  1.005636   \n",
              "D_56    166170.0  0.192139  0.172434  0.002303  0.002305  0.142647  0.993395   \n",
              "B_23    308200.0  0.170646  0.224239  0.001415  0.001415  0.061454  1.019663   \n",
              "D_88      1669.0  0.185404  0.221173  0.002545  0.002568  0.097316  1.073307   \n",
              "R_1     308200.0  0.074105  0.200294  0.000114  0.000114  0.005787  1.008829   \n",
              "D_76     37730.0  0.128832  0.182618  0.000930  0.000930  0.057812  0.956921   \n",
              "D_110     2820.0  0.741905  0.306735  0.004403  0.004443  0.885398  1.009673   \n",
              "D_77    247897.0  0.214145  0.206667  0.002064  0.002065  0.156487  0.998703   \n",
              "D_62    288770.0  0.183435  0.209629  0.003425  0.003425  0.090969  0.990162   \n",
              "B_11    308200.0  0.109417  0.198554  0.000312  0.000312  0.020457  1.003613   \n",
              "B_2     308200.0  0.622276  0.399339  0.003043  0.003043  0.814274  1.009678   \n",
              "D_51    308200.0  0.138911  0.229792  0.000146  0.000146  0.007198  1.006524   \n",
              "D_108    14580.0  0.048358  0.203769  0.000102  0.000102  0.005250  1.008879   \n",
              "S_3     271064.0  0.228263  0.177382  0.009092  0.009110  0.167233  1.011785   \n",
              "D_50    141755.0  0.153694  0.159126  0.001183  0.001183  0.106347  1.027792   \n",
              "R_3     308200.0  0.125398  0.190070  0.000198  0.000198  0.009781  1.006301   \n",
              "B_3     308200.0  0.127110  0.226426  0.000251  0.000251  0.009654  0.995186   \n",
              "D_49     41681.0  0.173147  0.175771  0.001914  0.001914  0.118355  0.966047   \n",
              "D_66     40670.0  0.892796  0.309377  0.000000  0.000000  1.000000  1.000000   \n",
              "B_38    308200.0  2.674666  1.580032  1.000000  1.000000  2.000000  7.000000   \n",
              "D_75    308200.0  0.168008  0.210234  0.000264  0.000264  0.074466  1.003377   \n",
              "D_53     98934.0  0.069690  0.149719  0.000266  0.000266  0.014120  0.945920   \n",
              "B_1     308200.0  0.123224  0.203733  0.000498  0.000498  0.032656  1.005668   \n",
              "B_4     308200.0  0.166337  0.204398  0.000722  0.000722  0.081179  0.987586   \n",
              "D_111     2820.0  0.870076  0.273901  0.001344  0.001355  1.003597  1.009882   \n",
              "D_134    23833.0  0.331998  0.298214  0.004554  0.004556  0.218477  1.008760   \n",
              "D_41    308200.0  0.049294  0.146404  0.000111  0.000111  0.005688  0.901434   \n",
              "B_17    168072.0  0.683585  0.415234  0.000453  0.000453  0.942914  1.009728   \n",
              "D_46    262391.0  0.476228  0.131030  0.026468  0.026469  0.460216  0.993097   \n",
              "B_5     308200.0  0.069326  0.151912  0.000396  0.000396  0.014784  0.996048   \n",
              "D_43    244213.0  0.148887  0.178136  0.002268  0.002268  0.087308  1.011033   \n",
              "S_23    308200.0  0.173022  0.147879  0.009549  0.009550  0.136207  0.985121   \n",
              "B_9     308200.0  0.187415  0.254222  0.000233  0.000233  0.028829  1.007329   \n",
              "D_48    289548.0  0.368731  0.322137  0.000365  0.000365  0.267662  1.000337   \n",
              "R_27    300080.0  0.888718  0.318281  0.004130  0.004130  1.004330  1.009884   \n",
              "B_18    308200.0  0.598455  0.362459  0.003774  0.003774  0.646939  1.009723   \n",
              "D_112   308200.0  0.848995  0.362016  0.001928  0.001928  1.004055  1.009885   \n",
              "D_47    308200.0  0.399168  0.234274 -0.003691 -0.003691  0.374927  1.002942   \n",
              "D_45    308200.0  0.241072  0.237708  0.003059  0.003059  0.163758  1.002119   \n",
              "D_42     73138.0  0.175411  0.190886  0.002601  0.002601  0.116797  0.997772   \n",
              "S_24    308191.0  0.748562  0.370483  0.005351  0.005351  0.949905  1.006088   \n",
              "\n",
              "             max  \n",
              "D_132   1.053642  \n",
              "P_3     1.007184  \n",
              "D_44    1.004810  \n",
              "D_64_O  1.000000  \n",
              "D_52    1.005973  \n",
              "P_2     1.005636  \n",
              "D_56    0.993570  \n",
              "B_23    1.019665  \n",
              "D_88    1.077990  \n",
              "R_1     1.008829  \n",
              "D_76    0.957633  \n",
              "D_110   1.009673  \n",
              "D_77    0.998713  \n",
              "D_62    0.990181  \n",
              "B_11    1.003614  \n",
              "B_2     1.009678  \n",
              "D_51    1.006524  \n",
              "D_108   1.008881  \n",
              "S_3     1.011838  \n",
              "D_50    1.027824  \n",
              "R_3     1.006301  \n",
              "B_3     0.995186  \n",
              "D_49    0.966067  \n",
              "D_66    1.000000  \n",
              "B_38    7.000000  \n",
              "D_75    1.003377  \n",
              "D_53    0.946242  \n",
              "B_1     1.005669  \n",
              "B_4     0.987586  \n",
              "D_111   1.009883  \n",
              "D_134   1.008763  \n",
              "D_41    0.901434  \n",
              "B_17    1.009729  \n",
              "D_46    0.993105  \n",
              "B_5     0.996049  \n",
              "D_43    1.011034  \n",
              "S_23    0.985121  \n",
              "B_9     1.007330  \n",
              "D_48    1.000338  \n",
              "R_27    1.009884  \n",
              "B_18    1.009723  \n",
              "D_112   1.009885  \n",
              "D_47    1.002942  \n",
              "D_45    1.002119  \n",
              "D_42    0.997904  \n",
              "S_24    1.006088  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae839aa4-7304-4374-ac62-f87e829e20df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>1%</th>\n",
              "      <th>50%</th>\n",
              "      <th>99%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D_132</th>\n",
              "      <td>41679.0</td>\n",
              "      <td>0.174952</td>\n",
              "      <td>0.178497</td>\n",
              "      <td>0.001291</td>\n",
              "      <td>0.001295</td>\n",
              "      <td>0.121890</td>\n",
              "      <td>1.053607</td>\n",
              "      <td>1.053642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_3</th>\n",
              "      <td>302831.0</td>\n",
              "      <td>0.599173</td>\n",
              "      <td>0.161003</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.617261</td>\n",
              "      <td>1.007183</td>\n",
              "      <td>1.007184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_44</th>\n",
              "      <td>296782.0</td>\n",
              "      <td>0.114555</td>\n",
              "      <td>0.202797</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.007684</td>\n",
              "      <td>1.004808</td>\n",
              "      <td>1.004810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_64_O</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.534137</td>\n",
              "      <td>0.498834</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_52</th>\n",
              "      <td>307727.0</td>\n",
              "      <td>0.176842</td>\n",
              "      <td>0.173802</td>\n",
              "      <td>0.003918</td>\n",
              "      <td>0.003918</td>\n",
              "      <td>0.140216</td>\n",
              "      <td>1.005973</td>\n",
              "      <td>1.005973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>306994.0</td>\n",
              "      <td>0.651830</td>\n",
              "      <td>0.239698</td>\n",
              "      <td>0.020771</td>\n",
              "      <td>0.020772</td>\n",
              "      <td>0.682384</td>\n",
              "      <td>1.005636</td>\n",
              "      <td>1.005636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_56</th>\n",
              "      <td>166170.0</td>\n",
              "      <td>0.192139</td>\n",
              "      <td>0.172434</td>\n",
              "      <td>0.002303</td>\n",
              "      <td>0.002305</td>\n",
              "      <td>0.142647</td>\n",
              "      <td>0.993395</td>\n",
              "      <td>0.993570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_23</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.170646</td>\n",
              "      <td>0.224239</td>\n",
              "      <td>0.001415</td>\n",
              "      <td>0.001415</td>\n",
              "      <td>0.061454</td>\n",
              "      <td>1.019663</td>\n",
              "      <td>1.019665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_88</th>\n",
              "      <td>1669.0</td>\n",
              "      <td>0.185404</td>\n",
              "      <td>0.221173</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>0.002568</td>\n",
              "      <td>0.097316</td>\n",
              "      <td>1.073307</td>\n",
              "      <td>1.077990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_1</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.074105</td>\n",
              "      <td>0.200294</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.005787</td>\n",
              "      <td>1.008829</td>\n",
              "      <td>1.008829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_76</th>\n",
              "      <td>37730.0</td>\n",
              "      <td>0.128832</td>\n",
              "      <td>0.182618</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.057812</td>\n",
              "      <td>0.956921</td>\n",
              "      <td>0.957633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_110</th>\n",
              "      <td>2820.0</td>\n",
              "      <td>0.741905</td>\n",
              "      <td>0.306735</td>\n",
              "      <td>0.004403</td>\n",
              "      <td>0.004443</td>\n",
              "      <td>0.885398</td>\n",
              "      <td>1.009673</td>\n",
              "      <td>1.009673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_77</th>\n",
              "      <td>247897.0</td>\n",
              "      <td>0.214145</td>\n",
              "      <td>0.206667</td>\n",
              "      <td>0.002064</td>\n",
              "      <td>0.002065</td>\n",
              "      <td>0.156487</td>\n",
              "      <td>0.998703</td>\n",
              "      <td>0.998713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_62</th>\n",
              "      <td>288770.0</td>\n",
              "      <td>0.183435</td>\n",
              "      <td>0.209629</td>\n",
              "      <td>0.003425</td>\n",
              "      <td>0.003425</td>\n",
              "      <td>0.090969</td>\n",
              "      <td>0.990162</td>\n",
              "      <td>0.990181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_11</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.109417</td>\n",
              "      <td>0.198554</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.020457</td>\n",
              "      <td>1.003613</td>\n",
              "      <td>1.003614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_2</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.622276</td>\n",
              "      <td>0.399339</td>\n",
              "      <td>0.003043</td>\n",
              "      <td>0.003043</td>\n",
              "      <td>0.814274</td>\n",
              "      <td>1.009678</td>\n",
              "      <td>1.009678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_51</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.138911</td>\n",
              "      <td>0.229792</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.007198</td>\n",
              "      <td>1.006524</td>\n",
              "      <td>1.006524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_108</th>\n",
              "      <td>14580.0</td>\n",
              "      <td>0.048358</td>\n",
              "      <td>0.203769</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.005250</td>\n",
              "      <td>1.008879</td>\n",
              "      <td>1.008881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S_3</th>\n",
              "      <td>271064.0</td>\n",
              "      <td>0.228263</td>\n",
              "      <td>0.177382</td>\n",
              "      <td>0.009092</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.167233</td>\n",
              "      <td>1.011785</td>\n",
              "      <td>1.011838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_50</th>\n",
              "      <td>141755.0</td>\n",
              "      <td>0.153694</td>\n",
              "      <td>0.159126</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.106347</td>\n",
              "      <td>1.027792</td>\n",
              "      <td>1.027824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_3</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.125398</td>\n",
              "      <td>0.190070</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.009781</td>\n",
              "      <td>1.006301</td>\n",
              "      <td>1.006301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_3</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.127110</td>\n",
              "      <td>0.226426</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.009654</td>\n",
              "      <td>0.995186</td>\n",
              "      <td>0.995186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_49</th>\n",
              "      <td>41681.0</td>\n",
              "      <td>0.173147</td>\n",
              "      <td>0.175771</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.118355</td>\n",
              "      <td>0.966047</td>\n",
              "      <td>0.966067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_66</th>\n",
              "      <td>40670.0</td>\n",
              "      <td>0.892796</td>\n",
              "      <td>0.309377</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_38</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>2.674666</td>\n",
              "      <td>1.580032</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_75</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.168008</td>\n",
              "      <td>0.210234</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.074466</td>\n",
              "      <td>1.003377</td>\n",
              "      <td>1.003377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_53</th>\n",
              "      <td>98934.0</td>\n",
              "      <td>0.069690</td>\n",
              "      <td>0.149719</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.014120</td>\n",
              "      <td>0.945920</td>\n",
              "      <td>0.946242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_1</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.123224</td>\n",
              "      <td>0.203733</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.032656</td>\n",
              "      <td>1.005668</td>\n",
              "      <td>1.005669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_4</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.166337</td>\n",
              "      <td>0.204398</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.081179</td>\n",
              "      <td>0.987586</td>\n",
              "      <td>0.987586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_111</th>\n",
              "      <td>2820.0</td>\n",
              "      <td>0.870076</td>\n",
              "      <td>0.273901</td>\n",
              "      <td>0.001344</td>\n",
              "      <td>0.001355</td>\n",
              "      <td>1.003597</td>\n",
              "      <td>1.009882</td>\n",
              "      <td>1.009883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_134</th>\n",
              "      <td>23833.0</td>\n",
              "      <td>0.331998</td>\n",
              "      <td>0.298214</td>\n",
              "      <td>0.004554</td>\n",
              "      <td>0.004556</td>\n",
              "      <td>0.218477</td>\n",
              "      <td>1.008760</td>\n",
              "      <td>1.008763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_41</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.049294</td>\n",
              "      <td>0.146404</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.005688</td>\n",
              "      <td>0.901434</td>\n",
              "      <td>0.901434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_17</th>\n",
              "      <td>168072.0</td>\n",
              "      <td>0.683585</td>\n",
              "      <td>0.415234</td>\n",
              "      <td>0.000453</td>\n",
              "      <td>0.000453</td>\n",
              "      <td>0.942914</td>\n",
              "      <td>1.009728</td>\n",
              "      <td>1.009729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_46</th>\n",
              "      <td>262391.0</td>\n",
              "      <td>0.476228</td>\n",
              "      <td>0.131030</td>\n",
              "      <td>0.026468</td>\n",
              "      <td>0.026469</td>\n",
              "      <td>0.460216</td>\n",
              "      <td>0.993097</td>\n",
              "      <td>0.993105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_5</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.069326</td>\n",
              "      <td>0.151912</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.014784</td>\n",
              "      <td>0.996048</td>\n",
              "      <td>0.996049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_43</th>\n",
              "      <td>244213.0</td>\n",
              "      <td>0.148887</td>\n",
              "      <td>0.178136</td>\n",
              "      <td>0.002268</td>\n",
              "      <td>0.002268</td>\n",
              "      <td>0.087308</td>\n",
              "      <td>1.011033</td>\n",
              "      <td>1.011034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S_23</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.173022</td>\n",
              "      <td>0.147879</td>\n",
              "      <td>0.009549</td>\n",
              "      <td>0.009550</td>\n",
              "      <td>0.136207</td>\n",
              "      <td>0.985121</td>\n",
              "      <td>0.985121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_9</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.187415</td>\n",
              "      <td>0.254222</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.028829</td>\n",
              "      <td>1.007329</td>\n",
              "      <td>1.007330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_48</th>\n",
              "      <td>289548.0</td>\n",
              "      <td>0.368731</td>\n",
              "      <td>0.322137</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.267662</td>\n",
              "      <td>1.000337</td>\n",
              "      <td>1.000338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_27</th>\n",
              "      <td>300080.0</td>\n",
              "      <td>0.888718</td>\n",
              "      <td>0.318281</td>\n",
              "      <td>0.004130</td>\n",
              "      <td>0.004130</td>\n",
              "      <td>1.004330</td>\n",
              "      <td>1.009884</td>\n",
              "      <td>1.009884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_18</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.598455</td>\n",
              "      <td>0.362459</td>\n",
              "      <td>0.003774</td>\n",
              "      <td>0.003774</td>\n",
              "      <td>0.646939</td>\n",
              "      <td>1.009723</td>\n",
              "      <td>1.009723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_112</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.848995</td>\n",
              "      <td>0.362016</td>\n",
              "      <td>0.001928</td>\n",
              "      <td>0.001928</td>\n",
              "      <td>1.004055</td>\n",
              "      <td>1.009885</td>\n",
              "      <td>1.009885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_47</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.399168</td>\n",
              "      <td>0.234274</td>\n",
              "      <td>-0.003691</td>\n",
              "      <td>-0.003691</td>\n",
              "      <td>0.374927</td>\n",
              "      <td>1.002942</td>\n",
              "      <td>1.002942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_45</th>\n",
              "      <td>308200.0</td>\n",
              "      <td>0.241072</td>\n",
              "      <td>0.237708</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.163758</td>\n",
              "      <td>1.002119</td>\n",
              "      <td>1.002119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_42</th>\n",
              "      <td>73138.0</td>\n",
              "      <td>0.175411</td>\n",
              "      <td>0.190886</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.116797</td>\n",
              "      <td>0.997772</td>\n",
              "      <td>0.997904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S_24</th>\n",
              "      <td>308191.0</td>\n",
              "      <td>0.748562</td>\n",
              "      <td>0.370483</td>\n",
              "      <td>0.005351</td>\n",
              "      <td>0.005351</td>\n",
              "      <td>0.949905</td>\n",
              "      <td>1.006088</td>\n",
              "      <td>1.006088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae839aa4-7304-4374-ac62-f87e829e20df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae839aa4-7304-4374-ac62-f87e829e20df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae839aa4-7304-4374-ac62-f87e829e20df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "xtrain.describe(percentiles = [.01, .99]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoUs63bx6kE4"
      },
      "source": [
        "### Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XWnl-WnT6kE4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(xtrain)\n",
        "\n",
        "xtrain_n = sc.transform(xtrain)\n",
        "xtest1_n  = sc.transform(xtest1)\n",
        "xtest2_n  = sc.transform(xtest2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "57slY3NQ6kE4"
      },
      "outputs": [],
      "source": [
        "# convert to Pandas DF\n",
        "xtrain_n_df = pd.DataFrame(xtrain_n, columns=xtrain.columns)\n",
        "xtest1_n_df = pd.DataFrame(xtest1_n, columns=xtest1.columns)\n",
        "xtest2_n_df = pd.DataFrame(xtest2_n, columns=xtest2.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdP7N84J6kE5"
      },
      "source": [
        "### Missing Value Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_5mEfExE6kE5"
      },
      "outputs": [],
      "source": [
        "xtrain_n_df.fillna(0,inplace=True)\n",
        "xtest1_n_df.fillna(0,inplace=True)\n",
        "xtest2_n_df.fillna(0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "k5bLdkE46kE6",
        "outputId": "e7242537-efce-4d33-e81f-cef289c6b64d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      D_132       P_3      D_44    D_64_O      D_52       P_2      D_56  \\\n",
              "0  0.000000 -0.505148 -0.564091  0.933905  0.358555  0.947136  2.920451   \n",
              "1  0.000000  0.521008 -0.564091  0.933905  0.121394 -0.118643  2.000253   \n",
              "2  0.000000 -0.794737  3.773878  0.933905 -0.165032 -1.039215 -0.314786   \n",
              "3  0.871773  0.000000  0.000000 -1.070772 -0.829931 -1.657535  0.000000   \n",
              "4  0.000000  0.822507 -0.534399  0.933905  0.114312  1.013611  3.797131   \n",
              "\n",
              "       B_23  D_88       R_1  D_76  D_110      D_77      D_62      B_11  \\\n",
              "0 -0.694351   0.0 -0.333794   0.0    0.0  0.048903  0.262786 -0.475435   \n",
              "1 -0.745614   0.0 -0.351168   0.0    0.0  0.920463  1.200622 -0.526262   \n",
              "2  3.575013   0.0  2.138164   0.0    0.0 -0.942008 -0.808191 -0.357369   \n",
              "3 -0.508011   0.0  4.642663   0.0    0.0 -1.008877  0.000000 -0.223174   \n",
              "4 -0.615847   0.0 -0.323647   0.0    0.0  0.899202  1.156361  0.081236   \n",
              "\n",
              "        B_2      D_51  D_108       S_3      D_50       R_3       B_3     D_49  \\\n",
              "0  0.959446  0.875116    0.0 -0.387733  0.000000 -0.083940 -0.522808  0.00000   \n",
              "1  0.970053 -0.569646    0.0  0.491577  1.839853 -0.650626 -0.540158  0.00000   \n",
              "2  0.472744  0.868636    0.0 -0.278217 -0.437429 -0.632134 -0.534053  0.00000   \n",
              "3  0.964853 -0.596078    0.0 -0.372045  0.000000  0.398404 -0.517511 -0.95754   \n",
              "4 -0.075026  0.857788    0.0 -0.690139 -0.483243 -0.649638  1.161940  0.00000   \n",
              "\n",
              "       D_66      B_38      D_75      D_53       B_1       B_4  D_111  D_134  \\\n",
              "0  0.000000 -0.426996 -0.755990  0.000000 -0.435203 -0.711658    0.0    0.0   \n",
              "1  0.000000 -0.426996 -0.784916 -0.422515 -0.533221 -0.772272    0.0    0.0   \n",
              "2  0.000000 -1.059895  1.448600  0.760980 -0.327681  2.176944    0.0    0.0   \n",
              "3  0.000000 -1.059895 -0.761658  0.640869 -0.124539 -0.748501    0.0    0.0   \n",
              "4  0.346521  0.205904 -0.471895  0.000000  0.197508 -0.480377    0.0    0.0   \n",
              "\n",
              "       D_41      B_17      D_46       B_5      D_43      S_23       B_9  \\\n",
              "0 -0.293842  0.000000 -0.045829 -0.389507 -0.487600 -0.221660 -0.691054   \n",
              "1 -0.280421  0.011992 -0.380362  0.306950 -0.531793 -0.230284 -0.602067   \n",
              "2 -0.296373  0.000000  2.339308 -0.391479 -0.284280 -0.268807  0.537477   \n",
              "3 -0.282957  0.000000  0.000000 -0.425116  0.000000 -0.245618 -0.179755   \n",
              "4 -0.295804 -1.485258 -1.259995 -0.426005  0.067839 -0.253387 -0.623887   \n",
              "\n",
              "       D_48      R_27      B_18     D_112      D_47      D_45      D_42  \\\n",
              "0 -1.113236  0.379178  1.111277  0.419485 -0.002393  0.095342  0.000000   \n",
              "1 -1.104109  0.373707  1.126438  0.437530  0.046392 -0.698914  0.000000   \n",
              "2  1.825103 -2.716296 -0.334444  0.421733 -0.245679 -0.697024  0.000000   \n",
              "3  0.000000  0.000000  1.109746  0.433858 -1.051692 -0.958438 -0.633055   \n",
              "4  0.598802  0.374317  0.248417  0.442394 -0.122736 -0.466182  0.000000   \n",
              "\n",
              "       S_24  \n",
              "0  0.698110  \n",
              "1  0.541320  \n",
              "2  0.508702  \n",
              "3  0.513815  \n",
              "4  0.589840  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6dcbd837-b669-4e18-b528-663fbb557a19\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D_132</th>\n",
              "      <th>P_3</th>\n",
              "      <th>D_44</th>\n",
              "      <th>D_64_O</th>\n",
              "      <th>D_52</th>\n",
              "      <th>P_2</th>\n",
              "      <th>D_56</th>\n",
              "      <th>B_23</th>\n",
              "      <th>D_88</th>\n",
              "      <th>R_1</th>\n",
              "      <th>D_76</th>\n",
              "      <th>D_110</th>\n",
              "      <th>D_77</th>\n",
              "      <th>D_62</th>\n",
              "      <th>B_11</th>\n",
              "      <th>B_2</th>\n",
              "      <th>D_51</th>\n",
              "      <th>D_108</th>\n",
              "      <th>S_3</th>\n",
              "      <th>D_50</th>\n",
              "      <th>R_3</th>\n",
              "      <th>B_3</th>\n",
              "      <th>D_49</th>\n",
              "      <th>D_66</th>\n",
              "      <th>B_38</th>\n",
              "      <th>D_75</th>\n",
              "      <th>D_53</th>\n",
              "      <th>B_1</th>\n",
              "      <th>B_4</th>\n",
              "      <th>D_111</th>\n",
              "      <th>D_134</th>\n",
              "      <th>D_41</th>\n",
              "      <th>B_17</th>\n",
              "      <th>D_46</th>\n",
              "      <th>B_5</th>\n",
              "      <th>D_43</th>\n",
              "      <th>S_23</th>\n",
              "      <th>B_9</th>\n",
              "      <th>D_48</th>\n",
              "      <th>R_27</th>\n",
              "      <th>B_18</th>\n",
              "      <th>D_112</th>\n",
              "      <th>D_47</th>\n",
              "      <th>D_45</th>\n",
              "      <th>D_42</th>\n",
              "      <th>S_24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.505148</td>\n",
              "      <td>-0.564091</td>\n",
              "      <td>0.933905</td>\n",
              "      <td>0.358555</td>\n",
              "      <td>0.947136</td>\n",
              "      <td>2.920451</td>\n",
              "      <td>-0.694351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.333794</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048903</td>\n",
              "      <td>0.262786</td>\n",
              "      <td>-0.475435</td>\n",
              "      <td>0.959446</td>\n",
              "      <td>0.875116</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.387733</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.083940</td>\n",
              "      <td>-0.522808</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.426996</td>\n",
              "      <td>-0.755990</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.435203</td>\n",
              "      <td>-0.711658</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.293842</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.045829</td>\n",
              "      <td>-0.389507</td>\n",
              "      <td>-0.487600</td>\n",
              "      <td>-0.221660</td>\n",
              "      <td>-0.691054</td>\n",
              "      <td>-1.113236</td>\n",
              "      <td>0.379178</td>\n",
              "      <td>1.111277</td>\n",
              "      <td>0.419485</td>\n",
              "      <td>-0.002393</td>\n",
              "      <td>0.095342</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.698110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.521008</td>\n",
              "      <td>-0.564091</td>\n",
              "      <td>0.933905</td>\n",
              "      <td>0.121394</td>\n",
              "      <td>-0.118643</td>\n",
              "      <td>2.000253</td>\n",
              "      <td>-0.745614</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.351168</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.920463</td>\n",
              "      <td>1.200622</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>0.970053</td>\n",
              "      <td>-0.569646</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.491577</td>\n",
              "      <td>1.839853</td>\n",
              "      <td>-0.650626</td>\n",
              "      <td>-0.540158</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.426996</td>\n",
              "      <td>-0.784916</td>\n",
              "      <td>-0.422515</td>\n",
              "      <td>-0.533221</td>\n",
              "      <td>-0.772272</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.280421</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>-0.380362</td>\n",
              "      <td>0.306950</td>\n",
              "      <td>-0.531793</td>\n",
              "      <td>-0.230284</td>\n",
              "      <td>-0.602067</td>\n",
              "      <td>-1.104109</td>\n",
              "      <td>0.373707</td>\n",
              "      <td>1.126438</td>\n",
              "      <td>0.437530</td>\n",
              "      <td>0.046392</td>\n",
              "      <td>-0.698914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.794737</td>\n",
              "      <td>3.773878</td>\n",
              "      <td>0.933905</td>\n",
              "      <td>-0.165032</td>\n",
              "      <td>-1.039215</td>\n",
              "      <td>-0.314786</td>\n",
              "      <td>3.575013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.138164</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.942008</td>\n",
              "      <td>-0.808191</td>\n",
              "      <td>-0.357369</td>\n",
              "      <td>0.472744</td>\n",
              "      <td>0.868636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.278217</td>\n",
              "      <td>-0.437429</td>\n",
              "      <td>-0.632134</td>\n",
              "      <td>-0.534053</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.059895</td>\n",
              "      <td>1.448600</td>\n",
              "      <td>0.760980</td>\n",
              "      <td>-0.327681</td>\n",
              "      <td>2.176944</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.296373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.339308</td>\n",
              "      <td>-0.391479</td>\n",
              "      <td>-0.284280</td>\n",
              "      <td>-0.268807</td>\n",
              "      <td>0.537477</td>\n",
              "      <td>1.825103</td>\n",
              "      <td>-2.716296</td>\n",
              "      <td>-0.334444</td>\n",
              "      <td>0.421733</td>\n",
              "      <td>-0.245679</td>\n",
              "      <td>-0.697024</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.508702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.871773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.070772</td>\n",
              "      <td>-0.829931</td>\n",
              "      <td>-1.657535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.508011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.642663</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.008877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.223174</td>\n",
              "      <td>0.964853</td>\n",
              "      <td>-0.596078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.372045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.398404</td>\n",
              "      <td>-0.517511</td>\n",
              "      <td>-0.95754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.059895</td>\n",
              "      <td>-0.761658</td>\n",
              "      <td>0.640869</td>\n",
              "      <td>-0.124539</td>\n",
              "      <td>-0.748501</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.282957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.425116</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.245618</td>\n",
              "      <td>-0.179755</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.109746</td>\n",
              "      <td>0.433858</td>\n",
              "      <td>-1.051692</td>\n",
              "      <td>-0.958438</td>\n",
              "      <td>-0.633055</td>\n",
              "      <td>0.513815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.822507</td>\n",
              "      <td>-0.534399</td>\n",
              "      <td>0.933905</td>\n",
              "      <td>0.114312</td>\n",
              "      <td>1.013611</td>\n",
              "      <td>3.797131</td>\n",
              "      <td>-0.615847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.323647</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.899202</td>\n",
              "      <td>1.156361</td>\n",
              "      <td>0.081236</td>\n",
              "      <td>-0.075026</td>\n",
              "      <td>0.857788</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.690139</td>\n",
              "      <td>-0.483243</td>\n",
              "      <td>-0.649638</td>\n",
              "      <td>1.161940</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.346521</td>\n",
              "      <td>0.205904</td>\n",
              "      <td>-0.471895</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197508</td>\n",
              "      <td>-0.480377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.295804</td>\n",
              "      <td>-1.485258</td>\n",
              "      <td>-1.259995</td>\n",
              "      <td>-0.426005</td>\n",
              "      <td>0.067839</td>\n",
              "      <td>-0.253387</td>\n",
              "      <td>-0.623887</td>\n",
              "      <td>0.598802</td>\n",
              "      <td>0.374317</td>\n",
              "      <td>0.248417</td>\n",
              "      <td>0.442394</td>\n",
              "      <td>-0.122736</td>\n",
              "      <td>-0.466182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.589840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6dcbd837-b669-4e18-b528-663fbb557a19')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6dcbd837-b669-4e18-b528-663fbb557a19 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6dcbd837-b669-4e18-b528-663fbb557a19');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "xtest2_n_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(activation = 'relu', dropout_rate = .5, neurons = 4):\n",
        "    # first step: create a Sequential object, as a sequence of layers. B/C NN is a sequence of layers.\n",
        "    classifier = Sequential()\n",
        "    # add the first hidden layer\n",
        "    classifier.add(Dense(units=neurons,kernel_initializer='glorot_uniform',\n",
        "                    activation = activation))\n",
        "    classifier.add(Dropout(dropout_rate))\n",
        "    # add the second hidden layer\n",
        "    classifier.add(Dense(units=neurons,kernel_initializer='glorot_uniform',\n",
        "                    activation = activation))\n",
        "    # add the output layer\n",
        "    classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',\n",
        "                    activation = 'sigmoid'))\n",
        "    # compiling the NN\n",
        "    classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "\n",
        "classifier = KerasClassifier(build_fn=build_classifier, batch_size = 100)\n",
        "\n",
        "parameters = dict(activation = ['relu', 'tanh'], batch_size = [100, 10000], )\n",
        "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'roc_auc', cv=10, return_train_score=True)\n",
        "grid_search = grid_search.fit(xtrain_n_df, ytrain)\n",
        "\n",
        "best_parameters = grid_search.best_params_ \n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "P1KTIfTfJ7do",
        "outputId": "e355669a-2df3-4225-dc2a-c06c12f347d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-62d358e82ec6>:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  classifier = KerasClassifier(build_fn=build_classifier, batch_size = 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2424/2424 [==============================] - 10s 4ms/step - loss: 0.3973 - accuracy: 0.7959\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "7573/7573 [==============================] - 16s 2ms/step\n",
            "2424/2424 [==============================] - 9s 3ms/step - loss: 0.4429 - accuracy: 0.8191\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "7573/7573 [==============================] - 15s 2ms/step\n",
            "2424/2424 [==============================] - 10s 4ms/step - loss: 0.3996 - accuracy: 0.8179\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "7573/7573 [==============================] - 15s 2ms/step\n",
            "2424/2424 [==============================] - 9s 4ms/step - loss: 0.4054 - accuracy: 0.8164\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "7573/7573 [==============================] - 16s 2ms/step\n",
            "2424/2424 [==============================] - 10s 4ms/step - loss: 0.3946 - accuracy: 0.7835\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "7573/7573 [==============================] - 15s 2ms/step\n",
            "2424/2424 [==============================] - 10s 3ms/step - loss: 0.4469 - accuracy: 0.8145\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "7573/7573 [==============================] - 15s 2ms/step\n",
            "2424/2424 [==============================] - 8s 3ms/step - loss: 0.4155 - accuracy: 0.7699\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "7573/7573 [==============================] - 15s 2ms/step\n",
            "2424/2424 [==============================] - 9s 3ms/step - loss: 0.3977 - accuracy: 0.7813\n",
            "842/842 [==============================] - 2s 2ms/step\n",
            "4422/7573 [================>.............] - ETA: 5s"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decision_function\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'decision_function'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-62d358e82ec6>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_n_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mScore\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         return self._score(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKeras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;31m# check if binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2348\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2350\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2351\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "means = grid_search.cv_results_['mean_test_score']\n",
        "stds = grid_search.cv_results_['std_test_score']\n",
        "params = grid_search.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSqpl5iUQXKd",
        "outputId": "a1487303-ee51-4064-b40d-960294a167ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.924460 (0.003092) with: {'activation': 'relu', 'batch_size': 100}\n",
            "0.617315 (0.122796) with: {'activation': 'relu', 'batch_size': 10000}\n",
            "0.925803 (0.001744) with: {'activation': 'tanh', 'batch_size': 100}\n",
            "0.655991 (0.130437) with: {'activation': 'tanh', 'batch_size': 10000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ2VzV9KWYPY",
        "outputId": "293449db-1232-40af-e854-89a2921c4a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FREwu7UJYWGF",
        "outputId": "64b731f2-4093-42c8-b08f-fd106f84764a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'tanh'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = grid_search.predict_proba(xtrain_n_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fal6QoJSYcXm",
        "outputId": "a0ae02d1-103d-416b-b2c9-ef977c195c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8414/8414 [==============================] - 43s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF0QiaEQuS3x",
        "outputId": "ce52db2a-92a0-4973-a23d-d7fdc32fb012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target    69028\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbkQeqe9tDWy",
        "outputId": "24d17cbc-07fd-421f-c10f-0621cb4c0a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9736629 , 0.02633711],\n",
              "       [0.970219  , 0.02978096],\n",
              "       [0.96727234, 0.03272764],\n",
              "       ...,\n",
              "       [0.49549836, 0.50450164],\n",
              "       [0.97080064, 0.02919936],\n",
              "       [0.9729349 , 0.02706511]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(ytrain, train_pred[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlK083WWZd9D",
        "outputId": "ee64cbee-c2ab-4e02-b7c6-64483ca61912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9261858132078623"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1_pred = grid_search.predict_proba(xtest1_n_df)[:,1]\n",
        "test2_pred = grid_search.predict_proba(xtest2_n_df)[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIEentBFZmRd",
        "outputId": "ee96fe19-3ebd-414d-c00c-74f87a176f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "961/961 [==============================] - 1s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(ytest1, test1_pred))\n",
        "print(roc_auc_score(ytest2, test2_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDL38Vp0ZuP0",
        "outputId": "94367beb-78cf-4d77-c5e4-c0dfe00b7c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9182272163901571\n",
            "0.938807971658403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8idkXpEYvtL",
        "outputId": "db30fff2-c093-4846-92fe-26288600c914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9282850734081782"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.cv_results_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYRTdYtiZdEm",
        "outputId": "1e457199-e813-443c-8e5a-cc1b8b1f1a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([24.16289396, 25.82018354]),\n",
              " 'std_fit_time': array([6.02319552, 8.24766352]),\n",
              " 'mean_score_time': array([2.45665553, 2.47038836]),\n",
              " 'std_score_time': array([0.43214532, 0.3582605 ]),\n",
              " 'param_activation': masked_array(data=['relu', 'tanh'],\n",
              "              mask=[False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'relu'}, {'activation': 'tanh'}],\n",
              " 'split0_test_score': array([0.92658136, 0.92623104]),\n",
              " 'split1_test_score': array([0.92750921, 0.92654195]),\n",
              " 'split2_test_score': array([0.92688978, 0.92681698]),\n",
              " 'split3_test_score': array([0.92984503, 0.92995832]),\n",
              " 'split4_test_score': array([0.93020029, 0.93007415]),\n",
              " 'split5_test_score': array([0.92676152, 0.92762218]),\n",
              " 'split6_test_score': array([0.92602759, 0.92687771]),\n",
              " 'split7_test_score': array([0.93133247, 0.93147751]),\n",
              " 'split8_test_score': array([0.92907383, 0.9293695 ]),\n",
              " 'split9_test_score': array([0.92787229, 0.9278814 ]),\n",
              " 'mean_test_score': array([0.92820934, 0.92828507]),\n",
              " 'std_test_score': array([0.00170271, 0.00171359]),\n",
              " 'rank_test_score': array([2, 1], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the AUC scores for all hyperparameters\n",
        "results = grid_search.cv_results_\n",
        "for i in range(len(results['params'])):\n",
        "    print(f\"Hyperparameters: {results['params'][i]}\")\n",
        "    #print(f\"Train AUC score: {results['mean_train_score'][i]:.3f}\")\n",
        "    print(f\"Test AUC score: {results['mean_test_score'][i]:.3f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em0DDYHNZCzm",
        "outputId": "eae747d5-914f-4f1c-a4be-fc1d3c4ca0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'activation': 'relu', 'batch_size': 100}\n",
            "Test AUC score: 0.924\n",
            "\n",
            "Hyperparameters: {'activation': 'relu', 'batch_size': 10000}\n",
            "Test AUC score: 0.617\n",
            "\n",
            "Hyperparameters: {'activation': 'tanh', 'batch_size': 100}\n",
            "Test AUC score: 0.926\n",
            "\n",
            "Hyperparameters: {'activation': 'tanh', 'batch_size': 10000}\n",
            "Test AUC score: 0.656\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search sucks!"
      ],
      "metadata": {
        "id": "AuMWy5xU55TJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 2 hidden Layers"
      ],
      "metadata": {
        "id": "PgRMkkNs6Ch_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(xtest2_n_df)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpZ5BkCcQs5I",
        "outputId": "fe701d13-4ade-4a94-d002-b8b0cfb713f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2774/2774 [==============================] - 8s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00259744],\n",
              "       [0.02210935],\n",
              "       [0.8318695 ],\n",
              "       ...,\n",
              "       [0.01020003],\n",
              "       [0.59218216],\n",
              "       [0.08405238]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(ytrain, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU7ANjCS8uly",
        "outputId": "bfd4abc3-8c40-42ca-d1cb-71b4a9cab2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9306093281602095"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest2['target'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-aFXagP6M_B",
        "outputId": "ef2f3883-577b-4303-d253-b79632be3ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88750,)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:, 0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMWF57Xp6Wil",
        "outputId": "05989beb-03dd-4a15-a7f4-6badb1396e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88750,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9bQhIgj-Jn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first step: create a Sequential object, as a sequence of layers. B/C NN is a sequence of layers.\n",
        "t1 = t.time()\n",
        "grid_search_nn1 = pd.DataFrame(columns = ['hd', 'nodes', 'activation', 'dropout', 'batch_size', 'auc_train', 'auc_test1', 'auc_test2'])\n",
        "\n",
        "\n",
        "neurons = [4, 6]\n",
        "activations = ['relu', 'tanh']\n",
        "dropout = [.5, 0]\n",
        "batch_sizes = [100, 10000]\n",
        "\n",
        "row = 0\n",
        "for i in neurons:\n",
        "  for a in activations:\n",
        "    for d in dropout:\n",
        "      for s in batch_sizes:\n",
        "        \n",
        "        grid_search_nn1.loc[row, 'nodes'] = i\n",
        "        grid_search_nn1.loc[row, 'activation'] = a\n",
        "        grid_search_nn1.loc[row, 'dropout'] = d\n",
        "        grid_search_nn1.loc[row, 'batch_size'] = s\n",
        "\n",
        "        classifier = Sequential()\n",
        "\n",
        "        # add the first hidden layer\n",
        "        classifier.add(Dense(units=i,kernel_initializer='glorot_uniform',\n",
        "                            activation = a))\n",
        "\n",
        "        classifier.add(Dropout(d))\n",
        "\n",
        "        # add the second hidden layer\n",
        "        classifier.add(Dense(units=i,kernel_initializer='glorot_uniform',\n",
        "                        activation = a))\n",
        "\n",
        "        classifier.add(Dropout(d))\n",
        "        # add the output layer\n",
        "        classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',\n",
        "                            activation = 'sigmoid'))\n",
        "\n",
        "        # add additional parameters\n",
        "        classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy', 'FalseNegatives'])\n",
        "\n",
        "        # train the model\n",
        "        classifier.fit(xtrain_n_df,ytrain,batch_size=s,epochs=20)\n",
        "\n",
        "        grid_search_nn1.loc[row, 'auc_train'] = roc_auc_score(ytrain, classifier.predict(xtrain_n_df))\n",
        "        grid_search_nn1.loc[row, 'auc_test1'] = roc_auc_score(ytest1, classifier.predict(xtest1_n_df))\n",
        "        grid_search_nn1.loc[row, 'auc_test2'] = roc_auc_score(ytest2, classifier.predict(xtest2_n_df))\n",
        "        print(\"Best Parameter Iteration\",  row, \"AUC Train\", roc_auc_score(ytrain, classifier.predict(xtrain_n_df)))\n",
        "\n",
        "        row += 1\n",
        "\n",
        "grid_search_nn1['hd'] = 2\n",
        "t2 = t.time()\n",
        "print(t2 - t1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y8-RZWpurrd",
        "outputId": "7e87c26c-29d2-442a-907d-d57f3a6ff707"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 11s 3ms/step - loss: 0.4409 - accuracy: 0.7677 - false_negatives: 64642.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 11s 3ms/step - loss: 0.4208 - accuracy: 0.7726 - false_negatives: 64629.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4213 - accuracy: 0.7724 - false_negatives: 64782.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4196 - accuracy: 0.7721 - false_negatives: 65028.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4212 - accuracy: 0.7717 - false_negatives: 65174.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4201 - accuracy: 0.7724 - false_negatives: 64870.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4207 - accuracy: 0.7728 - false_negatives: 64849.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4213 - accuracy: 0.7722 - false_negatives: 65045.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4210 - accuracy: 0.7720 - false_negatives: 65174.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4189 - accuracy: 0.7729 - false_negatives: 64889.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4210 - accuracy: 0.7726 - false_negatives: 64961.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4202 - accuracy: 0.7723 - false_negatives: 64956.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4197 - accuracy: 0.7721 - false_negatives: 65102.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4196 - accuracy: 0.7723 - false_negatives: 64913.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4193 - accuracy: 0.7731 - false_negatives: 64838.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4209 - accuracy: 0.7726 - false_negatives: 64951.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4202 - accuracy: 0.7725 - false_negatives: 64985.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4203 - accuracy: 0.7725 - false_negatives: 64938.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4206 - accuracy: 0.7724 - false_negatives: 64936.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4204 - accuracy: 0.7727 - false_negatives: 64855.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 1ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 0 AUC Train 0.9288315601389248\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 13ms/step - loss: 0.7528 - accuracy: 0.6090 - false_negatives: 55098.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6780 - accuracy: 0.7032 - false_negatives: 56839.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6188 - accuracy: 0.7387 - false_negatives: 57159.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5702 - accuracy: 0.7511 - false_negatives: 58623.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.5375 - accuracy: 0.7572 - false_negatives: 59386.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5156 - accuracy: 0.7616 - false_negatives: 59784.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5025 - accuracy: 0.7655 - false_negatives: 59454.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4925 - accuracy: 0.7686 - false_negatives: 59078.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4842 - accuracy: 0.7729 - false_negatives: 58463.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4775 - accuracy: 0.7739 - false_negatives: 58437.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.4730 - accuracy: 0.7754 - false_negatives: 58120.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4689 - accuracy: 0.7768 - false_negatives: 58058.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4644 - accuracy: 0.7803 - false_negatives: 57456.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4620 - accuracy: 0.7798 - false_negatives: 57768.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4581 - accuracy: 0.7820 - false_negatives: 57454.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4557 - accuracy: 0.7830 - false_negatives: 57436.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4538 - accuracy: 0.7845 - false_negatives: 57226.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4518 - accuracy: 0.7851 - false_negatives: 57563.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4509 - accuracy: 0.7862 - false_negatives: 57387.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4481 - accuracy: 0.7864 - false_negatives: 57482.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 1ms/step\n",
            "2774/2774 [==============================] - 4s 1ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 1 AUC Train 0.9253443067891862\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3343 - accuracy: 0.8418 - false_negatives: 27225.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2985 - accuracy: 0.8641 - false_negatives: 19549.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2944 - accuracy: 0.8655 - false_negatives: 20065.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2928 - accuracy: 0.8659 - false_negatives: 20351.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2921 - accuracy: 0.8660 - false_negatives: 20568.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2916 - accuracy: 0.8660 - false_negatives: 20542.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2912 - accuracy: 0.8660 - false_negatives: 20512.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2908 - accuracy: 0.8661 - false_negatives: 20576.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2904 - accuracy: 0.8665 - false_negatives: 20479.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2903 - accuracy: 0.8665 - false_negatives: 20506.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2900 - accuracy: 0.8665 - false_negatives: 20540.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2898 - accuracy: 0.8664 - false_negatives: 20651.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2895 - accuracy: 0.8665 - false_negatives: 20482.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2894 - accuracy: 0.8666 - false_negatives: 20633.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2891 - accuracy: 0.8670 - false_negatives: 20441.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2891 - accuracy: 0.8665 - false_negatives: 20252.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2889 - accuracy: 0.8671 - false_negatives: 20105.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2888 - accuracy: 0.8671 - false_negatives: 20032.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2886 - accuracy: 0.8671 - false_negatives: 19968.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2883 - accuracy: 0.8674 - false_negatives: 19822.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 1ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 2 AUC Train 0.9312885296059193\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 16ms/step - loss: 0.7216 - accuracy: 0.5629 - false_negatives: 75009.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.6140 - accuracy: 0.7213 - false_negatives: 74773.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5234 - accuracy: 0.7482 - false_negatives: 73413.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4586 - accuracy: 0.7594 - false_negatives: 70281.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4136 - accuracy: 0.7796 - false_negatives: 62135.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3803 - accuracy: 0.8154 - false_negatives: 45462.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3538 - accuracy: 0.8434 - false_negatives: 28901.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.8502 - false_negatives: 21040.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3248 - accuracy: 0.8514 - false_negatives: 18030.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3184 - accuracy: 0.8525 - false_negatives: 17053.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3143 - accuracy: 0.8542 - false_negatives: 16875.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3113 - accuracy: 0.8556 - false_negatives: 17067.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3091 - accuracy: 0.8566 - false_negatives: 17223.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3073 - accuracy: 0.8579 - false_negatives: 17370.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3058 - accuracy: 0.8587 - false_negatives: 17649.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3046 - accuracy: 0.8594 - false_negatives: 17746.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3036 - accuracy: 0.8600 - false_negatives: 17889.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 0.8607 - false_negatives: 18069.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.8612 - false_negatives: 18237.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8616 - false_negatives: 18335.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 1ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 3 AUC Train 0.9249134008213957\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.4176 - accuracy: 0.8148 - false_negatives: 34615.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3738 - accuracy: 0.8335 - false_negatives: 34886.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3707 - accuracy: 0.8350 - false_negatives: 35402.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3694 - accuracy: 0.8344 - false_negatives: 35888.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3684 - accuracy: 0.8352 - false_negatives: 35711.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3692 - accuracy: 0.8349 - false_negatives: 35982.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3685 - accuracy: 0.8350 - false_negatives: 35733.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.3676 - accuracy: 0.8356 - false_negatives: 35517.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3687 - accuracy: 0.8351 - false_negatives: 35690.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3682 - accuracy: 0.8348 - false_negatives: 35815.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3695 - accuracy: 0.8346 - false_negatives: 35844.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3678 - accuracy: 0.8357 - false_negatives: 35709.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3692 - accuracy: 0.8354 - false_negatives: 35727.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3681 - accuracy: 0.8362 - false_negatives: 35377.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3693 - accuracy: 0.8351 - false_negatives: 35716.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3688 - accuracy: 0.8357 - false_negatives: 35546.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3692 - accuracy: 0.8351 - false_negatives: 35637.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3673 - accuracy: 0.8356 - false_negatives: 35549.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3685 - accuracy: 0.8355 - false_negatives: 35592.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3688 - accuracy: 0.8349 - false_negatives: 35727.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 4s 1ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 4 AUC Train 0.9268121888679355\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 1s 13ms/step - loss: 0.8615 - accuracy: 0.5795 - false_negatives: 42926.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6542 - accuracy: 0.6951 - false_negatives: 36031.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5734 - accuracy: 0.7453 - false_negatives: 32959.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5335 - accuracy: 0.7685 - false_negatives: 31884.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5089 - accuracy: 0.7819 - false_negatives: 31386.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4883 - accuracy: 0.7927 - false_negatives: 31413.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4726 - accuracy: 0.8010 - false_negatives: 31320.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4606 - accuracy: 0.8060 - false_negatives: 31692.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4503 - accuracy: 0.8108 - false_negatives: 31988.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4408 - accuracy: 0.8153 - false_negatives: 32041.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4338 - accuracy: 0.8197 - false_negatives: 32065.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4290 - accuracy: 0.8210 - false_negatives: 32192.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.8235 - false_negatives: 32267.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4186 - accuracy: 0.8252 - false_negatives: 32520.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4146 - accuracy: 0.8265 - false_negatives: 32589.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4110 - accuracy: 0.8281 - false_negatives: 32675.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8283 - false_negatives: 33076.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4064 - accuracy: 0.8289 - false_negatives: 33263.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4050 - accuracy: 0.8294 - false_negatives: 33390.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4010 - accuracy: 0.8308 - false_negatives: 33542.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 1ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 5 AUC Train 0.9250901618855749\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3348 - accuracy: 0.8498 - false_negatives: 20446.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2953 - accuracy: 0.8645 - false_negatives: 20407.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2921 - accuracy: 0.8657 - false_negatives: 20560.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2907 - accuracy: 0.8661 - false_negatives: 20535.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2899 - accuracy: 0.8664 - false_negatives: 20610.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2895 - accuracy: 0.8667 - false_negatives: 20529.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2890 - accuracy: 0.8671 - false_negatives: 20494.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2886 - accuracy: 0.8670 - false_negatives: 20494.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2880 - accuracy: 0.8673 - false_negatives: 20455.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2876 - accuracy: 0.8677 - false_negatives: 20446.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2871 - accuracy: 0.8680 - false_negatives: 20435.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2867 - accuracy: 0.8682 - false_negatives: 20362.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2866 - accuracy: 0.8680 - false_negatives: 20340.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2863 - accuracy: 0.8684 - false_negatives: 20300.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2862 - accuracy: 0.8684 - false_negatives: 20147.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2860 - accuracy: 0.8686 - false_negatives: 20091.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2858 - accuracy: 0.8689 - false_negatives: 20009.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2858 - accuracy: 0.8685 - false_negatives: 20013.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2857 - accuracy: 0.8687 - false_negatives: 19967.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2857 - accuracy: 0.8687 - false_negatives: 19886.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 1ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 6 AUC Train 0.9327019999537834\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 14ms/step - loss: 0.6039 - accuracy: 0.6991 - false_negatives: 25925.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5192 - accuracy: 0.7658 - false_negatives: 20006.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4663 - accuracy: 0.7906 - false_negatives: 17221.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4318 - accuracy: 0.8078 - false_negatives: 15995.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4040 - accuracy: 0.8230 - false_negatives: 15839.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3798 - accuracy: 0.8354 - false_negatives: 16838.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3605 - accuracy: 0.8441 - false_negatives: 18281.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3463 - accuracy: 0.8494 - false_negatives: 19136.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3362 - accuracy: 0.8531 - false_negatives: 19828.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3289 - accuracy: 0.8557 - false_negatives: 20278.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.8577 - false_negatives: 20604.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3191 - accuracy: 0.8589 - false_negatives: 20780.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3158 - accuracy: 0.8600 - false_negatives: 20973.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3132 - accuracy: 0.8610 - false_negatives: 21065.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3112 - accuracy: 0.8616 - false_negatives: 21009.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3096 - accuracy: 0.8621 - false_negatives: 21251.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3083 - accuracy: 0.8625 - false_negatives: 21270.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3073 - accuracy: 0.8626 - false_negatives: 21327.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3064 - accuracy: 0.8629 - false_negatives: 21370.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3056 - accuracy: 0.8633 - false_negatives: 21331.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 7 AUC Train 0.9262294994726549\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 11s 3ms/step - loss: 0.4252 - accuracy: 0.8035 - false_negatives: 45193.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3868 - accuracy: 0.8208 - false_negatives: 43470.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.3854 - accuracy: 0.8220 - false_negatives: 43316.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3857 - accuracy: 0.8218 - false_negatives: 43486.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3858 - accuracy: 0.8225 - false_negatives: 43379.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3852 - accuracy: 0.8232 - false_negatives: 42956.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3841 - accuracy: 0.8227 - false_negatives: 43136.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3843 - accuracy: 0.8233 - false_negatives: 43015.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3835 - accuracy: 0.8232 - false_negatives: 42950.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3839 - accuracy: 0.8236 - false_negatives: 43036.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3834 - accuracy: 0.8236 - false_negatives: 42900.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3838 - accuracy: 0.8231 - false_negatives: 43068.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3851 - accuracy: 0.8230 - false_negatives: 43168.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3842 - accuracy: 0.8235 - false_negatives: 42891.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3828 - accuracy: 0.8241 - false_negatives: 42578.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.3834 - accuracy: 0.8234 - false_negatives: 42813.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.3839 - accuracy: 0.8242 - false_negatives: 42690.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3822 - accuracy: 0.8243 - false_negatives: 42498.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3835 - accuracy: 0.8240 - false_negatives: 42879.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3821 - accuracy: 0.8243 - false_negatives: 42699.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 8 AUC Train 0.9292995077944385\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 1s 14ms/step - loss: 0.7244 - accuracy: 0.6251 - false_negatives: 64516.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6504 - accuracy: 0.6903 - false_negatives: 65916.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5965 - accuracy: 0.7190 - false_negatives: 68729.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5511 - accuracy: 0.7316 - false_negatives: 69609.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.5118 - accuracy: 0.7440 - false_negatives: 68755.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4850 - accuracy: 0.7532 - false_negatives: 66872.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4677 - accuracy: 0.7599 - false_negatives: 64430.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4554 - accuracy: 0.7647 - false_negatives: 62537.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4478 - accuracy: 0.7692 - false_negatives: 61282.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4388 - accuracy: 0.7724 - false_negatives: 60187.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4298 - accuracy: 0.7757 - false_negatives: 59367.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4240 - accuracy: 0.7775 - false_negatives: 58865.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4206 - accuracy: 0.7781 - false_negatives: 58797.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4180 - accuracy: 0.7802 - false_negatives: 58269.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4148 - accuracy: 0.7808 - false_negatives: 58078.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4150 - accuracy: 0.7816 - false_negatives: 58099.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4132 - accuracy: 0.7824 - false_negatives: 57850.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4119 - accuracy: 0.7824 - false_negatives: 58018.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4105 - accuracy: 0.7836 - false_negatives: 57552.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4092 - accuracy: 0.7840 - false_negatives: 57619.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 6s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 9 AUC Train 0.9251475146217957\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.3135 - accuracy: 0.8510 - false_negatives: 19624.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2906 - accuracy: 0.8661 - false_negatives: 20669.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2888 - accuracy: 0.8667 - false_negatives: 20155.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2877 - accuracy: 0.8674 - false_negatives: 20030.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2871 - accuracy: 0.8676 - false_negatives: 20043.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2866 - accuracy: 0.8678 - false_negatives: 20047.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2862 - accuracy: 0.8682 - false_negatives: 19937.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2856 - accuracy: 0.8686 - false_negatives: 19933.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2849 - accuracy: 0.8689 - false_negatives: 19827.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2842 - accuracy: 0.8693 - false_negatives: 19705.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2838 - accuracy: 0.8692 - false_negatives: 19694.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2835 - accuracy: 0.8696 - false_negatives: 19593.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2832 - accuracy: 0.8695 - false_negatives: 19596.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2831 - accuracy: 0.8698 - false_negatives: 19498.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2830 - accuracy: 0.8697 - false_negatives: 19555.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2829 - accuracy: 0.8699 - false_negatives: 19535.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2828 - accuracy: 0.8699 - false_negatives: 19605.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2828 - accuracy: 0.8697 - false_negatives: 19626.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2827 - accuracy: 0.8699 - false_negatives: 19663.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2825 - accuracy: 0.8704 - false_negatives: 19614.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 6s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 10 AUC Train 0.9340902432446705\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 1s 10ms/step - loss: 0.7453 - accuracy: 0.4730 - false_negatives: 23880.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5630 - accuracy: 0.7231 - false_negatives: 17469.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4545 - accuracy: 0.8078 - false_negatives: 14348.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3937 - accuracy: 0.8274 - false_negatives: 13791.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3613 - accuracy: 0.8360 - false_negatives: 14086.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3429 - accuracy: 0.8420 - false_negatives: 14587.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3315 - accuracy: 0.8467 - false_negatives: 15107.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3239 - accuracy: 0.8508 - false_negatives: 15737.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3185 - accuracy: 0.8539 - false_negatives: 16472.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3145 - accuracy: 0.8563 - false_negatives: 17042.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3114 - accuracy: 0.8582 - false_negatives: 17698.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3088 - accuracy: 0.8596 - false_negatives: 18178.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3067 - accuracy: 0.8606 - false_negatives: 18481.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3048 - accuracy: 0.8618 - false_negatives: 18906.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8626 - false_negatives: 19384.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.3018 - accuracy: 0.8631 - false_negatives: 19547.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.3006 - accuracy: 0.8636 - false_negatives: 19789.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.2995 - accuracy: 0.8639 - false_negatives: 20080.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.2986 - accuracy: 0.8642 - false_negatives: 20370.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.2977 - accuracy: 0.8643 - false_negatives: 20431.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 11 AUC Train 0.9273833547876571\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.3925 - accuracy: 0.8226 - false_negatives: 30427.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3506 - accuracy: 0.8412 - false_negatives: 30246.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3465 - accuracy: 0.8427 - false_negatives: 30673.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3457 - accuracy: 0.8425 - false_negatives: 31036.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3453 - accuracy: 0.8433 - false_negatives: 30796.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3449 - accuracy: 0.8430 - false_negatives: 30840.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3447 - accuracy: 0.8432 - false_negatives: 30783.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3448 - accuracy: 0.8432 - false_negatives: 30687.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3443 - accuracy: 0.8432 - false_negatives: 30701.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3441 - accuracy: 0.8438 - false_negatives: 30562.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3439 - accuracy: 0.8432 - false_negatives: 30634.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3438 - accuracy: 0.8434 - false_negatives: 30609.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3442 - accuracy: 0.8434 - false_negatives: 30447.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3440 - accuracy: 0.8430 - false_negatives: 30524.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3446 - accuracy: 0.8433 - false_negatives: 30581.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3446 - accuracy: 0.8425 - false_negatives: 30768.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3447 - accuracy: 0.8429 - false_negatives: 30598.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.3453 - accuracy: 0.8428 - false_negatives: 30703.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3451 - accuracy: 0.8433 - false_negatives: 30567.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3443 - accuracy: 0.8437 - false_negatives: 30479.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 12 AUC Train 0.9271782772124083\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 17ms/step - loss: 0.6968 - accuracy: 0.5706 - false_negatives: 39272.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6257 - accuracy: 0.6558 - false_negatives: 35616.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5850 - accuracy: 0.7087 - false_negatives: 33767.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5522 - accuracy: 0.7452 - false_negatives: 32076.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.5212 - accuracy: 0.7711 - false_negatives: 30075.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4947 - accuracy: 0.7880 - false_negatives: 28229.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.4686 - accuracy: 0.8033 - false_negatives: 26462.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4472 - accuracy: 0.8139 - false_negatives: 25405.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.4298 - accuracy: 0.8226 - false_negatives: 24998.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4169 - accuracy: 0.8282 - false_negatives: 25498.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4067 - accuracy: 0.8328 - false_negatives: 25822.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4001 - accuracy: 0.8355 - false_negatives: 26048.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.3928 - accuracy: 0.8383 - false_negatives: 26393.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.3875 - accuracy: 0.8408 - false_negatives: 26492.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3848 - accuracy: 0.8413 - false_negatives: 26764.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3804 - accuracy: 0.8430 - false_negatives: 26786.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3773 - accuracy: 0.8442 - false_negatives: 26940.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3749 - accuracy: 0.8440 - false_negatives: 27239.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3725 - accuracy: 0.8448 - false_negatives: 27313.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3709 - accuracy: 0.8456 - false_negatives: 27594.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 6s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 13 AUC Train 0.9271859622861307\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.3084 - accuracy: 0.8597 - false_negatives: 20207.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2943 - accuracy: 0.8649 - false_negatives: 20478.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2918 - accuracy: 0.8656 - false_negatives: 20848.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2905 - accuracy: 0.8664 - false_negatives: 20811.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2893 - accuracy: 0.8664 - false_negatives: 20936.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2884 - accuracy: 0.8674 - false_negatives: 20744.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2878 - accuracy: 0.8675 - false_negatives: 20620.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2870 - accuracy: 0.8678 - false_negatives: 20426.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2863 - accuracy: 0.8680 - false_negatives: 20435.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.2859 - accuracy: 0.8687 - false_negatives: 20265.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2855 - accuracy: 0.8689 - false_negatives: 20262.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2852 - accuracy: 0.8689 - false_negatives: 20309.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2850 - accuracy: 0.8688 - false_negatives: 20346.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2848 - accuracy: 0.8691 - false_negatives: 20238.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2847 - accuracy: 0.8692 - false_negatives: 20247.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2845 - accuracy: 0.8690 - false_negatives: 20252.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2843 - accuracy: 0.8691 - false_negatives: 20240.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2842 - accuracy: 0.8693 - false_negatives: 20199.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2842 - accuracy: 0.8690 - false_negatives: 20240.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2841 - accuracy: 0.8696 - false_negatives: 20084.0000\n",
            "9632/9632 [==============================] - 18s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 14 AUC Train 0.93314044260149\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 17ms/step - loss: 0.7131 - accuracy: 0.5265 - false_negatives: 41795.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5718 - accuracy: 0.7491 - false_negatives: 21255.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4898 - accuracy: 0.8070 - false_negatives: 15152.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4369 - accuracy: 0.8239 - false_negatives: 14265.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4002 - accuracy: 0.8354 - false_negatives: 14967.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3737 - accuracy: 0.8444 - false_negatives: 16085.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3547 - accuracy: 0.8508 - false_negatives: 17094.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3406 - accuracy: 0.8554 - false_negatives: 17797.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3299 - accuracy: 0.8588 - false_negatives: 18595.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3223 - accuracy: 0.8610 - false_negatives: 19100.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3170 - accuracy: 0.8625 - false_negatives: 19451.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3133 - accuracy: 0.8634 - false_negatives: 19849.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3107 - accuracy: 0.8638 - false_negatives: 19955.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3088 - accuracy: 0.8640 - false_negatives: 20275.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3074 - accuracy: 0.8642 - false_negatives: 20380.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3062 - accuracy: 0.8642 - false_negatives: 20576.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3053 - accuracy: 0.8642 - false_negatives: 20492.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3046 - accuracy: 0.8642 - false_negatives: 20614.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3039 - accuracy: 0.8642 - false_negatives: 20771.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3033 - accuracy: 0.8642 - false_negatives: 20674.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 15 AUC Train 0.9267779874338191\n",
            "2451.929089307785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_nn1['hd'] = 2"
      ],
      "metadata": {
        "id": "3Vo40d-C_p_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_nn1.to_csv('grid_1.csv', index = False)"
      ],
      "metadata": {
        "id": "zmRbiTcgD8Wk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_nn1 = pd.read_csv('grid_1.csv', index_col=False)\n",
        "grid_search_nn1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "2se9fzgwevyt",
        "outputId": "f7e49919-6e7a-4191-90ea-1e25873fa5b3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    hd  nodes activation  dropout  batch_size  auc_train  auc_test1  auc_test2\n",
              "0    2      4       relu      0.5         100   0.928832   0.916810   0.938458\n",
              "1    2      4       relu      0.5       10000   0.925344   0.912269   0.935024\n",
              "2    2      4       relu      0.0         100   0.931289   0.919808   0.940360\n",
              "3    2      4       relu      0.0       10000   0.924913   0.911534   0.935018\n",
              "4    2      4       tanh      0.5         100   0.926812   0.914070   0.937749\n",
              "5    2      4       tanh      0.5       10000   0.925090   0.911815   0.936053\n",
              "6    2      4       tanh      0.0         100   0.932702   0.922581   0.940042\n",
              "7    2      4       tanh      0.0       10000   0.926229   0.914412   0.936055\n",
              "8    2      6       relu      0.5         100   0.929300   0.917527   0.938869\n",
              "9    2      6       relu      0.5       10000   0.925148   0.912114   0.935019\n",
              "10   2      6       relu      0.0         100   0.934090   0.924959   0.940911\n",
              "11   2      6       relu      0.0       10000   0.927383   0.914655   0.937462\n",
              "12   2      6       tanh      0.5         100   0.927178   0.914925   0.937700\n",
              "13   2      6       tanh      0.5       10000   0.927186   0.914694   0.937659\n",
              "14   2      6       tanh      0.0         100   0.933140   0.923371   0.940384\n",
              "15   2      6       tanh      0.0       10000   0.926778   0.915076   0.936231"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f950cf78-a8a2-4a12-8d75-323d81135441\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hd</th>\n",
              "      <th>nodes</th>\n",
              "      <th>activation</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>auc_train</th>\n",
              "      <th>auc_test1</th>\n",
              "      <th>auc_test2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.928832</td>\n",
              "      <td>0.916810</td>\n",
              "      <td>0.938458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.925344</td>\n",
              "      <td>0.912269</td>\n",
              "      <td>0.935024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.931289</td>\n",
              "      <td>0.919808</td>\n",
              "      <td>0.940360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.924913</td>\n",
              "      <td>0.911534</td>\n",
              "      <td>0.935018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.926812</td>\n",
              "      <td>0.914070</td>\n",
              "      <td>0.937749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.925090</td>\n",
              "      <td>0.911815</td>\n",
              "      <td>0.936053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.932702</td>\n",
              "      <td>0.922581</td>\n",
              "      <td>0.940042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926229</td>\n",
              "      <td>0.914412</td>\n",
              "      <td>0.936055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.929300</td>\n",
              "      <td>0.917527</td>\n",
              "      <td>0.938869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.925148</td>\n",
              "      <td>0.912114</td>\n",
              "      <td>0.935019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.934090</td>\n",
              "      <td>0.924959</td>\n",
              "      <td>0.940911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.927383</td>\n",
              "      <td>0.914655</td>\n",
              "      <td>0.937462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.927178</td>\n",
              "      <td>0.914925</td>\n",
              "      <td>0.937700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.927186</td>\n",
              "      <td>0.914694</td>\n",
              "      <td>0.937659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.933140</td>\n",
              "      <td>0.923371</td>\n",
              "      <td>0.940384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926778</td>\n",
              "      <td>0.915076</td>\n",
              "      <td>0.936231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f950cf78-a8a2-4a12-8d75-323d81135441')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f950cf78-a8a2-4a12-8d75-323d81135441 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f950cf78-a8a2-4a12-8d75-323d81135441');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first step: create a Sequential object, as a sequence of layers. B/C NN is a sequence of layers.\n",
        "t1 = t.time()\n",
        "grid_search_nn2 = pd.DataFrame(columns = ['hd', 'nodes', 'activation', 'dropout', 'batch_size', 'auc_train', 'auc_test1', 'auc_test2'])\n",
        "\n",
        "\n",
        "neurons = [4, 6]\n",
        "activations = ['relu', 'tanh']\n",
        "dropout = [.5, 0]\n",
        "batch_sizes = [100, 10000]\n",
        "\n",
        "row = 0\n",
        "for i in neurons:\n",
        "  for a in activations:\n",
        "    for d in dropout:\n",
        "      for s in batch_sizes:\n",
        "        \n",
        "        grid_search_nn2.loc[row, 'nodes'] = i\n",
        "        grid_search_nn2.loc[row, 'activation'] = a\n",
        "        grid_search_nn2.loc[row, 'dropout'] = d\n",
        "        grid_search_nn2.loc[row, 'batch_size'] = s\n",
        "\n",
        "        classifier = Sequential()\n",
        "\n",
        "        # add the first hidden layer\n",
        "        classifier.add(Dense(units=i,kernel_initializer='glorot_uniform',\n",
        "                            activation = a))\n",
        "        classifier.add(Dropout(d))\n",
        "\n",
        "        # add the second hidden layer\n",
        "        classifier.add(Dense(units=i,kernel_initializer='glorot_uniform',\n",
        "                        activation = a))\n",
        "        classifier.add(Dropout(d))\n",
        "\n",
        "        # add the third hidden layer\n",
        "        classifier.add(Dense(units=i,kernel_initializer='glorot_uniform',\n",
        "                        activation = a))\n",
        "        classifier.add(Dropout(d))\n",
        "\n",
        "        # add the fourth hidden layer\n",
        "        classifier.add(Dense(units=i,kernel_initializer='glorot_uniform',\n",
        "                        activation = a))\n",
        "        classifier.add(Dropout(d))\n",
        "\n",
        "        # add the output layer\n",
        "        classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',\n",
        "                            activation = 'sigmoid'))\n",
        "\n",
        "        # add additional parameters\n",
        "        classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy', 'FalseNegatives'])\n",
        "\n",
        "        # train the model\n",
        "        classifier.fit(xtrain_n_df,ytrain,batch_size=s,epochs=20)\n",
        "\n",
        "        grid_search_nn2.loc[row, 'auc_train'] = roc_auc_score(ytrain, classifier.predict(xtrain_n_df))\n",
        "        grid_search_nn2.loc[row, 'auc_test1'] = roc_auc_score(ytest1, classifier.predict(xtest1_n_df))\n",
        "        grid_search_nn2.loc[row, 'auc_test2'] = roc_auc_score(ytest2, classifier.predict(xtest2_n_df))\n",
        "        print(\"Best Parameter Iteration\",  row, \"AUC Train\", roc_auc_score(ytrain, classifier.predict(xtrain_n_df)))\n",
        "\n",
        "        row += 1\n",
        "        \n",
        "grid_search_nn2['hd'] = 4\n",
        "t2 = t.time()\n",
        "print(t2 - t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlWimQUOEEQi",
        "outputId": "1f1b2f6b-bc2b-4a01-f1de-f401da50553b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.5563 - accuracy: 0.7410 - false_negatives: 79515.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.5170 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 12s 4ms/step - loss: 0.5159 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.5148 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.5158 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.5152 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.5153 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.5152 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.5155 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.5152 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.5150 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.5153 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.5150 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.5151 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.5154 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.5149 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.5139 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.5154 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.5143 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.5150 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 1ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 0 AUC Train 0.8860326677497017\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 15ms/step - loss: 0.8267 - accuracy: 0.6720 - false_negatives: 67948.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.7265 - accuracy: 0.7144 - false_negatives: 69635.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.6844 - accuracy: 0.7319 - false_negatives: 71036.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.6626 - accuracy: 0.7388 - false_negatives: 72110.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.6450 - accuracy: 0.7431 - false_negatives: 72689.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.6308 - accuracy: 0.7474 - false_negatives: 72598.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.6204 - accuracy: 0.7495 - false_negatives: 72372.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 0.6104 - accuracy: 0.7515 - false_negatives: 72197.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.6024 - accuracy: 0.7533 - false_negatives: 71984.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.5955 - accuracy: 0.7548 - false_negatives: 71628.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.5897 - accuracy: 0.7558 - false_negatives: 71414.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.5837 - accuracy: 0.7572 - false_negatives: 71154.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5806 - accuracy: 0.7579 - false_negatives: 70862.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.5763 - accuracy: 0.7586 - false_negatives: 70617.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5727 - accuracy: 0.7597 - false_negatives: 70371.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5702 - accuracy: 0.7598 - false_negatives: 70291.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5673 - accuracy: 0.7599 - false_negatives: 70242.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5645 - accuracy: 0.7613 - false_negatives: 69800.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5627 - accuracy: 0.7612 - false_negatives: 69808.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5610 - accuracy: 0.7617 - false_negatives: 69696.0000\n",
            "9632/9632 [==============================] - 15s 2ms/step\n",
            "1937/1937 [==============================] - 3s 1ms/step\n",
            "2774/2774 [==============================] - 6s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 1 AUC Train 0.8960601040203633\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.3229 - accuracy: 0.8513 - false_negatives: 25643.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2914 - accuracy: 0.8663 - false_negatives: 20593.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2895 - accuracy: 0.8666 - false_negatives: 20419.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2890 - accuracy: 0.8671 - false_negatives: 20163.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2887 - accuracy: 0.8672 - false_negatives: 20323.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2885 - accuracy: 0.8672 - false_negatives: 20512.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2882 - accuracy: 0.8674 - false_negatives: 20327.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2880 - accuracy: 0.8676 - false_negatives: 20623.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2877 - accuracy: 0.8679 - false_negatives: 20373.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2874 - accuracy: 0.8676 - false_negatives: 20375.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2871 - accuracy: 0.8679 - false_negatives: 20334.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2869 - accuracy: 0.8681 - false_negatives: 20411.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2866 - accuracy: 0.8681 - false_negatives: 20383.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2865 - accuracy: 0.8678 - false_negatives: 20417.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2863 - accuracy: 0.8683 - false_negatives: 20333.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2863 - accuracy: 0.8681 - false_negatives: 20103.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2862 - accuracy: 0.8684 - false_negatives: 20141.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2861 - accuracy: 0.8684 - false_negatives: 20173.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2861 - accuracy: 0.8685 - false_negatives: 20212.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2860 - accuracy: 0.8682 - false_negatives: 20124.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 2 AUC Train 0.9323805928167975\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 14ms/step - loss: 0.6794 - accuracy: 0.7002 - false_negatives: 12456.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.6578 - accuracy: 0.8023 - false_negatives: 13092.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.6393 - accuracy: 0.8257 - false_negatives: 13495.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.6216 - accuracy: 0.8409 - false_negatives: 15305.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.6043 - accuracy: 0.8504 - false_negatives: 16881.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5873 - accuracy: 0.8557 - false_negatives: 18234.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.5704 - accuracy: 0.8590 - false_negatives: 19525.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5538 - accuracy: 0.8612 - false_negatives: 20530.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.5378 - accuracy: 0.8625 - false_negatives: 21427.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5222 - accuracy: 0.8631 - false_negatives: 21990.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5072 - accuracy: 0.8637 - false_negatives: 22502.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4927 - accuracy: 0.8642 - false_negatives: 22652.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4788 - accuracy: 0.8644 - false_negatives: 22924.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4655 - accuracy: 0.8645 - false_negatives: 22970.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4529 - accuracy: 0.8646 - false_negatives: 23091.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.4410 - accuracy: 0.8646 - false_negatives: 23367.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4298 - accuracy: 0.8648 - false_negatives: 23237.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4194 - accuracy: 0.8648 - false_negatives: 23263.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4096 - accuracy: 0.8649 - false_negatives: 23387.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4006 - accuracy: 0.8648 - false_negatives: 23439.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 3 AUC Train 0.9066551084920694\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 9s 2ms/step - loss: 0.4778 - accuracy: 0.7749 - false_negatives: 47859.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4148 - accuracy: 0.8015 - false_negatives: 44978.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4096 - accuracy: 0.8043 - false_negatives: 45072.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4075 - accuracy: 0.8056 - false_negatives: 45059.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4057 - accuracy: 0.8107 - false_negatives: 43805.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4064 - accuracy: 0.8084 - false_negatives: 44495.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4060 - accuracy: 0.8095 - false_negatives: 44268.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.4055 - accuracy: 0.8096 - false_negatives: 44334.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4050 - accuracy: 0.8108 - false_negatives: 43852.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4051 - accuracy: 0.8110 - false_negatives: 43751.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4067 - accuracy: 0.8094 - false_negatives: 44288.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4054 - accuracy: 0.8086 - false_negatives: 44529.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4056 - accuracy: 0.8111 - false_negatives: 43736.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4052 - accuracy: 0.8093 - false_negatives: 44391.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4050 - accuracy: 0.8117 - false_negatives: 43550.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4058 - accuracy: 0.8090 - false_negatives: 44506.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.4050 - accuracy: 0.8106 - false_negatives: 43712.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4038 - accuracy: 0.8097 - false_negatives: 44145.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4051 - accuracy: 0.8091 - false_negatives: 44308.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4052 - accuracy: 0.8114 - false_negatives: 43652.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 4 AUC Train 0.9271423269239017\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 18ms/step - loss: 0.7262 - accuracy: 0.5804 - false_negatives: 52319.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.6773 - accuracy: 0.6333 - false_negatives: 56417.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.6375 - accuracy: 0.6696 - false_negatives: 57680.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.6025 - accuracy: 0.6997 - false_negatives: 57902.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.5731 - accuracy: 0.7282 - false_negatives: 56529.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.5476 - accuracy: 0.7502 - false_negatives: 54462.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.5265 - accuracy: 0.7638 - false_negatives: 52339.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.5106 - accuracy: 0.7740 - false_negatives: 50657.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4985 - accuracy: 0.7827 - false_negatives: 49028.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4873 - accuracy: 0.7891 - false_negatives: 47748.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.4778 - accuracy: 0.7952 - false_negatives: 46237.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4713 - accuracy: 0.7986 - false_negatives: 45433.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4664 - accuracy: 0.8025 - false_negatives: 44099.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4617 - accuracy: 0.8038 - false_negatives: 43946.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.4562 - accuracy: 0.8072 - false_negatives: 43334.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4515 - accuracy: 0.8091 - false_negatives: 42589.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 0.4482 - accuracy: 0.8110 - false_negatives: 42449.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 0.4448 - accuracy: 0.8118 - false_negatives: 42460.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 0.4436 - accuracy: 0.8129 - false_negatives: 42337.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 1s 25ms/step - loss: 0.4400 - accuracy: 0.8148 - false_negatives: 41839.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 5 AUC Train 0.9265559379042546\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 9s 2ms/step - loss: 0.3204 - accuracy: 0.8524 - false_negatives: 21586.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2941 - accuracy: 0.8644 - false_negatives: 20953.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2922 - accuracy: 0.8653 - false_negatives: 21094.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2908 - accuracy: 0.8659 - false_negatives: 21243.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2898 - accuracy: 0.8664 - false_negatives: 21074.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2892 - accuracy: 0.8666 - false_negatives: 21073.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2884 - accuracy: 0.8671 - false_negatives: 20956.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2881 - accuracy: 0.8673 - false_negatives: 20771.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2876 - accuracy: 0.8670 - false_negatives: 20787.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2873 - accuracy: 0.8673 - false_negatives: 20624.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2871 - accuracy: 0.8676 - false_negatives: 20598.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2867 - accuracy: 0.8679 - false_negatives: 20302.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2866 - accuracy: 0.8678 - false_negatives: 20370.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2866 - accuracy: 0.8678 - false_negatives: 20343.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2862 - accuracy: 0.8679 - false_negatives: 20215.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2861 - accuracy: 0.8681 - false_negatives: 20224.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2860 - accuracy: 0.8680 - false_negatives: 20217.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2859 - accuracy: 0.8681 - false_negatives: 20093.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2859 - accuracy: 0.8681 - false_negatives: 20106.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2858 - accuracy: 0.8683 - false_negatives: 20090.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 6 AUC Train 0.9326296592233215\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 18ms/step - loss: 0.6259 - accuracy: 0.7328 - false_negatives: 26050.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.5393 - accuracy: 0.8009 - false_negatives: 18511.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4809 - accuracy: 0.8210 - false_negatives: 16704.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4384 - accuracy: 0.8347 - false_negatives: 16998.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.4066 - accuracy: 0.8445 - false_negatives: 17838.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.3838 - accuracy: 0.8497 - false_negatives: 18075.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.3679 - accuracy: 0.8528 - false_negatives: 17853.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.3567 - accuracy: 0.8552 - false_negatives: 18025.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3485 - accuracy: 0.8566 - false_negatives: 17678.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3422 - accuracy: 0.8580 - false_negatives: 17990.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3372 - accuracy: 0.8591 - false_negatives: 17943.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3330 - accuracy: 0.8599 - false_negatives: 17963.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3294 - accuracy: 0.8606 - false_negatives: 18180.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3262 - accuracy: 0.8611 - false_negatives: 18312.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3235 - accuracy: 0.8618 - false_negatives: 18476.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3210 - accuracy: 0.8621 - false_negatives: 18423.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3188 - accuracy: 0.8623 - false_negatives: 18440.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3168 - accuracy: 0.8628 - false_negatives: 18762.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3149 - accuracy: 0.8630 - false_negatives: 18855.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3132 - accuracy: 0.8634 - false_negatives: 18904.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 7 AUC Train 0.9260393194156608\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 9s 2ms/step - loss: 0.4768 - accuracy: 0.7394 - false_negatives: 79416.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4288 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4217 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4174 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4174 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.4179 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4179 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.4177 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4177 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.4171 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4159 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4158 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4155 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4145 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.4159 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4163 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.4159 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.4173 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4144 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.4150 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 8 AUC Train 0.908717062740921\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 19ms/step - loss: 0.6939 - accuracy: 0.6696 - false_negatives: 66892.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.6725 - accuracy: 0.7174 - false_negatives: 74814.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.6481 - accuracy: 0.7314 - false_negatives: 78329.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.6209 - accuracy: 0.7374 - false_negatives: 79281.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.5903 - accuracy: 0.7413 - false_negatives: 79020.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.5638 - accuracy: 0.7415 - false_negatives: 79094.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.5437 - accuracy: 0.7403 - false_negatives: 79593.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.5265 - accuracy: 0.7406 - false_negatives: 79607.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.5123 - accuracy: 0.7409 - false_negatives: 79605.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.5044 - accuracy: 0.7411 - false_negatives: 79607.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.4978 - accuracy: 0.7413 - false_negatives: 79607.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4944 - accuracy: 0.7413 - false_negatives: 79609.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 0.4934 - accuracy: 0.7414 - false_negatives: 79609.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.4913 - accuracy: 0.7414 - false_negatives: 79611.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.4894 - accuracy: 0.7415 - false_negatives: 79611.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.4874 - accuracy: 0.7415 - false_negatives: 79609.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 0.4874 - accuracy: 0.7416 - false_negatives: 79611.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.4863 - accuracy: 0.7416 - false_negatives: 79611.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.4857 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.4862 - accuracy: 0.7417 - false_negatives: 79611.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 9 AUC Train 0.9236650707173536\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 9s 2ms/step - loss: 0.3259 - accuracy: 0.8500 - false_negatives: 26462.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2943 - accuracy: 0.8654 - false_negatives: 21238.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2912 - accuracy: 0.8661 - false_negatives: 21252.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2899 - accuracy: 0.8663 - false_negatives: 21234.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2889 - accuracy: 0.8668 - false_negatives: 20969.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2882 - accuracy: 0.8671 - false_negatives: 20506.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2876 - accuracy: 0.8674 - false_negatives: 20600.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2871 - accuracy: 0.8679 - false_negatives: 20277.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2867 - accuracy: 0.8681 - false_negatives: 20463.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2864 - accuracy: 0.8683 - false_negatives: 20335.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2861 - accuracy: 0.8682 - false_negatives: 20352.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2857 - accuracy: 0.8683 - false_negatives: 20398.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2853 - accuracy: 0.8687 - false_negatives: 20287.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2850 - accuracy: 0.8689 - false_negatives: 20193.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2849 - accuracy: 0.8689 - false_negatives: 20140.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2847 - accuracy: 0.8688 - false_negatives: 20148.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2846 - accuracy: 0.8689 - false_negatives: 20119.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2846 - accuracy: 0.8685 - false_negatives: 20278.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2844 - accuracy: 0.8691 - false_negatives: 20160.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2844 - accuracy: 0.8690 - false_negatives: 20039.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 10 AUC Train 0.9333349623736684\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 10ms/step - loss: 0.6890 - accuracy: 0.6235 - false_negatives: 59119.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.6665 - accuracy: 0.7554 - false_negatives: 73230.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6262 - accuracy: 0.8042 - false_negatives: 51059.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5404 - accuracy: 0.8407 - false_negatives: 24315.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.4201 - accuracy: 0.8469 - false_negatives: 17504.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3416 - accuracy: 0.8545 - false_negatives: 19231.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3148 - accuracy: 0.8583 - false_negatives: 19543.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3065 - accuracy: 0.8606 - false_negatives: 19841.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3025 - accuracy: 0.8619 - false_negatives: 19898.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.2999 - accuracy: 0.8630 - false_negatives: 20507.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2981 - accuracy: 0.8637 - false_negatives: 20991.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.2968 - accuracy: 0.8641 - false_negatives: 21096.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.2958 - accuracy: 0.8645 - false_negatives: 21192.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.2950 - accuracy: 0.8649 - false_negatives: 21070.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.2945 - accuracy: 0.8650 - false_negatives: 21144.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.2940 - accuracy: 0.8654 - false_negatives: 20825.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.2936 - accuracy: 0.8654 - false_negatives: 20958.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.2933 - accuracy: 0.8656 - false_negatives: 20830.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.2931 - accuracy: 0.8657 - false_negatives: 20718.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.2928 - accuracy: 0.8658 - false_negatives: 20897.0000\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 16s 2ms/step\n",
            "Best Parameter Iteration 11 AUC Train 0.9287050489651921\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.4364 - accuracy: 0.7965 - false_negatives: 36488.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.3787 - accuracy: 0.8259 - false_negatives: 31011.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3711 - accuracy: 0.8313 - false_negatives: 31467.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3693 - accuracy: 0.8335 - false_negatives: 31517.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3680 - accuracy: 0.8331 - false_negatives: 31886.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3677 - accuracy: 0.8329 - false_negatives: 31798.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3661 - accuracy: 0.8335 - false_negatives: 31723.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3670 - accuracy: 0.8339 - false_negatives: 31677.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3663 - accuracy: 0.8332 - false_negatives: 31525.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3666 - accuracy: 0.8338 - false_negatives: 31577.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3670 - accuracy: 0.8333 - false_negatives: 31537.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3670 - accuracy: 0.8330 - false_negatives: 31626.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3658 - accuracy: 0.8335 - false_negatives: 31558.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3669 - accuracy: 0.8330 - false_negatives: 31329.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3657 - accuracy: 0.8332 - false_negatives: 31525.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.3657 - accuracy: 0.8338 - false_negatives: 31541.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3672 - accuracy: 0.8323 - false_negatives: 31752.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3650 - accuracy: 0.8343 - false_negatives: 31491.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3662 - accuracy: 0.8326 - false_negatives: 31513.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.3653 - accuracy: 0.8344 - false_negatives: 31255.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 6s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 12 AUC Train 0.9270978901087323\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 20ms/step - loss: 0.6931 - accuracy: 0.5952 - false_negatives: 38831.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 1s 28ms/step - loss: 0.6324 - accuracy: 0.6571 - false_negatives: 38762.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 0.5808 - accuracy: 0.7093 - false_negatives: 37197.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 0.5401 - accuracy: 0.7462 - false_negatives: 36048.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 0.5101 - accuracy: 0.7706 - false_negatives: 35843.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 30ms/step - loss: 0.4866 - accuracy: 0.7890 - false_negatives: 35408.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 30ms/step - loss: 0.4688 - accuracy: 0.7996 - false_negatives: 35480.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4577 - accuracy: 0.8070 - false_negatives: 35346.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4477 - accuracy: 0.8134 - false_negatives: 34630.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.4388 - accuracy: 0.8179 - false_negatives: 33823.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4333 - accuracy: 0.8212 - false_negatives: 33305.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4275 - accuracy: 0.8235 - false_negatives: 33003.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4218 - accuracy: 0.8267 - false_negatives: 32273.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4175 - accuracy: 0.8284 - false_negatives: 31910.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4152 - accuracy: 0.8286 - false_negatives: 32229.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.4117 - accuracy: 0.8306 - false_negatives: 31612.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4088 - accuracy: 0.8308 - false_negatives: 31932.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.4039 - accuracy: 0.8332 - false_negatives: 31766.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4026 - accuracy: 0.8331 - false_negatives: 31656.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.4008 - accuracy: 0.8346 - false_negatives: 31730.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 4s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 13 AUC Train 0.9267440975415223\n",
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 10s 3ms/step - loss: 0.3090 - accuracy: 0.8600 - false_negatives: 21229.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2922 - accuracy: 0.8653 - false_negatives: 21540.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2901 - accuracy: 0.8660 - false_negatives: 21337.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2891 - accuracy: 0.8668 - false_negatives: 20993.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2885 - accuracy: 0.8671 - false_negatives: 20777.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2879 - accuracy: 0.8678 - false_negatives: 20545.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2872 - accuracy: 0.8678 - false_negatives: 20422.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2871 - accuracy: 0.8680 - false_negatives: 20392.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2866 - accuracy: 0.8684 - false_negatives: 20235.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2866 - accuracy: 0.8685 - false_negatives: 20215.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2864 - accuracy: 0.8683 - false_negatives: 20134.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2861 - accuracy: 0.8686 - false_negatives: 20138.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2859 - accuracy: 0.8687 - false_negatives: 19991.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2858 - accuracy: 0.8685 - false_negatives: 20062.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2856 - accuracy: 0.8687 - false_negatives: 20019.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2856 - accuracy: 0.8689 - false_negatives: 19974.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2854 - accuracy: 0.8692 - false_negatives: 19962.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2853 - accuracy: 0.8687 - false_negatives: 19992.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2853 - accuracy: 0.8690 - false_negatives: 19936.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 9s 3ms/step - loss: 0.2850 - accuracy: 0.8691 - false_negatives: 19955.0000\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "1937/1937 [==============================] - 4s 2ms/step\n",
            "2774/2774 [==============================] - 5s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 14 AUC Train 0.933078729845878\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 2s 19ms/step - loss: 0.6888 - accuracy: 0.5486 - false_negatives: 50421.0000\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.5050 - accuracy: 0.7818 - false_negatives: 26876.0000\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.4153 - accuracy: 0.8241 - false_negatives: 18264.0000\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.3702 - accuracy: 0.8416 - false_negatives: 18401.0000\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.3457 - accuracy: 0.8506 - false_negatives: 20427.0000\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.3325 - accuracy: 0.8552 - false_negatives: 21165.0000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.3245 - accuracy: 0.8582 - false_negatives: 21025.0000\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.3190 - accuracy: 0.8600 - false_negatives: 20993.0000\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.3150 - accuracy: 0.8613 - false_negatives: 20808.0000\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3120 - accuracy: 0.8624 - false_negatives: 20816.0000\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3097 - accuracy: 0.8632 - false_negatives: 20620.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3080 - accuracy: 0.8635 - false_negatives: 20624.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3066 - accuracy: 0.8638 - false_negatives: 20554.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3055 - accuracy: 0.8638 - false_negatives: 20560.0000\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3045 - accuracy: 0.8641 - false_negatives: 20454.0000\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3037 - accuracy: 0.8642 - false_negatives: 20412.0000\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3029 - accuracy: 0.8645 - false_negatives: 20373.0000\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3023 - accuracy: 0.8644 - false_negatives: 20312.0000\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3016 - accuracy: 0.8646 - false_negatives: 20292.0000\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3010 - accuracy: 0.8646 - false_negatives: 20299.0000\n",
            "9632/9632 [==============================] - 19s 2ms/step\n",
            "1937/1937 [==============================] - 3s 2ms/step\n",
            "2774/2774 [==============================] - 6s 2ms/step\n",
            "9632/9632 [==============================] - 17s 2ms/step\n",
            "Best Parameter Iteration 15 AUC Train 0.9269311836110086\n",
            "2470.3295769691467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_nn2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "BjDD5sLJrcnX",
        "outputId": "6f5a0824-66ea-4315-f68c-fcf7cdf47433"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    hd nodes activation dropout batch_size auc_train auc_test1 auc_test2\n",
              "0    4     4       relu     0.5        100  0.886033  0.886025  0.879065\n",
              "1    4     4       relu     0.5      10000   0.89606  0.870127  0.917721\n",
              "2    4     4       relu       0        100  0.932381   0.92169  0.940576\n",
              "3    4     4       relu       0      10000  0.906655  0.884888  0.925662\n",
              "4    4     4       tanh     0.5        100  0.927142   0.91422  0.938102\n",
              "5    4     4       tanh     0.5      10000  0.926556  0.913982  0.937402\n",
              "6    4     4       tanh       0        100   0.93263  0.922721  0.940084\n",
              "7    4     4       tanh       0      10000  0.926039  0.914242  0.934664\n",
              "8    4     6       relu     0.5        100  0.908717  0.903914  0.907567\n",
              "9    4     6       relu     0.5      10000  0.923665  0.912266  0.932783\n",
              "10   4     6       relu       0        100  0.933335  0.922316  0.941022\n",
              "11   4     6       relu       0      10000  0.928705  0.916279  0.938372\n",
              "12   4     6       tanh     0.5        100  0.927098   0.91449  0.937924\n",
              "13   4     6       tanh     0.5      10000  0.926744  0.914132  0.937223\n",
              "14   4     6       tanh       0        100  0.933079  0.922741  0.940284\n",
              "15   4     6       tanh       0      10000  0.926931  0.914981  0.936395"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12b8cdd5-70bd-482a-bbbc-432f8cacced3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hd</th>\n",
              "      <th>nodes</th>\n",
              "      <th>activation</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>auc_train</th>\n",
              "      <th>auc_test1</th>\n",
              "      <th>auc_test2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.886033</td>\n",
              "      <td>0.886025</td>\n",
              "      <td>0.879065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.89606</td>\n",
              "      <td>0.870127</td>\n",
              "      <td>0.917721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.932381</td>\n",
              "      <td>0.92169</td>\n",
              "      <td>0.940576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.906655</td>\n",
              "      <td>0.884888</td>\n",
              "      <td>0.925662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.927142</td>\n",
              "      <td>0.91422</td>\n",
              "      <td>0.938102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926556</td>\n",
              "      <td>0.913982</td>\n",
              "      <td>0.937402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.93263</td>\n",
              "      <td>0.922721</td>\n",
              "      <td>0.940084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926039</td>\n",
              "      <td>0.914242</td>\n",
              "      <td>0.934664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.908717</td>\n",
              "      <td>0.903914</td>\n",
              "      <td>0.907567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.923665</td>\n",
              "      <td>0.912266</td>\n",
              "      <td>0.932783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.933335</td>\n",
              "      <td>0.922316</td>\n",
              "      <td>0.941022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.928705</td>\n",
              "      <td>0.916279</td>\n",
              "      <td>0.938372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.927098</td>\n",
              "      <td>0.91449</td>\n",
              "      <td>0.937924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926744</td>\n",
              "      <td>0.914132</td>\n",
              "      <td>0.937223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.933079</td>\n",
              "      <td>0.922741</td>\n",
              "      <td>0.940284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926931</td>\n",
              "      <td>0.914981</td>\n",
              "      <td>0.936395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12b8cdd5-70bd-482a-bbbc-432f8cacced3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12b8cdd5-70bd-482a-bbbc-432f8cacced3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12b8cdd5-70bd-482a-bbbc-432f8cacced3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_nn2.to_csv('grid_2.csv', index = False)"
      ],
      "metadata": {
        "id": "BtToR-UlRFyI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_nn = pd.concat([grid_search_nn1, grid_search_nn2], axis=0)\n",
        "grid_nn.sort_values(['auc_train'], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x2D3d89Re78q",
        "outputId": "37af2f85-f8cf-4827-bc9b-6ab1cc3b48fe"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    hd nodes activation dropout batch_size auc_train auc_test1 auc_test2\n",
              "10   2     6       relu     0.0        100   0.93409  0.924959  0.940911\n",
              "10   4     6       relu       0        100  0.933335  0.922316  0.941022\n",
              "14   2     6       tanh     0.0        100   0.93314  0.923371  0.940384\n",
              "14   4     6       tanh       0        100  0.933079  0.922741  0.940284\n",
              "6    2     4       tanh     0.0        100  0.932702  0.922581  0.940042\n",
              "6    4     4       tanh       0        100   0.93263  0.922721  0.940084\n",
              "2    4     4       relu       0        100  0.932381   0.92169  0.940576\n",
              "2    2     4       relu     0.0        100  0.931289  0.919808   0.94036\n",
              "8    2     6       relu     0.5        100    0.9293  0.917527  0.938869\n",
              "0    2     4       relu     0.5        100  0.928832   0.91681  0.938458\n",
              "11   4     6       relu       0      10000  0.928705  0.916279  0.938372\n",
              "11   2     6       relu     0.0      10000  0.927383  0.914655  0.937462\n",
              "13   2     6       tanh     0.5      10000  0.927186  0.914694  0.937659\n",
              "12   2     6       tanh     0.5        100  0.927178  0.914925    0.9377\n",
              "4    4     4       tanh     0.5        100  0.927142   0.91422  0.938102\n",
              "12   4     6       tanh     0.5        100  0.927098   0.91449  0.937924\n",
              "15   4     6       tanh       0      10000  0.926931  0.914981  0.936395\n",
              "4    2     4       tanh     0.5        100  0.926812   0.91407  0.937749\n",
              "15   2     6       tanh     0.0      10000  0.926778  0.915076  0.936231\n",
              "13   4     6       tanh     0.5      10000  0.926744  0.914132  0.937223\n",
              "5    4     4       tanh     0.5      10000  0.926556  0.913982  0.937402\n",
              "7    2     4       tanh     0.0      10000  0.926229  0.914412  0.936055\n",
              "7    4     4       tanh       0      10000  0.926039  0.914242  0.934664\n",
              "1    2     4       relu     0.5      10000  0.925344  0.912269  0.935024\n",
              "9    2     6       relu     0.5      10000  0.925148  0.912114  0.935019\n",
              "5    2     4       tanh     0.5      10000   0.92509  0.911815  0.936053\n",
              "3    2     4       relu     0.0      10000  0.924913  0.911534  0.935018\n",
              "9    4     6       relu     0.5      10000  0.923665  0.912266  0.932783\n",
              "8    4     6       relu     0.5        100  0.908717  0.903914  0.907567\n",
              "3    4     4       relu       0      10000  0.906655  0.884888  0.925662\n",
              "1    4     4       relu     0.5      10000   0.89606  0.870127  0.917721\n",
              "0    4     4       relu     0.5        100  0.886033  0.886025  0.879065"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c125c65-e22e-4c0b-86e8-703f7610f08d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hd</th>\n",
              "      <th>nodes</th>\n",
              "      <th>activation</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>auc_train</th>\n",
              "      <th>auc_test1</th>\n",
              "      <th>auc_test2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.93409</td>\n",
              "      <td>0.924959</td>\n",
              "      <td>0.940911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.933335</td>\n",
              "      <td>0.922316</td>\n",
              "      <td>0.941022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.93314</td>\n",
              "      <td>0.923371</td>\n",
              "      <td>0.940384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.933079</td>\n",
              "      <td>0.922741</td>\n",
              "      <td>0.940284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.932702</td>\n",
              "      <td>0.922581</td>\n",
              "      <td>0.940042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.93263</td>\n",
              "      <td>0.922721</td>\n",
              "      <td>0.940084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.932381</td>\n",
              "      <td>0.92169</td>\n",
              "      <td>0.940576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.931289</td>\n",
              "      <td>0.919808</td>\n",
              "      <td>0.94036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.9293</td>\n",
              "      <td>0.917527</td>\n",
              "      <td>0.938869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.928832</td>\n",
              "      <td>0.91681</td>\n",
              "      <td>0.938458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.928705</td>\n",
              "      <td>0.916279</td>\n",
              "      <td>0.938372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.927383</td>\n",
              "      <td>0.914655</td>\n",
              "      <td>0.937462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.927186</td>\n",
              "      <td>0.914694</td>\n",
              "      <td>0.937659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.927178</td>\n",
              "      <td>0.914925</td>\n",
              "      <td>0.9377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.927142</td>\n",
              "      <td>0.91422</td>\n",
              "      <td>0.938102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.927098</td>\n",
              "      <td>0.91449</td>\n",
              "      <td>0.937924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926931</td>\n",
              "      <td>0.914981</td>\n",
              "      <td>0.936395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.926812</td>\n",
              "      <td>0.91407</td>\n",
              "      <td>0.937749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926778</td>\n",
              "      <td>0.915076</td>\n",
              "      <td>0.936231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926744</td>\n",
              "      <td>0.914132</td>\n",
              "      <td>0.937223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926556</td>\n",
              "      <td>0.913982</td>\n",
              "      <td>0.937402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926229</td>\n",
              "      <td>0.914412</td>\n",
              "      <td>0.936055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.926039</td>\n",
              "      <td>0.914242</td>\n",
              "      <td>0.934664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.925344</td>\n",
              "      <td>0.912269</td>\n",
              "      <td>0.935024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.925148</td>\n",
              "      <td>0.912114</td>\n",
              "      <td>0.935019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.92509</td>\n",
              "      <td>0.911815</td>\n",
              "      <td>0.936053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.924913</td>\n",
              "      <td>0.911534</td>\n",
              "      <td>0.935018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.923665</td>\n",
              "      <td>0.912266</td>\n",
              "      <td>0.932783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.908717</td>\n",
              "      <td>0.903914</td>\n",
              "      <td>0.907567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.906655</td>\n",
              "      <td>0.884888</td>\n",
              "      <td>0.925662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.89606</td>\n",
              "      <td>0.870127</td>\n",
              "      <td>0.917721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.886033</td>\n",
              "      <td>0.886025</td>\n",
              "      <td>0.879065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c125c65-e22e-4c0b-86e8-703f7610f08d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c125c65-e22e-4c0b-86e8-703f7610f08d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c125c65-e22e-4c0b-86e8-703f7610f08d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_nn.to_csv('grid_nn.csv', index = False)"
      ],
      "metadata": {
        "id": "6tICphoOVQN5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_n_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t2lgXt4f1PY",
        "outputId": "f4b220d0-3ac6-48f9-e016-af1dfa058e3f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(308200, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first step: create a Sequential object, as a sequence of layers. B/C NN is a sequence of layers.\n",
        "classifier = Sequential()\n",
        "\n",
        "# add the first hidden layer\n",
        "classifier.add(Dense(units=6,kernel_initializer='glorot_uniform',\n",
        "                    activation = 'relu'))\n",
        "\n",
        "# add the second hidden layer\n",
        "classifier.add(Dense(units=6,kernel_initializer='glorot_uniform',\n",
        "                activation = 'relu'))\n",
        "\n",
        "# add the output layer\n",
        "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',\n",
        "                    activation = 'sigmoid'))\n",
        "\n",
        "# add additional parameters\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy', 'FalseNegatives'])\n",
        "\n",
        "# train the model\n",
        "classifier.fit(xtrain_n_df,ytrain,batch_size=100,epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcp5hvYPgrQW",
        "outputId": "ae31ae56-115f-4b40-b081-99ceeb0384ee"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3082/3082 [==============================] - 9s 2ms/step - loss: 0.3065 - accuracy: 0.8573 - false_negatives: 18829.0000\n",
            "Epoch 2/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2901 - accuracy: 0.8663 - false_negatives: 20057.0000\n",
            "Epoch 3/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2888 - accuracy: 0.8666 - false_negatives: 20055.0000\n",
            "Epoch 4/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2880 - accuracy: 0.8672 - false_negatives: 19862.0000\n",
            "Epoch 5/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2873 - accuracy: 0.8676 - false_negatives: 19647.0000\n",
            "Epoch 6/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2868 - accuracy: 0.8678 - false_negatives: 19646.0000\n",
            "Epoch 7/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2862 - accuracy: 0.8686 - false_negatives: 19655.0000\n",
            "Epoch 8/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2854 - accuracy: 0.8687 - false_negatives: 19736.0000\n",
            "Epoch 9/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2846 - accuracy: 0.8692 - false_negatives: 19723.0000\n",
            "Epoch 10/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2841 - accuracy: 0.8697 - false_negatives: 19632.0000\n",
            "Epoch 11/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2837 - accuracy: 0.8696 - false_negatives: 19604.0000\n",
            "Epoch 12/20\n",
            "3082/3082 [==============================] - 7s 2ms/step - loss: 0.2835 - accuracy: 0.8698 - false_negatives: 19623.0000\n",
            "Epoch 13/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2833 - accuracy: 0.8696 - false_negatives: 19661.0000\n",
            "Epoch 14/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2832 - accuracy: 0.8697 - false_negatives: 19729.0000\n",
            "Epoch 15/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2831 - accuracy: 0.8698 - false_negatives: 19652.0000\n",
            "Epoch 16/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2831 - accuracy: 0.8698 - false_negatives: 19609.0000\n",
            "Epoch 17/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2829 - accuracy: 0.8701 - false_negatives: 19546.0000\n",
            "Epoch 18/20\n",
            "3082/3082 [==============================] - 8s 3ms/step - loss: 0.2828 - accuracy: 0.8701 - false_negatives: 19624.0000\n",
            "Epoch 19/20\n",
            "3082/3082 [==============================] - 6s 2ms/step - loss: 0.2828 - accuracy: 0.8702 - false_negatives: 19554.0000\n",
            "Epoch 20/20\n",
            "3082/3082 [==============================] - 8s 2ms/step - loss: 0.2827 - accuracy: 0.8701 - false_negatives: 19506.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fea843f6ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filename = 'final_nn.sav'\n",
        "pickle.dump(classifier, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "id": "N3By4Vr_hLMH"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(ytrain, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6feYd90ooj4n",
        "outputId": "c4fe077a-9a85-4c3e-845d-d3737294b917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9318542302928623"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'final_nn.sav'\n",
        "classifier = pickle.load(open(filename, 'rb'))"
      ],
      "metadata": {
        "id": "4ZWFIldeihQc"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(xtrain_n_df)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5IrcsV4hJiF",
        "outputId": "63391f93-3c71-489e-9faa-9192983fdbed"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9632/9632 [==============================] - 31s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00140518],\n",
              "       [0.01087826],\n",
              "       [0.00430678],\n",
              "       ...,\n",
              "       [0.00682847],\n",
              "       [0.11247852],\n",
              "       [0.00216041]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tj2b-iJ4bnBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytest1_pred = classifier.predict(xtest1_n_df)\n",
        "ytest1_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTnFefedjH5z",
        "outputId": "1ebdcd5a-955c-4ce2-f1dd-bf050324e2b7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1937/1937 [==============================] - 3s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00351413],\n",
              "       [0.00271205],\n",
              "       [0.46987712],\n",
              "       ...,\n",
              "       [0.0427321 ],\n",
              "       [0.9294626 ],\n",
              "       [0.00364177]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest2_pred = classifier.predict(xtest2_n_df)\n",
        "ytest2_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WyuXvwOnmzx",
        "outputId": "9a8d5455-2843-4053-9188-c8e92714ae83"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2774/2774 [==============================] - 8s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00202247],\n",
              "       [0.00912482],\n",
              "       [0.7535311 ],\n",
              "       ...,\n",
              "       [0.00681261],\n",
              "       [0.6220824 ],\n",
              "       [0.07628394]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rank Ordering\n",
        "perf_train_data = pd.DataFrame({\"Actual\": ytrain['target'], \"Prediction\":y_pred[:, 0] })\n",
        "quantiles = list(set(perf_train_data.Prediction.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])))\n",
        "quantiles.sort()\n",
        "quantiles.insert(0,0)\n",
        "quantiles.insert(len(quantiles),1)\n",
        "quantiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj-Rkk8lbHGU",
        "outputId": "739d9b95-c9ba-40e2-cf9a-6f1235d3c7fb"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0.0020404573995620014,\n",
              " 0.004003044217824936,\n",
              " 0.007986957486718892,\n",
              " 0.018547765538096436,\n",
              " 0.053573647513985634,\n",
              " 0.17486051321029664,\n",
              " 0.3942304342985153,\n",
              " 0.611303222179413,\n",
              " 0.7866362273693086,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perf_train_data[\"Score Bins\"] = pd.cut(perf_train_data[\"Prediction\"], quantiles)\n",
        "stat = perf_train_data.groupby(\"Score Bins\")[\"Actual\"].agg([\"sum\", \"count\"])\n",
        "stat[\"Bad Rate\"] = stat[\"sum\"] / stat[\"count\"]\n",
        "stat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JaWhCWOQbWEm",
        "outputId": "33fd7b02-d673-49e4-dd43-8d2d81bddbad"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     sum  count  Bad Rate\n",
              "Score Bins                               \n",
              "(0.0, 0.00204]        39  30820  0.001265\n",
              "(0.00204, 0.004]      77  30820  0.002498\n",
              "(0.004, 0.00799]     156  30820  0.005062\n",
              "(0.00799, 0.0185]    354  30820  0.011486\n",
              "(0.0185, 0.0536]    1042  30820  0.033809\n",
              "(0.0536, 0.175]     3456  30820  0.112135\n",
              "(0.175, 0.394]      8996  30820  0.291888\n",
              "(0.394, 0.611]     16072  30820  0.521480\n",
              "(0.611, 0.787]     22184  30820  0.719792\n",
              "(0.787, 1.0]       27235  30820  0.883679"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-271bb470-2dc0-4f96-a28d-b7db1729ce40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sum</th>\n",
              "      <th>count</th>\n",
              "      <th>Bad Rate</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Score Bins</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(0.0, 0.00204]</th>\n",
              "      <td>39</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.001265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.00204, 0.004]</th>\n",
              "      <td>77</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.002498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.004, 0.00799]</th>\n",
              "      <td>156</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.005062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.00799, 0.0185]</th>\n",
              "      <td>354</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.011486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.0185, 0.0536]</th>\n",
              "      <td>1042</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.033809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.0536, 0.175]</th>\n",
              "      <td>3456</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.112135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.175, 0.394]</th>\n",
              "      <td>8996</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.291888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.394, 0.611]</th>\n",
              "      <td>16072</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.521480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.611, 0.787]</th>\n",
              "      <td>22184</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.719792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(0.787, 1.0]</th>\n",
              "      <td>27235</td>\n",
              "      <td>30820</td>\n",
              "      <td>0.883679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-271bb470-2dc0-4f96-a28d-b7db1729ce40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-271bb470-2dc0-4f96-a28d-b7db1729ce40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-271bb470-2dc0-4f96-a28d-b7db1729ce40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stat.loc[:, 'Bad Rate'].plot(kind = 'bar', figsize=(15, 8), title = 'Train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "4X_TSkMbbuOo",
        "outputId": "af2b5c48-a1a4-487c-a699-1bf239f8908e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Train'}, xlabel='Score Bins'>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perf_test_data = pd.DataFrame({\"Actual\": ytest1['target'], \"Prediction\": ytest1_pred[:,0]})\n",
        "\n",
        "perf_test_data[\"Score Bins\"] = pd.cut(perf_test_data[\"Prediction\"], quantiles)\n",
        "stat1 = perf_test_data.groupby(\"Score Bins\")[\"Actual\"].agg([\"sum\", \"count\"])\n",
        "stat1[\"Bad Rate\"] = stat1[\"sum\"] / stat1[\"count\"]\n",
        "stat1.loc[:, 'Bad Rate'].plot(kind = 'bar', figsize=(15, 8), title = 'Test1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "9sRGj6meb1M4",
        "outputId": "15e76e02-5587-4e02-e062-46d5509be46a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Test1'}, xlabel='Score Bins'>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perf_test_data1 = pd.DataFrame({\"Actual\": ytest2['target'], \"Prediction\": ytest2_pred[:,0]})\n",
        "\n",
        "perf_test_data1[\"Score Bins\"] = pd.cut(perf_test_data1[\"Prediction\"], quantiles)\n",
        "stat2 = perf_test_data1.groupby(\"Score Bins\")[\"Actual\"].agg([\"sum\", \"count\"])\n",
        "stat2[\"Bad Rate\"] = stat2[\"sum\"] / stat2[\"count\"]\n",
        "stat2.loc[:, 'Bad Rate'].plot(kind = 'bar', figsize=(15, 8), title = 'Test2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "GEryhcv7cAh8",
        "outputId": "6f6bd3b6-906c-4c76-c544-0ec43d65762e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Test2'}, xlabel='Score Bins'>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest2 = pd.read_csv('xtest2.csv')\n",
        "ytest2 = pd.read_csv('ytest2.csv')"
      ],
      "metadata": {
        "id": "rh2fjbdjMjn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in xtest2.columns: \n",
        "  if ('B_' in i ) or ('S_' in i ):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7z-hAGCj0Cq",
        "outputId": "301f928a-98cd-4a8d-c640-5275eefc5222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S_3\n",
            "B_17\n",
            "B_39\n",
            "B_1\n",
            "B_3\n",
            "B_2\n",
            "B_9\n",
            "B_5\n",
            "B_38\n",
            "S_23\n",
            "B_7\n",
            "B_4\n",
            "B_10\n",
            "B_8\n",
            "S_7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy(x, actual, pred, threshold, balance = 'B_2', spend = 'S_3'):\n",
        "  ydf = pd.DataFrame({'actual': actual, 'pred': pred})\n",
        "  df = pd.concat([x, ydf], axis = 1)\n",
        "  total = df.loc[df['pred'] < threshold].shape[0]\n",
        "  default = df.loc[df['pred'] < threshold, 'actual'].mean()\n",
        "\n",
        "  df['revenue'] = df.apply(lambda x: x[balance]*0.02 + x[spend]*.001 if x['actual'] != 1 else 0, axis = 1)\n",
        "\n",
        "  revenue = df.loc[df['pred'] < threshold, 'revenue'].sum()\n",
        "\n",
        "  return [total, default, revenue]\n"
      ],
      "metadata": {
        "id": "WT9ZB-FEj9Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy(xtrain, ytrain['target'], y_pred[:,0], 0.55, balance = 'B_2', spend = 'S_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcdBjtYSRymV",
        "outputId": "0295b0b4-a6e4-4604-94ef-e2ad7e34c98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[208039, 0.10498992977278299, 2390.8141167246567]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy(xtrain, ytrain['target'], y_pred[:,0], 0.35, balance = 'B_2', spend = 'S_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSD6rrzgxF-Y",
        "outputId": "237c3542-fb6d-45c4-a8ec-4f3760a697fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[182839, 0.056114942654466496, 2292.8212212545823]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy(xtest1, ytest1['target'], ytest1_pred[:,0], 0.55, balance = 'B_2', spend = 'S_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdkB8MnijDUO",
        "outputId": "9282d8cc-848d-48fd-91ba-8a750a4e9650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24743, 0.11085963706907004, 280.1134215132236]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.linspace(0, 1, 100)"
      ],
      "metadata": {
        "id": "fnsBoMqaWJLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnINlsszWLAh",
        "outputId": "8d8a6b26-f9e3-4030-c115-3b8b541bedab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010101010101010102"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dh-DhF9Wfnm",
        "outputId": "4e7fe6ab-ae8a-4e4d-c681-3a609fed56d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010101010101010102"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = np.array([])\n",
        "r = np.append([r],[2])\n",
        "np.append([r],[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5IgxoykY8l9",
        "outputId": "ca3c175e-0a44-452e-f85a-c5f9b546cf7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "threshold = np.linspace(0, 1, 100)\n",
        "default = np.array([])\n",
        "revenue = np.array([])\n",
        "\n",
        "for i in range(100) :\n",
        "    lis = strategy(xtrain, ytrain['target'], y_pred[:,0], threshold[i], balance = 'B_2', spend = 'S_3')\n",
        "    default = np.append(default, lis[0])\n",
        "    revenue = np.append(revenue, lis[1])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(threshold, default, label = 'default')\n",
        "\n",
        "ax.plot(threshold, revenue, label = 'revenue')\n",
        "\n",
        "# Add a legend\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "OpsVd7rjNkE7",
        "outputId": "73eecb42-30c0-4ec0-9170-735c1f834c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+NUlEQVR4nO3deXxU5d3///dkskMWQsgmAVlkR1FUjIoL8CMoUtfbjSK2KC0G+0UsUpQbUCxUbF2r9etS8f6JoraC3oAoqyhErGgUQaNglDUBgWSSAElmcr5/nMyEgYCZycycTPJ6Ph7ncWa5ZuYzJ9R59zrXdR2bYRiGAAAAwkiE1QUAAAD4igADAADCDgEGAACEHQIMAAAIOwQYAAAQdggwAAAg7BBgAABA2CHAAACAsBNpdQHBUltbqz179ighIUE2m83qcgAAQCMYhqHy8nJlZWUpIuLk/SwtNsDs2bNH2dnZVpcBAAD8sHPnTnXs2PGkz7fYAJOQkCDJPACJiYkWVwMAABrD4XAoOzvb8zt+Mi02wLhPGyUmJhJgAAAIM780/INBvAAAIOwQYAAAQNghwAAAgLDTYsfANIZhGHI6nXK5XFaXggbY7XZFRkYyDR4AcIJWG2Cqq6u1d+9eHT582OpScArx8fHKzMxUdHS01aUAAJoRnwLM3Llz9fbbb+vbb79VXFycLrzwQj3yyCPq2bOnp81ll12mDz/80Ot1v/vd7/Tcc8957u/YsUMTJkzQmjVr1LZtW40dO1Zz585VZGR9OWvXrtXkyZO1ZcsWZWdna/r06br99tv9/JreamtrVVRUJLvdrqysLEVHR/P/8psZwzBUXV2t/fv3q6ioSGecccYpFzQCALQuPgWYDz/8UHl5eTrvvPPkdDp1//33a/jw4dq6davatGnjaXfnnXfqoYce8tyPj4/33Ha5XBo5cqQyMjK0YcMG7d27V7fddpuioqI0Z84cSVJRUZFGjhyp3//+91qwYIFWrVqlO+64Q5mZmcrNzW3qd1Z1dbVqa2uVnZ3tVRual7i4OEVFRemnn35SdXW1YmNjrS4JANBM+BRgli9f7nV//vz5SktL06ZNm3TJJZd4Ho+Pj1dGRkaD7/HBBx9o69atWrlypdLT0zVgwADNnj1bU6dO1axZsxQdHa3nnntOXbp00d/+9jdJUu/evfXxxx/r8ccfD0iAceP/0Td//I0AAA1p0q9DWVmZJCklJcXr8QULFig1NVX9+vXTtGnTvMaZ5Ofnq3///kpPT/c8lpubK4fDoS1btnjaDBs2zOs9c3NzlZ+f35RyAQBAC+H3IN7a2lpNmjRJF110kfr16+d5/NZbb1Xnzp2VlZWlr776SlOnTlVhYaHefvttSVJxcbFXeJHkuV9cXHzKNg6HQ0eOHFFcXNwJ9VRVVamqqspz3+Fw+PvVAABAM+d3D0xeXp6+/vprLVy40Ovx8ePHKzc3V/3799fo0aP1P//zP1q0aJG2b9/e5GJPZe7cuUpKSvJsrelCjpdddpkmTZrU6PaLFy9W9+7dZbfbfXrdL7HZbFq8eHHA3g8AgJPxK8BMnDhRS5Ys0Zo1a055pUhJGjRokCRp27ZtkqSMjAyVlJR4tXHfd4+bOVmbxMTEBntfJGnatGkqKyvzbDt37vT9i7USv/vd73TDDTdo586dmj17dlA+48cff5TNZlNBQUFQ3h8A0Lr5dArJMAzdfffdWrRokdauXasuXbr84mvcP2CZmZmSpJycHP35z3/Wvn37lJaWJklasWKFEhMT1adPH0+bZcuWeb3PihUrlJOTc9LPiYmJUUxMjC9fp1WqqKjQvn37lJubq6ysLKvLAYCWzzCkWqfkqq7bao67XSPV1ki1tWa7Wqd531W3r3XWtXFJRq1k1O1rXeZt9+O1zrrnj98M772Ou+95zPCuWcYxt0/irJulrAHBO3an4FOAycvL02uvvaZ33nlHCQkJnjErSUlJiouL0/bt2/Xaa6/pyiuvVPv27fXVV1/pnnvu0SWXXKIzzzxTkjR8+HD16dNHY8aM0bx581RcXKzp06crLy/PE0B+//vf6+9//7vuu+8+/fa3v9Xq1av15ptvaunSpQH++ibDMHSkxprVeOOi7D6tQVNZWakJEybo7bffVkJCgv74xz96PV9VVaUHHnhAr7/+ukpLS9WvXz898sgjuuyyy7R27VpdfvnlkqQhQ4ZIktasWaP+/ftr4sSJWrdunQ4dOqRu3brp/vvv1y233OJ539NPP12TJk3yOuU0YMAAXXPNNZo1a9YJdbrD7dlnny1JuvTSS7V27dpGf08ACAqXU6qplGqOSNV1+5ojUs1hyXm0/r7ziOSsqnvsqLl3Hm3gNXVtnFWSq0pyuoNJlXdQaak6nhseAeYf//iHJHPMxbFefvll3X777YqOjtbKlSv1xBNPqLKyUtnZ2br++us1ffp0T1u73a4lS5ZowoQJysnJUZs2bTR27FivdWO6dOmipUuX6p577tGTTz6pjh076sUXXwzoFOpjHalxqc+M94Py3r9k60O5io9u/J9hypQp+vDDD/XOO+8oLS1N999/vz7//HMNGDBAknl6b+vWrVq4cKGysrK0aNEijRgxQps3b9aFF16owsJC9ezZU//+97914YUXKiUlRfv379fAgQM1depUJSYmaunSpRozZoy6deum888/36/v9emnn+r888/XypUr1bdvX1bSBeCf2lqpusLcjjqkqnKpqqz+dnWlGUiqK6Xqw3X7userKurvu287j1j9jUz2GMkeZW4R7r1dioj03uxRdbfrnrdF1O2PvX3MYxGR5n1bhGSz1W32un2EJNtxt+vaSXV724l7z3MN6NAr6IfqZHw+hXQq2dnZJ6zC25DOnTufcIroeJdddpm++OILX8pr8SoqKvTSSy/p1Vdf1dChQyVJr7zyimcc0o4dO/Tyyy9rx44dntNDf/zjH7V8+XK9/PLLmjNnjue0XUpKimfM0WmnnebVk3P33Xfr/fff15tvvul3gOnQoYMkqX379iddEwhAK2EYZng4fKBuOygdLZWOHJKOlNbdrrvvefxQXUCpCE5NtggpKr5uizX3kbFSVFwD+xgpMq6+XVS8+XhUfN1zsVJktLm3Rx+zRZn7yJj62/aYurDB6u9N1WqvhXSsuCi7tj4UnN6dxnx2Y23fvl3V1dWegdGSGUTcl3LYvHmzXC6XevTo4fW6qqoqtW/f/qTv63K5NGfOHL355pvavXu3qqurVVVVxSrFABrmrJIq99dtB44JJnXbkYNmSDlyyNwfPmCeUmkKm12KSZBiE6WYpPrb0W2l6HhzHxUvRbcxn4tuU/fc8ffrHouMIUSEOQKMzOm/vpzGaa4qKipkt9u1adMm2e3ewaht27Ynfd2jjz6qJ598Uk888YT69++vNm3aaNKkSaqurj9vGxERcUIPXE1NTWC/AABrGIbZ0+EOJJX7pcM/SxX7zK1yn1SxX6ooMW8fLfPvc+wxUptUKS5Fiks2t9hj9vEpUlw7c4tNNoNHTKIU09bs3SBw4Bjh/6vdinTr1k1RUVHauHGjOnXqJEk6dOiQvvvuO1166aU6++yz5XK5tG/fPg0ePLjR77t+/XpdffXV+vWvfy3JXKTwu+++88wKk8xTQnv37vXcdzgcKioqOul7use8uFzWDI4GUKe21gwdZbuk0h3mvmyXVFEslZfU730dGxIRKbXpIMWnmsEjvn3dVnc7LkWKb1e3b28Gl6h4QggChgATRtq2batx48ZpypQpat++vdLS0vTAAw94rhfUo0cPjR49Wrfddpv+9re/6eyzz9b+/fu1atUqnXnmmRo5cmSD73vGGWfoX//6lzZs2KB27drpscceU0lJiVeAGTJkiObPn69Ro0YpOTlZM2bMOKGX51hpaWmKi4vT8uXL1bFjR8XGxiopKSmwBwRo7VxOqXyv5NhthhLHbsmxx9zKi83nyovNqbiNERVvBo34VHPfJk1qW7e16VC3r7sfmyxxrTJYiAATZh599FFVVFRo1KhRSkhI0L333uu5JpVkzgh7+OGHde+992r37t1KTU3VBRdcoKuuuuqk7zl9+nT98MMPys3NVXx8vMaPH69rrrnG632nTZumoqIiXXXVVUpKStLs2bNP2QMTGRmpp556Sg899JBmzJihwYMHM40a8IWzWnLU9ZaU7pTKdtb1nJTUBZMS81SPTj25QpI5YDUhS0rqKCVnS4mnSYlZUtt0KSHD3LdNM8eGAGHCZvzS1KIw5XA4lJSUpLKyMiUmJno9d/ToURUVFalLly6KjY21qEI0Bn8rtFhV5VLZ7rqQstsMKKU76jfHHjUqnEREmWEk8TQp6bT6cJKQaW6JmWZAsUcF/SsBgXCq3+9j0QMDAIFkGObMG8cuM4SU1e3L99ad7qk7rVPViIGwkXH1vSZJHaWkbLPHJCGzvvckPpVTOWiVCDAA4Av3uBP3YNgyd69J3Wme0p2NHxAbmyQldjR7TpI6SsmdpOTOdVsncxwKg16BBhFgAOBYNUe8T+WU7aoff1K6UyrfU3ftmF/QpkPdaZ2ODZzSyTBDS0xC8L8P0EIRYAC0LrUuM4wc+tHcSn+SDv1Uv6/c98vv4R53ktzJDCnJneq2bPM0T+Jp5qqtAIKGAAOg5XHVeIeUQ0XSge3SgW3SwaJfXhU2OkFq19kMI8eOP3Hv26aZy8EDsAwBBkB4qj5sBpODP9RtRXX3i8zwYpxiEUV7tDnOpF3deJN2p9ffTu5krgTL2BOgWSPAAGi+jpSaoeTQj94B5cB2cyzKqdhj6oJJ3da+u9S+m7klZdODAoQ5AgwA6xiGOaPnwDZzO/SjOQ7FfernaOmpXx+bLKV0lVK6SO26eN9um870YqAFI8AACC7DMC8I6DnV80PdmJRtZk9KdcWpX982va4XpYt5mielrhclpat53R0ArRIBBkDTGYZ05FB9z8mB7dLP30kHvpd+3iZVl5/8tTa7GUzadzdDSbvTvcelsLw9gAYQYMJYdXW156rPQEhUV5o9Jz9/bwaUn78zw8qhn069sqwtwpzBk9LVe2t/hhlUIvl3DMA3nCAOI5dddpkmTpyoSZMmKTU1Vbm5ufr66691xRVXqG3btkpPT9eYMWP0888/S5Kef/55ZWVlqbbWe9Gtq6++Wr/97W8999955x2dc845io2NVdeuXfXggw/K6XR6nrfZbHrxxRd17bXXKj4+XmeccYbeffddz/Pz589XcnKy12csXrxYtuNmcfzS56AZqTkq7f1S+nKhtGKm9NpN0hNnSnNOk/7vJdK/x0kfPiJtWSQVf1UfXtpmSNmDpLNulYbOkG78/6W7NkoPFEuTNku3vSNd9bh04d1Sr5FShx6EFwB+oQdGMru/aw5b89lR8T5N13zllVc0YcIErV+/XqWlpRoyZIjuuOMOPf744zpy5IimTp2qG2+8UatXr9Z//dd/6e6779aaNWs0dOhQSdLBgwe1fPlyLVu2TJL00Ucf6bbbbtNTTz2lwYMHa/v27Ro/frwkaebMmZ7PffDBBzVv3jw9+uijevrppzV69Gj99NNPSklp3BiExn4OQqzmqHSw7nTP/u+kfVukkq3mYydbbTaunZTa0wwfqT3MUz/tupjTj6PjQ1s/gFaLq1HHxprd4nOyrCn0/j2NPsd/2WWXyeFw6PPPP5ckPfzww/roo4/0/vvve9rs2rVL2dnZKiwsVI8ePXTNNdeoffv2eumllySZvTIPPvigdu7cqYiICA0bNkxDhw7VtGnTPO/x6quv6r777tOePeY0VZvNpunTp2v27NmSpMrKSrVt21bvvfeeRowYofnz52vSpEkqLS31vMfixYt17bXXyv3PqzGf0xCuRh0gLqd56qfka6lki7Rvq7T/W/PUz8mueBzXTkrrI3XoJaX1rt+3SQ1p6QBaF65G3UINHDjQc/vLL7/UmjVr1LZt2xPabd++XT169NDo0aN155136tlnn1VMTIwWLFigm2++WRF100u//PJLrV+/Xn/+8589r3W5XDp69KgOHz6s+Hjz/1GfeeaZnufbtGmjxMRE7dvXiCXXj6m1MZ+DJqp1mYNo3QFl37fm/ufvJFd1w6+JTTJ7VFLPMANKWh9zS8hgMTcAzRYBRjJP49z/C4tiBfOzfdCmTX1vTUVFhUaNGqVHHnnkhHaZmZmSpFGjRskwDC1dulTnnXeePvroIz3++ONe7/Hggw/quuuuO+E9ju3xiIqK8nrOZrN5xtZERETo+I68mpoar/uN/Rw0kmGYq83+XGiGlH1bzZ6V/YUnvxJydFszmKT3Nbe03mZw4YrHAMIQAUYy/+MdhlM1zznnHP373//W6aefrsjIhv+UsbGxuu6667RgwQJt27ZNPXv21DnnnOP1HoWFherevbvfdXTo0EHl5eWqrKz0BKyCgoITam3q57RaVRVS8WZzUO3eL6X935jjVWoqG24fGWeOT+nQW0rrZZ766dDLnJrMwm4AWggCTBjLy8vTCy+8oFtuuUX33XefUlJStG3bNi1cuFAvvvii7HZzqfTRo0frqquu0pYtW/TrX//a6z1mzJihq666Sp06ddINN9ygiIgIffnll/r666/18MMPN6qOQYMGKT4+Xvfff7/+8Ic/aOPGjZo/f37AP6dVOFJqzupxh5W9X5pTlhsapxIRaQ6gTe1R16NS17vS7nSWyQfQ4hFgwlhWVpbWr1+vqVOnavjw4aqqqlLnzp01YsQIzxgXSRoyZIhSUlJUWFioW2+91es9cnNztWTJEj300EN65JFHFBUVpV69eumOO+5odB0pKSl69dVXNWXKFL3wwgsaOnSoZs2a5ZllFKjPaVGcVebpnv11p3/cp4FKf2q4fUKWlHmWuaX3NXtUUrpI9qiG2wNAC8csJMZfNGst5m/l2Cvt+lTaWbft/VJyVTXcNrlTfVjJOEvKGiC1TQtpuQBgFWYhAVYwDPNaP3sL6satfGXuKxuYsRWbVDfjp3f9eJX0flzfBwAagQADNMWRUmn3JmnXZ9Luz8z9kYMntrNFSGl9pezzpI7nS9nnm0vpM/sHAPxCgAF8cWC79NOG+tNB+wt1wgBbe7TZk5J5lpTR39yn9WGVWgAIIAIMcCq1LmnXf6TCZVLhe+aCcMdrd7rU8TxzO+1cKaOfFBkT8lIBoDUhwADHqjliDrDd9R+zh+WnDdLhn+ufj4isPwWUfb55u20H6+oFgFaqVQeYFjoBq0UJ6t+o1mX2qOz+3BzHsudzc8Bt7XFXyI5Nks4YLvW8Quo+zLwPALBUqwww7mXxDx8+rLi4OIurwakcPmxeJfz4Sxn45ajDHLuyY6O08xMzuFRXnNiuTVpd78q59b0trLcCAM1KqwwwdrtdycnJnosRxsfHy8ZskGbFMAwdPnxY+/btU3JysmdVYZ9U7DNPAbm3fVsko9a7TVQbc52VrLOl0waaW3InZgcBQDPXKgOMJGVkZEiST1dURuglJyd7/la/qGK/9ONHUtE66cePpQPfN/CGnaVOOVKnQVL2IHNFW5bdB4Cw02oDjM1mU2ZmptLS0k64cjKah6ioqFP3vBwpNXtWitaZ274txzWwmcvud77QDC2dL5QSGhmGAADNWqsNMG52u92/0xMIvaNl5vgVdy9L8VcnnhJK7yd1ucTcOl0gxbWzplYAQFC1+gCDZuyowwwqP603t+LNJwaW9t2l0wfXh5Y2qdbUCgAIKQIMmpcD26Xv3pe+W26GluOnNLfrInW+qC6wDJYSs6ypEwBgKQIMrOVySjs3St+9JxUuP3HgbfvuUpdLzfErnS8ksAAAJBFgYAVnlfT9Cumbd6XvP5COHKp/LiLS7GHpMULqkSu172ZdnQCAZosAg9BwOaWiD6Wv/y19s0SqKqt/Lq6ddEau1HOE1G0IK90CAH4RAQbBYxjSni+kr94wg0vl/vrnEk+T+l4r9RpprnZr558iAKDx+NVA4JXtlr583Qwux169Ob691Ocaqf8NUvYFUkSEZSUCAMIbAQaBUeuStq2UPntZ+v79+unOkbFmL8uZN0vdLueaQgCAgCDAoGkce6QvXpU+/x+pbGf9450vlgbcIvX+lRSbaF19AIAWiQAD37mc0rYV0qb55iwid29LXDtpwGhp4O1S6hlWVggAaOEIMGi8I6XSpy9In70kle+tf7zzRdI5Y6U+V0tRsZaVBwBoPQgw+GWVB6RPnpU+fV6qcpiPxbeXzrrFDC4delhbHwCg1SHA4OQq9kvrn5A++6dUc9h8rENvafBks7clMsbS8gAArRcBBic6UipteFr65B9STaX5WOZZ0iVTpJ4jmf4MALAcAQb1qiuljc9J65+UjtatlJt1tnTZ/dIZ/59ks1lbHwAAdQgwkGprzUXnVs6SKorNxzr0loZMN9dwIbgAAJoZAkxrt+sz6b37pN2bzPvtTpcuf0Dqd70UYbe0NAAAToYA01pV7JM++G/pq4Xm/ei25hiXCyYwOBcA0OwRYFqjLYulJfdIRw6a9weMlobOlBLSLS0LAIDGIsC0JocPSsumSF//y7yf3k8a9ZTUcaC1dQEA4COf5sPOnTtX5513nhISEpSWlqZrrrlGhYWFXm2OHj2qvLw8tW/fXm3bttX111+vkpISrzY7duzQyJEjFR8fr7S0NE2ZMkVOp9Orzdq1a3XOOecoJiZG3bt31/z58/37hjB994H07AVmeLHZzdNFd64hvAAAwpJPAebDDz9UXl6ePvnkE61YsUI1NTUaPny4KisrPW3uuece/e///q/eeustffjhh9qzZ4+uu+46z/Mul0sjR45UdXW1NmzYoFdeeUXz58/XjBkzPG2Kioo0cuRIXX755SooKNCkSZN0xx136P333w/AV25lnNXS8mnSa/8lVZRIqT2kcSvMGUaR0VZXBwCAX2yGYRj+vnj//v1KS0vThx9+qEsuuURlZWXq0KGDXnvtNd1www2SpG+//Va9e/dWfn6+LrjgAr333nu66qqrtGfPHqWnm2MunnvuOU2dOlX79+9XdHS0pk6dqqVLl+rrr7/2fNbNN9+s0tJSLV++vFG1ORwOJSUlqaysTImJrfRqyAeLpH/9RtrzhXl/0ARp2EwpKs7augAAOInG/n43aUnVsjJzsbOUlBRJ0qZNm1RTU6Nhw4Z52vTq1UudOnVSfn6+JCk/P1/9+/f3hBdJys3NlcPh0JYtWzxtjn0Pdxv3e6ARtiyS/u8lZniJayfdslC64i+EFwBAi+D3IN7a2lpNmjRJF110kfr16ydJKi4uVnR0tJKTk73apqenq7i42NPm2PDift793KnaOBwOHTlyRHFxJ/4IV1VVqaqqynPf4XD4+9XCW22ttOK/pfy/m/ezL5BueElK6mhtXQAABJDfPTB5eXn6+uuvtXDhwkDW47e5c+cqKSnJs2VnZ1tdUug5q6VF4+vDy8WTpduXEl4AAC2OXwFm4sSJWrJkidasWaOOHet/HDMyMlRdXa3S0lKv9iUlJcrIyPC0OX5Wkvv+L7VJTExssPdFkqZNm6aysjLPtnPnTn++WviqKpdeu1Ha/JYUESld+7w53sXOTHkAQMvjU4AxDEMTJ07UokWLtHr1anXp0sXr+YEDByoqKkqrVq3yPFZYWKgdO3YoJydHkpSTk6PNmzdr3759njYrVqxQYmKi+vTp42lz7Hu427jfoyExMTFKTEz02lqNiv3S/KukH9ZIUW2kW9+QzrrJ6qoAAAgan2Yh3XXXXXrttdf0zjvvqGfPnp7Hk5KSPD0jEyZM0LJlyzR//nwlJibq7rvvliRt2LBBkjmNesCAAcrKytK8efNUXFysMWPG6I477tCcOXMkmdOo+/Xrp7y8PP32t7/V6tWr9Yc//EFLly5Vbm5uo2ptNbOQHHuk+SOlgz9I8e2l0W9Jp7G2CwAgPDX699vwgaQGt5dfftnT5siRI8Zdd91ltGvXzoiPjzeuvfZaY+/evV7v8+OPPxpXXHGFERcXZ6Smphr33nuvUVNT49VmzZo1xoABA4zo6Gija9euXp/RGGVlZYYko6yszKfXhZWK/Ybx9LmGMTPRMB7vZxg/b7O6IgAAmqSxv99NWgemOWvxPTBHy6RXRkl7v5QSO0q/fU9K7mR1VQAANElI1oGBRaoPS6/dbIaX+FTptsWEFwBAq0KACTfOaunNMdKODVJMkjRmkZR6htVVAQAQUgSYcGIY0jt50raVUlS8NPpNKfNMq6sCACDkCDDhZONz0uY3zXVebnpV6nSB1RUBAGAJAky4+GmD9MF08/bwh6XuQ62tBwAACxFgwkF5sfTW7VKtU+p3gzTo91ZXBACApQgwzZ2rxgwvFSVSWh/pV09JNpvVVQEAYCkCTHO3Yoa0I1+KSTTHvUS3sboiAAAsR4Bpzr5dJn3yrHn72uek9t2srQcAgGaCANNcHTkkLbnHvH3h3VKvkdbWAwBAM0KAaa7eny5VFEvtz5Aun251NQAANCsEmOZo20qp4FVJNunqZ6SoWKsrAgCgWSHANDdHHdK7/8e8fcEEqdMga+sBAKAZIsA0NytnSY5dUrvTpSGcOgIAoCEEmOak6CPps5fM27/6O1OmAQA4CQJMc1Hrqp91dO44qctga+sBAKAZI8A0F1sXSwe+l+LaScNmWV0NAADNGgGmOTAM6aPHzNuDJkixidbWAwBAM0eAaQ6+e18q+VqKbiudf6fV1QAA0OwRYKxmGNJHfzVvnzdOik+xth4AAMIAAcZqP34s7fqPZI+RLsizuhoAAMICAcZq7t6Xc8ZICenW1gIAQJggwFhp1ybph7VSRKR00f+xuhoAAMIGAcZKH/3N3Pe/UUruZG0tAACEEQKMVUq2SoVLJdmki++xuhoAAMIKAcYqn79i7ntfJXXoYW0tAACEGQKMFWpd0pZF5u0Bv7a2FgAAwhABxgo/fixVlEixyVK3IVZXAwBA2CHAWOHrf5n7Pr+SIqOtrQUAgDBEgAk1Z7W09V3zdr8brK0FAIAwRYAJte2rpaOlUtt06fSLra4GAICwRIAJNffpo77XShF2a2sBACBMEWBCqfqw9O0y8zanjwAA8BsBJpS+Wy7VVJqr7nY81+pqAAAIWwSYUPr63+a+3/WSzWZtLQAAhDECTKgcLZO+X2He5vQRAABNQoAJlW+WSK4qqUMvKb2v1dUAABDWCDChwukjAAAChgATCtWVUtGH5u2+11lbCwAALQABJhT2FEi1TikhU0rtbnU1AACEPQJMKOz+zNwzdRoAgIAgwITCrv+Y+47nWVsHAAAtBAEmFHZtMven0QMDAEAgEGCCrWy3VL5HstmlrAFWVwMAQItAgAk29/iX9D5SdBtrawEAoIUgwAQb418AAAg4Akyw7XLPQCLAAAAQKASYYHLVmGvASAzgBQAggAgwwVSyRXIekWKTpPYsYAcAQKAQYILJPYD3tIFSBIcaAIBA4Vc1mBj/AgBAUBBggokZSAAABAUBJlgOH5QObDNvnzbQ2loAAGhhCDDBsvtzc5/STYpPsbYWAABaGAJMsHAFagAAgoYAEyyMfwEAIGgIMMFgGMfMQKIHBgCAQPM5wKxbt06jRo1SVlaWbDabFi9e7PX87bffLpvN5rWNGDHCq83Bgwc1evRoJSYmKjk5WePGjVNFRYVXm6+++kqDBw9WbGyssrOzNW/ePN+/nVUObJeOlkqRsVJ6P6urAQCgxfE5wFRWVuqss87SM888c9I2I0aM0N69ez3b66+/7vX86NGjtWXLFq1YsUJLlizRunXrNH78eM/zDodDw4cPV+fOnbVp0yY9+uijmjVrlp5//nlfy7WG+/RR5gDJHmVpKQAAtESRvr7giiuu0BVXXHHKNjExMcrIyGjwuW+++UbLly/Xf/7zH517rnl65emnn9aVV16pv/71r8rKytKCBQtUXV2tf/7zn4qOjlbfvn1VUFCgxx57zCvoNFvFm839aedYWwcAAC1UUMbArF27VmlpaerZs6cmTJigAwcOeJ7Lz89XcnKyJ7xI0rBhwxQREaGNGzd62lxyySWKjo72tMnNzVVhYaEOHToUjJIDy7HL3Cd3trYOAABaKJ97YH7JiBEjdN1116lLly7avn277r//fl1xxRXKz8+X3W5XcXGx0tLSvIuIjFRKSoqKi4slScXFxerSpYtXm/T0dM9z7dq1O+Fzq6qqVFVV5bnvcDgC/dUar2y3uU/Msq4GAABasIAHmJtvvtlzu3///jrzzDPVrVs3rV27VkOHDg30x3nMnTtXDz74YNDe3yeOPeY+6TRr6wAAoIUK+jTqrl27KjU1Vdu2mcvqZ2RkaN++fV5tnE6nDh486Bk3k5GRoZKSEq827vsnG1szbdo0lZWVebadO3cG+qs0jsspVZg9SUokwAAAEAxBDzC7du3SgQMHlJmZKUnKyclRaWmpNm3a5GmzevVq1dbWatCgQZ4269atU01NjafNihUr1LNnzwZPH0nmwOHExESvzRIVxZJRK0VESm06WFMDAAAtnM8BpqKiQgUFBSooKJAkFRUVqaCgQDt27FBFRYWmTJmiTz75RD/++KNWrVqlq6++Wt27d1dubq4kqXfv3hoxYoTuvPNOffrpp1q/fr0mTpyom2++WVlZ5piRW2+9VdHR0Ro3bpy2bNmiN954Q08++aQmT54cuG8eLO7TRwlZUoTd2loAAGihfA4wn332mc4++2ydffbZkqTJkyfr7LPP1owZM2S32/XVV1/pV7/6lXr06KFx48Zp4MCB+uijjxQTE+N5jwULFqhXr14aOnSorrzySl188cVea7wkJSXpgw8+UFFRkQYOHKh7771XM2bMCI8p1A4G8AIAEGw2wzAMq4sIBofDoaSkJJWVlYX2dNKGv0sfPCD1vU76r5dD97kAALQAjf395lpIgcYMJAAAgo4AE2ieU0gEGAAAgoUAE2iMgQEAIOgIMIHmPoWU2NHaOgAAaMEIMIHkckrl7kXs6IEBACBYCDCBVLlPMlySzS61Tfvl9gAAwC8EmEByX8QxIZNF7AAACCICTCC5B/AyhRoAgKAiwASSZwAv418AAAgmAkwgsQYMAAAhQYAJJAIMAAAhQYAJJE4hAQAQEgSYQCqjBwYAgFAgwARKrUsq32veZhYSAABBRYAJlIpjF7FLt7oaAABaNAJMoLgH8CZksIgdAABBRoAJFGYgAQAQMgSYQGEGEgAAIUOACZSyXeaeHhgAAIKOABMo9MAAABAyBJhAcQcYplADABB0BJhA8fTAEGAAAAg2Akwg1Lqkck4hAQAQKgSYQKjcL9U6JVuE1DbD6moAAGjxCDCB4F4Dpm2GZI+0thYAAFoBAkwgeC7iyOkjAABCgQATCMxAAgAgpAgwgcBlBAAACCkCTCA4OIUEAEAoEWACgTVgAAAIKQJMIHAKCQCAkCLANFVtreTYa97mFBIAACFBgGmqwwek2hrzdgKL2AEAEAoEmKaqOWzuI2Mle5S1tQAA0EoQYJrKVW3u7THW1gEAQCtCgGkqZ5W5j4y2tg4AAFoRAkxTueoCDD0wAACEDAGmqZx1p5DogQEAIGQIME1FDwwAACFHgGkqemAAAAg5AkxT0QMDAEDIEWCayjMLiQADAECoEGCayr0ODAEGAICQIcA0lfOouecUEgAAIUOAaSoG8QIAEHIEmKZiEC8AACFHgGkqemAAAAg5AkxT0QMDAEDIEWCaimnUAACEHAGmqdzTqO2cQgIAIFQIME1FDwwAACFHgGkqemAAAAg5AkxT0QMDAEDIEWCayjMLiR4YAABChQDTVE6uhQQAQKgRYJqKdWAAAAg5AkxT0QMDAEDI+Rxg1q1bp1GjRikrK0s2m02LFy/2et4wDM2YMUOZmZmKi4vTsGHD9P3333u1OXjwoEaPHq3ExEQlJydr3Lhxqqio8Grz1VdfafDgwYqNjVV2drbmzZvn+7cLBReDeAEACDWfA0xlZaXOOussPfPMMw0+P2/ePD311FN67rnntHHjRrVp00a5ubk6evSop83o0aO1ZcsWrVixQkuWLNG6des0fvx4z/MOh0PDhw9X586dtWnTJj366KOaNWuWnn/+eT++YpA5GcQLAEDIGU0gyVi0aJHnfm1trZGRkWE8+uijnsdKS0uNmJgY4/XXXzcMwzC2bt1qSDL+85//eNq89957hs1mM3bv3m0YhmE8++yzRrt27YyqqipPm6lTpxo9e/ZsdG1lZWWGJKOsrMzfr9c4Tw00jJmJhlH0UXA/BwCAVqCxv98BHQNTVFSk4uJiDRs2zPNYUlKSBg0apPz8fElSfn6+kpOTde6553raDBs2TBEREdq4caOnzSWXXKLo6PpejdzcXBUWFurQoUOBLLnpGMQLAEDIRQbyzYqLiyVJ6enpXo+np6d7nisuLlZaWpp3EZGRSklJ8WrTpUuXE97D/Vy7du1O+OyqqipVVVV57jscjiZ+m0byDOLlFBIAAKHSYmYhzZ07V0lJSZ4tOzs7NB9MDwwAACEX0ACTkZEhSSopKfF6vKSkxPNcRkaG9u3b5/W80+nUwYMHvdo09B7Hfsbxpk2bprKyMs+2c+fOpn+hxqAHBgCAkAtogOnSpYsyMjK0atUqz2MOh0MbN25UTk6OJCknJ0elpaXatGmTp83q1atVW1urQYMGedqsW7dONTU1njYrVqxQz549Gzx9JEkxMTFKTEz02kKCHhgAAELO5wBTUVGhgoICFRQUSDIH7hYUFGjHjh2y2WyaNGmSHn74Yb377rvavHmzbrvtNmVlZemaa66RJPXu3VsjRozQnXfeqU8//VTr16/XxIkTdfPNNysrK0uSdOuttyo6Olrjxo3Tli1b9MYbb+jJJ5/U5MmTA/bFA6K2Vqp1mrdZBwYAgJDxeRDvZ599pssvv9xz3x0qxo4dq/nz5+u+++5TZWWlxo8fr9LSUl188cVavny5YmNjPa9ZsGCBJk6cqKFDhyoiIkLXX3+9nnrqKc/zSUlJ+uCDD5SXl6eBAwcqNTVVM2bM8Forpllw1Q8aZh0YAABCx2YYhmF1EcHgcDiUlJSksrKy4J1OOlIqPdLZvD19H70wAAA0UWN/v1vMLCRLuKrrb9MDAwBAyBBgmuLYywjYbNbWAgBAK0KAaQp3D0xk7KnbAQCAgCLANAUXcgQAwBIEmKZwz0Ji8C4AACFFgGkKemAAALAEAaYpnPTAAABgBQJMU7gH8dIDAwBASBFgmoIeGAAALEGAaQou5AgAgCUIME3hdK8DwykkAABCiQDTFPTAAABgCQJMU9ADAwCAJQgwTUEPDAAAliDANIVnFhI9MAAAhBIBpik868DQAwMAQCgRYJrC0wPD1agBAAglAkxTuBjECwCAFQgwTeFkEC8AAFYgwDSFi0G8AABYgQDTFPTAAABgCQJMU3AxRwAALEGAaQrPNGpOIQEAEEoEmKagBwYAAEsQYJqCHhgAACxBgGkKemAAALAEAaYpuJgjAACWIMA0hZOVeAEAsAIBpinogQEAwBIEmKagBwYAAEsQYJrCxdWoAQCwAgGmKZxMowYAwAoEmKZwMY0aAAArEGD8ZRjHLGRHgAEAIJQIMP5yL2InMYgXAIAQI8D4y3VMgKEHBgCAkCLA+Ms9gFdiEC8AACFGgPGXuwcmIkqK4DACABBK/PL6iws5AgBgGQKMv1ysAQMAgFUIMP6iBwYAAMsQYPxFDwwAAJYhwPiLHhgAACxDgPGXexYSa8AAABByBBh/udeBoQcGAICQI8D4iws5AgBgGQKMv5wM4gUAwCoEGH/RAwMAgGUIMP5yz0KiBwYAgJAjwPiLadQAAFiGAOMvplEDAGAZAoy/PNOoOYUEAECoEWD8RQ8MAACWIcD4ix4YAAAsQ4DxFz0wAABYhgDjL88sJHpgAAAINQKMv1zulXjpgQEAINQCHmBmzZolm83mtfXq1cvz/NGjR5WXl6f27durbdu2uv7661VSUuL1Hjt27NDIkSMVHx+vtLQ0TZkyRU6nM9ClNg3rwAAAYJnIYLxp3759tXLlyvoPiaz/mHvuuUdLly7VW2+9paSkJE2cOFHXXXed1q9fL0lyuVwaOXKkMjIytGHDBu3du1e33XaboqKiNGfOnGCU6x8XV6MGAMAqQQkwkZGRysjIOOHxsrIyvfTSS3rttdc0ZMgQSdLLL7+s3r1765NPPtEFF1ygDz74QFu3btXKlSuVnp6uAQMGaPbs2Zo6dapmzZql6OhmMubEySBeAACsEpQxMN9//72ysrLUtWtXjR49Wjt27JAkbdq0STU1NRo2bJinba9evdSpUyfl5+dLkvLz89W/f3+lp6d72uTm5srhcGjLli0n/cyqqio5HA6vLahcTKMGAMAqAQ8wgwYN0vz587V8+XL94x//UFFRkQYPHqzy8nIVFxcrOjpaycnJXq9JT09XcXGxJKm4uNgrvLifdz93MnPnzlVSUpJny87ODuwXOx49MAAAWCbgp5CuuOIKz+0zzzxTgwYNUufOnfXmm28qLi4u0B/nMW3aNE2ePNlz3+FwBDfEuBjECwCAVYI+jTo5OVk9evTQtm3blJGRoerqapWWlnq1KSkp8YyZycjIOGFWkvt+Q+Nq3GJiYpSYmOi1BZV7JV47p5AAAAi1oAeYiooKbd++XZmZmRo4cKCioqK0atUqz/OFhYXasWOHcnJyJEk5OTnavHmz9u3b52mzYsUKJSYmqk+fPsEut/GcR809PTAAAIRcwE8h/fGPf9SoUaPUuXNn7dmzRzNnzpTdbtctt9yipKQkjRs3TpMnT1ZKSooSExN19913KycnRxdccIEkafjw4erTp4/GjBmjefPmqbi4WNOnT1deXp5iYppRWHDRAwMAgFUCHmB27dqlW265RQcOHFCHDh108cUX65NPPlGHDh0kSY8//rgiIiJ0/fXXq6qqSrm5uXr22Wc9r7fb7VqyZIkmTJignJwctWnTRmPHjtVDDz0U6FKbhoXsAACwjM0wDMPqIoLB4XAoKSlJZWVlwRkPMzdbqnJIEzdJqd0D//4AALRCjf395lpI/uJijgAAWIYA4w/DqJ9GzTowAACEHAHGH66a+tv0wAAAEHIEGH+4e18kemAAALAAAcYf7kXsJGYhAQBgAQKMP9w9MBGRUoTd2loAAGiFCDD+4EKOAABYigDjD/cqvAzgBQDAEgQYf9ADAwCApQgw/qAHBgAASxFg/EEPDAAAliLA+MN51NwzhRoAAEsQYPzhPoVk5xQSAABWIMD4w3MhR3pgAACwAgHGH/TAAABgKQKMP+iBAQDAUgQYf7gvJUAPDAAAliDA+MN9MUd6YAAAsAQBxh/uHpjIWGvrAACglSLA+MPJIF4AAKxEgPGHi0G8AABYiQDjDyeDeAEAsBIBxh8uBvECAGAlAow/uJgjAACWIsD4w9MDwykkAACsQIDxh/tq1PTAAABgCQKMP5z0wAAAYCUCjD9cjIEBAMBKBBh/cDFHAAAsRYDxh4uVeAEAsBIBxh/0wAAAYCkCjD/ogQEAwFIEGH84uRo1AABWIsD4g4XsAACwFAHGH1xKAAAASxFg/OFiEC8AAFYiwPjDySBeAACsRIDxBz0wAABYigDjK5dTMmrN2/TAAABgCQKMr9y9LxI9MAAAWIQA4yvnMQGGWUgAAFiCAOMrd4CxRUj2SGtrAQCglSLA+MrFGjAAAFiNAOMrJ6vwAgBgNQKMr+iBAQDAcgQYX3l6YAgwAABYhQDjKxaxAwDAcgQYX3EhRwAALEeA8ZWLQbwAAFiNAOMremAAALAcAcZX9MAAAGA5Aoyv6IEBAMByBBhfMQsJAADLEWB85V4Hxs4pJAAArEKA8RU9MAAAWI4A4yvPGBh6YAAAsAoBxldOemAAALBasw4wzzzzjE4//XTFxsZq0KBB+vTTT60u6ZiLOdIDAwCAVZptgHnjjTc0efJkzZw5U59//rnOOuss5ebmat++fdYWxsUcAQCwXLMNMI899pjuvPNO/eY3v1GfPn303HPPKT4+Xv/85z+tLczFOjAAAFgt0uoCGlJdXa1NmzZp2rRpnsciIiI0bNgw5efnN/iaqqoqVVVVee47HI7gFHdcD0z50Rr97YPvgvNZQIAYhmF1CSETrt+0uf2JDIuPpNXHw+o/h9Xfv7FuPi9bZ2UnW/LZzTLA/Pzzz3K5XEpPT/d6PD09Xd9++22Dr5k7d64efPDB4Bd33DTqIzUuzd/wY/A/FwCAZianW3sCTFNNmzZNkydP9tx3OBzKzs4O/Af1ukpK7ixlnSNJio+OVN7l3QL/Ob/AJlvIP7O1snGovbTowxGGf+zmWHEoD6PV/y1sbv9kQl1Or4yEEH9ivWYZYFJTU2W321VSUuL1eElJiTIyMhp8TUxMjGJiQjAupd915lanbUykpuT2Cv7nAgAAj2Y5iDc6OloDBw7UqlWrPI/V1tZq1apVysnJsbAyAADQHDTLHhhJmjx5ssaOHatzzz1X559/vp544glVVlbqN7/5jdWlAQAAizXbAHPTTTdp//79mjFjhoqLizVgwAAtX778hIG9AACg9bEZLXR+pcPhUFJSksrKypSYmGh1OQAAoBEa+/vdLMfAAAAAnAoBBgAAhB0CDAAACDsEGAAAEHYIMAAAIOwQYAAAQNghwAAAgLBDgAEAAGGHAAMAAMJOs72UQFO5Fxh2OBwWVwIAABrL/bv9SxcKaLEBpry8XJKUnZ1tcSUAAMBX5eXlSkpKOunzLfZaSLW1tdqzZ48SEhJks9kC9r4Oh0PZ2dnauXMn11gKMo51aHCcQ4PjHBoc59AI5nE2DEPl5eXKyspSRMTJR7q02B6YiIgIdezYMWjvn5iYyP84QoRjHRoc59DgOIcGxzk0gnWcT9Xz4sYgXgAAEHYIMAAAIOwQYHwUExOjmTNnKiYmxupSWjyOdWhwnEOD4xwaHOfQaA7HucUO4gUAAC0XPTAAACDsEGAAAEDYIcAAAICwQ4ABAABhhwDTgGeeeUann366YmNjNWjQIH366aenbP/WW2+pV69eio2NVf/+/bVs2bIQVRr+fDnWL7zwggYPHqx27dqpXbt2GjZs2C/+bWDy9d+028KFC2Wz2XTNNdcEt8AWwtfjXFpaqry8PGVmZiomJkY9evTgvx+N4OtxfuKJJ9SzZ0/FxcUpOztb99xzj44ePRqiasPTunXrNGrUKGVlZclms2nx4sW/+Jq1a9fqnHPOUUxMjLp376758+cHt0gDXhYuXGhER0cb//znP40tW7YYd955p5GcnGyUlJQ02H79+vWG3W435s2bZ2zdutWYPn26ERUVZWzevDnElYcfX4/1rbfeajzzzDPGF198YXzzzTfG7bffbiQlJRm7du0KceXhxdfj7FZUVGScdtppxuDBg42rr746NMWGMV+Pc1VVlXHuuecaV155pfHxxx8bRUVFxtq1a42CgoIQVx5efD3OCxYsMGJiYowFCxYYRUVFxvvvv29kZmYa99xzT4grDy/Lli0zHnjgAePtt982JBmLFi06ZfsffvjBiI+PNyZPnmxs3brVePrppw273W4sX748aDUSYI5z/vnnG3l5eZ77LpfLyMrKMubOndtg+xtvvNEYOXKk12ODBg0yfve73wW1zpbA12N9PKfTaSQkJBivvPJKsEpsEfw5zk6n07jwwguNF1980Rg7diwBphF8Pc7/+Mc/jK5duxrV1dWhKrFF8PU45+XlGUOGDPF6bPLkycZFF10U1DpbksYEmPvuu8/o27ev12M33XSTkZubG7S6OIV0jOrqam3atEnDhg3zPBYREaFhw4YpPz+/wdfk5+d7tZek3Nzck7aHyZ9jfbzDhw+rpqZGKSkpwSoz7Pl7nB966CGlpaVp3LhxoSgz7PlznN99913l5OQoLy9P6enp6tevn+bMmSOXyxWqssOOP8f5wgsv1KZNmzynmX744QctW7ZMV155ZUhqbi2s+C1ssRdz9MfPP/8sl8ul9PR0r8fT09P17bffNvia4uLiBtsXFxcHrc6WwJ9jfbypU6cqKyvrhP/RoJ4/x/njjz/WSy+9pIKCghBU2DL4c5x/+OEHrV69WqNHj9ayZcu0bds23XXXXaqpqdHMmTNDUXbY8ec433rrrfr555918cUXyzAMOZ1O/f73v9f9998fipJbjZP9FjocDh05ckRxcXEB/0x6YBCW/vKXv2jhwoVatGiRYmNjrS6nxSgvL9eYMWP0wgsvKDU11epyWrTa2lqlpaXp+eef18CBA3XTTTfpgQce0HPPPWd1aS3K2rVrNWfOHD377LP6/PPP9fbbb2vp0qWaPXu21aWhieiBOUZqaqrsdrtKSkq8Hi8pKVFGRkaDr8nIyPCpPUz+HGu3v/71r/rLX/6ilStX6swzzwxmmWHP1+O8fft2/fjjjxo1apTnsdraWklSZGSkCgsL1a1bt+AWHYb8+fecmZmpqKgo2e12z2O9e/dWcXGxqqurFR0dHdSaw5E/x/m///u/NWbMGN1xxx2SpP79+6uyslLjx4/XAw88oIgI/n98IJzstzAxMTEovS8SPTBeoqOjNXDgQK1atcrzWG1trVatWqWcnJwGX5OTk+PVXpJWrFhx0vYw+XOsJWnevHmaPXu2li9frnPPPTcUpYY1X49zr169tHnzZhUUFHi2X/3qV7r88stVUFCg7OzsUJYfNvz593zRRRdp27ZtnoAoSd99950yMzMJLyfhz3E+fPjwCSHFHRoNLgUYMJb8FgZteHCYWrhwoRETE2PMnz/f2Lp1qzF+/HgjOTnZKC4uNgzDMMaMGWP86U9/8rRfv369ERkZafz1r381vvnmG2PmzJlMo24kX4/1X/7yFyM6Otr417/+Zezdu9ezlZeXW/UVwoKvx/l4zEJqHF+P844dO4yEhARj4sSJRmFhobFkyRIjLS3NePjhh636CmHB1+M8c+ZMIyEhwXj99deNH374wfjggw+Mbt26GTfeeKNVXyEslJeXG1988YXxxRdfGJKMxx57zPjiiy+Mn376yTAMw/jTn/5kjBkzxtPePY16ypQpxjfffGM888wzTKO2wtNPP2106tTJiI6ONs4//3zjk08+8Tx36aWXGmPHjvVq/+abbxo9evQwoqOjjb59+xpLly4NccXhy5dj3blzZ0PSCdvMmTNDX3iY8fXf9LEIMI3n63HesGGDMWjQICMmJsbo2rWr8ec//9lwOp0hrjr8+HKca2pqjFmzZhndunUzYmNjjezsbOOuu+4yDh06FPrCw8iaNWsa/O+t+9iOHTvWuPTSS094zYABA4zo6Gija9euxssvvxzUGm2GQR8aAAAIL4yBAQAAYYcAAwAAwg4BBgAAhB0CDAAACDsEGAAAEHYIMAAAIOwQYAAAQNghwAAAgLBDgAEAAGGHAAMAAMIOAQYAAIQdAgwAAAg7/w8Xf93bfixJxgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(threshold, default, label = 'default')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "TSV9dmVsZ9uS",
        "outputId": "28867a6b-07e3-48c1-d9a9-bb759d0f36a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCBUlEQVR4nO3deVxVdeLG8edyEVARRFEWRRHcTUXZUjObYsS2X5aVWqNm+zK20KYtUmON5jjllE6OTaU1ubZNmUMLZauJ4pr7DoqAaOyy3Xt+f5AUpeZF4Nx7+bxfr/tKDuccn3uEe5/OPd/vsRiGYQgAAMCJeZgdAAAA4PdQWAAAgNOjsAAAAKdHYQEAAE6PwgIAAJwehQUAADg9CgsAAHB6FBYAAOD0PM0OUB/sdruysrLUqlUrWSwWs+MAAICzYBiGioqKFBoaKg+PM59DcYvCkpWVpbCwMLNjAACAOsjMzFTHjh3PuI5bFJZWrVpJqn7Cfn5+JqcBAABno7CwUGFhYTXv42fiFoXl5MdAfn5+FBYAAFzM2VzOwUW3AADA6VFYAACA06OwAAAAp0dhAQAATo/CAgAAnB6FBQAAOD0KCwAAcHoUFgAA4PQoLAAAwOlRWAAAgNOjsAAAAKdHYQEAAE7PLW5+CAAA6l9pRZU2ZuRr7YEfVXCiUlOv7G1aFgoLAACosf1Iod5OP6R1B47rh6xC2eyGJMnL6qFHRvSQTzOrKbkoLAAAQNkFZfr7Jzv19vpDMoyfl4f4+yg2vI1iwwNk/+U3GhmFBQCAJqy4vEr/+nKvXvl6n8oq7ZKkS88LVmKfYMV2aaMOrZubnLAahQUAgCbqf1uO6Mn/blVecbkkKTY8QI9d1ksDOgWYnOy3KCwAADQxx4rLNfWDrfpo8xFJUnjbFpp8aS8l9gmSxWIxOd2p1WlY89y5cxUeHi4fHx/Fx8crLS3ttOu+8sorGjp0qAICAhQQEKCEhITfrH/TTTfJYrHUeowYMaIu0QAAwBms3HJEw1/4Sh9tPiKrh0WTLu6qjx+4UCPOC3basiLVobAsXbpUSUlJSk5O1vr169W/f38lJiYqNzf3lOuvWrVKY8eO1RdffKHVq1crLCxMw4cP1+HDh2utN2LECB05cqTmsXjx4ro9IwAA8Bsl5VW6d/EG3f3Weh0rqVDP4Fb67z1D9ODwHvL2NGfkjyMshuHYJb/x8fGKjY3VnDlzJEl2u11hYWGaNGmSJk+e/Lvb22w2BQQEaM6cORo/fryk6jMs+fn5ev/99x1/BpIKCwvl7++vgoIC+fn51WkfAAC4q31Hi3XHm+nanVssq4dF91wUqT9f3E1enubOH+vI+7dDSSsqKpSenq6EhISfd+DhoYSEBK1evfqs9lFaWqrKykq1adOm1vJVq1apffv26tGjh+666y4dO3bstPsoLy9XYWFhrQcAAPitT7Zm66o532p3brHat/LWsjvOV9LwHqaXFUc5lDYvL082m01BQUG1lgcFBSk7O/us9vHoo48qNDS0VukZMWKE3njjDaWmpuq5557Tl19+qUsvvVQ2m+2U+5g+fbr8/f1rHmFhYY48DQAA3J7NbmjWxzt1+5vpKiqvUlx4G6249wJFd27z+xs7oUYdJTRjxgwtWbJEq1atko+PT83yMWPG1Py5b9++6tevnyIjI7Vq1Spdcsklv9nPlClTlJSUVPN1YWEhpQUAgJ8UlVXq3sUb9MXOo5Kkm4d00ZTLeqqZ1bXOqvySQ4UlMDBQVqtVOTk5tZbn5OQoODj4jNvOmjVLM2bM0GeffaZ+/fqdcd2IiAgFBgZqz549pyws3t7e8vb2diQ6AABNQsaxUt2ycK125xbL29NDM6/tp6uiOpgd65w5VLW8vLwUHR2t1NTUmmV2u12pqakaNGjQabebOXOmpk2bppSUFMXExPzu33Po0CEdO3ZMISEhjsQDAKBJ+37fMV019xvtzi1WkJ+3lt85yC3KilSHj4SSkpI0YcIExcTEKC4uTrNnz1ZJSYkmTpwoSRo/frw6dOig6dOnS5Kee+45TZ06VYsWLVJ4eHjNtS6+vr7y9fVVcXGxnn76aY0aNUrBwcHau3evHnnkEXXt2lWJiYn1+FQBAHBfS9Iy9MT7P6jKbqh/R3/NHx+jID+f39/QRThcWEaPHq2jR49q6tSpys7OVlRUlFJSUmouxM3IyJCHx88nbl5++WVVVFTo2muvrbWf5ORkPfXUU7Jardq8ebMWLlyo/Px8hYaGavjw4Zo2bRof+wAA8DsMw9BLn+/R85/ukiRd2T9Uf7u2n2l3VW4oDs/D4oyYhwUA0BTZ7YaeXbldr36zX5J07yXd9EBCN6eesfaXHHn/5l5CAAC4oCqbXZPf3aK30w9JkpKv7K2JQ7qYnKrhUFgAAHAxZZU23bdkgz7emiOrh0UzR/XTqOiOZsdqUBQWAABcSFmlTbe9sU5f786Tl9VDc24YoOF9zjy1iDugsAAA4CJKK6p068J1+m7vMbXwsurf42M0uGug2bEaBYUFAAAXUFJepYkL1ipt/3G19LJqwc1xig13zWn264LCAgCAkysur9JNr6Vp3cEf1crbUwtujlN05wCzYzUqCgsAAE6ssKxSN72WpvUZ+Wrl46k3b4lXVFhrs2M1OgoLAABOqrCsUuNfTdPGzHz5N2+m/9wSr74d/c2OZQoKCwAATqjgRKXGv5amTZn5at2iuqyc16FplhWJwgIAgNP5dVl569Z49QltumVForAAAOBUCk5Uavyra7TpUIECWjTTW7eer96h3HbG4/dXAQAAjaGkvKr6zApl5Tc4wwIAgBOoqLLrzv+k13wMtOi289UrhLJyEmdYAAAwmd1u6JG3N+nr3Xlq3syq12+Kpaz8CoUFAAATGYahZ1du1/sbs+TpYdHLfxqoAZ2a1qRwZ4PCAgCAif711T69+s1+SdLfruuni3q0NzmRc6KwAABgkuXrMjXjfzskSU9c3ktXD+hociLnRWEBAMAEH2/N1qPvbJYk3X5hhG4dGmFyIudGYQEAoJF9tzdPkxZtkN2QrovuqCmX9jQ7ktOjsAAA0Ig2H8rXbQvXqcJm1/DeQZp+TV9ZLBazYzk9CgsAAI1kT26xbnp9rUoqbBoc2VYvjh0gTytvxWeDowQAQCM4UnBC419do+MlFerX0V/zx8fIp5nV7Fgug8ICAEADKzhRqZteW6usgjJFtGupBRPj5OvNZPOOoLAAANCAyqtsuuPNddqZU6T2rbz1xs1xatPSy+xYLofCAgBAA7HbDT20fLO+33dcvt6een1irDoGtDA7lkuisAAA0ECm/2+7Ptz085T7fUL9zY7ksigsAAA0gNe/3a9Xvq6ecn/mtf00tFs7kxO5NgoLAAD17LNtOfrLim2SpEdG9NA1A5ly/1xRWAAAqEdbswp075INMgxpbFyY7hoWaXYkt0BhAQCgnuQUlunWhetUWmHTkK5t9ZerzmMW23pCYQEAoB6UVlTp1oXrdKSgTJHtWuqfN0arGbPY1huOJAAA58huN/TA0o3acrhAbVp66fWb4uTfvJnZsdwKhQUAgHP0t0926uOtOfKyemj+uGh1astcK/WNwgIAwDl4d/0hvbxqr6Tq4csx4W1MTuSeKCwAANRR+sEfNfmdLZKke/4QqZEDOpicyH1RWAAAqIPD+Sd0x5vrVGGza3jvID34xx5mR3JrFBYAABxUUl49IiivuEK9Qvz0wugoeXgwfLkhUVgAAHCA3W4oadlGbT9SqEBfL70yPlotvT3NjuX2KCwAADhg5sc/jwj617ho7r7cSCgsAACcpWXrMjXvy59HBEV3ZkRQY6GwAABwFlbvPabH3q0eEXTvxV0ZEdTIKCwAAPyO/XkluvM/6aqyG7qiX4ge+GN3syM1ORQWAADOIL+0QjcvWKuCE5Ua0Km1Zl3XnxsamoDCAgDAaVTa7Lr7rfXan1eiDq2ba/64GPk0s5odq0misAAAcBp/+XCbvtt7TC29rHr1phi1a+VtdqQmi8ICAMApvLn6gN78/qAsFukfYwaoZ7Cf2ZGaNAoLAAC/8u2ePD314TZJ0qMjeiqhd5DJiUBhAQDgF/bnlejut9bLZjd0zcAOuuPCCLMjQRQWAABqFJZV6taF1SOCBnZqrb9e3ZcRQU6CwgIAgCSb3dD9SzZq79EShfr7aN64aEYEOREKCwAAkp7/dKc+35Erb08P/WtcjNq38jE7En6BwgIAaPI+2nxEc7+ovkfQc6P6qW9Hf5MT4dcoLACAJm37kUI9tHyTJOm2oV24R5CTorAAAJqsH0sqdPub63Si0qah3QL16IieZkfCaVBYAABNUpXNrj8vXq/M4yfUqU0LvTR2gDytvC06qzr9y8ydO1fh4eHy8fFRfHy80tLSTrvuK6+8oqFDhyogIEABAQFKSEj4zfqGYWjq1KkKCQlR8+bNlZCQoN27d9clGgAAZ+W5lB36ds8xtfCyav74aLVu4WV2JJyBw4Vl6dKlSkpKUnJystavX6/+/fsrMTFRubm5p1x/1apVGjt2rL744gutXr1aYWFhGj58uA4fPlyzzsyZM/Xiiy9q3rx5WrNmjVq2bKnExESVlZXV/ZkBAHAa/914WK98vV+SNOu6/ky77wIshmEYjmwQHx+v2NhYzZkzR5Jkt9sVFhamSZMmafLkyb+7vc1mU0BAgObMmaPx48fLMAyFhobqwQcf1EMPPSRJKigoUFBQkBYsWKAxY8b87j4LCwvl7++vgoIC+fnxQwcAOL2tWQUa9fJ3Kqu06+6LIvUI162YxpH3b4fOsFRUVCg9PV0JCQk/78DDQwkJCVq9evVZ7aO0tFSVlZVq06aNJGn//v3Kzs6utU9/f3/Fx8efdp/l5eUqLCys9QAA4PccL6nQ7W+kq6zSrot6tNODw3uYHQlnyaHCkpeXJ5vNpqCg2jeBCgoKUnZ29lnt49FHH1VoaGhNQTm5nSP7nD59uvz9/WseYWFhjjwNAEATVGWz68+L1utw/gl1bttC/xg9QFYPpt13FY16OfSMGTO0ZMkSvffee/LxqfsMglOmTFFBQUHNIzMzsx5TAgDc0cyPd+q7vT9dZDsuRv4tmpkdCQ7wdGTlwMBAWa1W5eTk1Fqek5Oj4ODgM247a9YszZgxQ5999pn69etXs/zkdjk5OQoJCam1z6ioqFPuy9vbW97e3o5EBwA0YR9tPqL5X+2TVH2RbY/gViYngqMcOsPi5eWl6Ohopaam1iyz2+1KTU3VoEGDTrvdzJkzNW3aNKWkpCgmJqbW97p06aLg4OBa+ywsLNSaNWvOuE8AAM7GrpwiPfx29Uy2dwyL0GV9Q35nCzgjh86wSFJSUpImTJigmJgYxcXFafbs2SopKdHEiRMlSePHj1eHDh00ffp0SdJzzz2nqVOnatGiRQoPD6+5LsXX11e+vr6yWCy6//779cwzz6hbt27q0qWLnnzySYWGhmrkyJH190wBAE1OYVml7nwzXaUVNg2ObKuHucjWZTlcWEaPHq2jR49q6tSpys7OVlRUlFJSUmoums3IyJCHx88nbl5++WVVVFTo2muvrbWf5ORkPfXUU5KkRx55RCUlJbr99tuVn5+vCy64QCkpKed0nQsAoGmz2w09uGyT9uWVKNTfh5lsXZzD87A4I+ZhAQD82pzPd2vWJ7vk5emht+8cpH4dW5sdCb/SYPOwAADgCj7emq2/f7pLkjTtqj6UFTdAYQEAuJWtWQW6f8lGGYY07vzOGh3byexIqAcUFgCA28gtKtOtC9fpRKVNQ7sFKvnK3mZHQj2hsAAA3EJZpU23vZGuIwVlimjXUnNuGMhFtm6Ef0kAgMszDEMPv71ZmzLz1bpFM702IVb+zZnJ1p1QWAAALu/F1D36cFOWPD0sevnGaIUHtjQ7EuoZhQUA4NI+2nxEL3xWPSLomZHnaVBkW5MToSFQWAAALmvLoQI9uHyjJOnmIV00Jo4RQe6KwgIAcEm5hWW67Y11Kqu066Ie7fTYZT3NjoQGRGEBALic6hFB65RdWKau7X31ItPuuz3+dQEALsUwDD3y9mZtOlSg1i2a6dUJMfLzYUSQu6OwAABcyj9X7dUHvxgR1LktI4KaAgoLAMBlpG7P0axPdkqSnr6qDyOCmhAKCwDAJezJLdJ9P90j6E/nd9KN8Z3NjoRGRGEBADi9gtJK3fZGuorLqxTXpY2mXtHH7EhoZBQWAIBTs9kNTVqyQfvzStShdXP988aB8vLk7aup4V8cAODUZqbs0Fe7jsqnmYfmj49WoK+32ZFgAgoLAMBpfbgpS//6ap8kadZ1/dUn1N/kRDALhQUA4JS2HynUI29vliTddVGkrugXanIimInCAgBwOvmlFbrjzXSdqLRpaLdAPTS8h9mRYDIKCwDAqdjshu5dslEZx0sV1qa5Xho7QFYPi9mxYDIKCwDAqfz9k536atdRNW9m1fxxMWrdwsvsSHACFBYAgNNYsTlL/1y1V5L03LX91CvEz+REcBYUFgCAU/jhcIEeWr5JknT7hRH6v/5cZIufUVgAAKbLLSrTbW+sU1mlXRf1aKdHR/Q0OxKcDIUFAGCqskqb7ngzXUcKyhTZrqVe5CJbnAKFBQBgGsMw9Ni7W7QhI1/+zZvp3xNi5efTzOxYcEIUFgCAaeZ/tU/vbjgsq4dFc28YqC6BLc2OBCdFYQEAmGLVzlzNSNkhSXry8l66oFugyYngzCgsAIBGt+9osSYt3iDDkMbEhmnC4HCzI8HJUVgAAI2qqKxSt72xTkVlVYruHKCnr+oji4WLbHFmFBYAQKOx2w09sHSj9h4tUbCfj17+00B5e1rNjgUXQGEBADSaFz7bpc+258rL00Pzx0erfSsfsyPBRVBYAACN4qPNR/TS53skSTOu6at+HVubGwguhcICAGhwPxwu0IPLN0qSbr2gi64Z2NHcQHA5FBYAQIP65bT7w7q305TLepkdCS6IwgIAaDC/nnb/pRuYdh91Q2EBADSIX0+7/yrT7uMcUFgAAA3iX7+Ydv+fNw5UONPu4xxQWAAA9e7zHTl67qdp95+6sreGdGXafZwbCgsAoF7tyS3WfYs3yjCkG+M7adygcLMjwQ1QWAAA9abgRKVuf2OdisqrFBfeRslX9jE7EtwEhQUAUC9sdkP3LdmgfXklCvX30T//NFBenrzNoH7wkwQAqBd/+3inVu08Kp9mHpo/PkaBvt5mR4IbobAAAM7Zfzce1rwv90qSnhvVT+d18Dc5EdwNhQUAcE7SD/6oh9/eLEm6c1ikrorqYHIiuCMKCwCgzjKPl+r2N9aposquhF5Bejixh9mR4KYoLACAOik4UamJC9bqWEmF+oT66R9joph2Hw2GwgIAcFilza573lqvPbnFCvbz0asTYtXS29PsWHBjFBYAgEMMw9DU//6gb/bkqYWXVa/eFKNgfx+zY8HNUVgAAA559Zv9WpyWKQ+L9NLYAeoTyoggNDwKCwDgrH29+6j+unK7JOmxy3rpkl5BJidCU0FhAQCclQN5Jfrzog2yG9K10R11ywVdzI6EJoTCAgD4XUVllbr1jXUqOFGpAZ1a69mrz5PFwoggNB4KCwDgjOx2Qw8s3ag9ucUK8vPWv/4ULW9Pq9mx0MRQWAAAZ/T3T3fqs+258vL00PxxMWrvx4ggNL46FZa5c+cqPDxcPj4+io+PV1pa2mnX3bp1q0aNGqXw8HBZLBbNnj37N+s89dRTslgstR49e/asSzQAQD16O/2Q5n5x8h5BfdU/rLW5gdBkOVxYli5dqqSkJCUnJ2v9+vXq37+/EhMTlZube8r1S0tLFRERoRkzZig4OPi0++3Tp4+OHDlS8/jmm28cjQYAqEff7c3TlHer7xF010WRunpAR5MToSlzuLA8//zzuu222zRx4kT17t1b8+bNU4sWLfTaa6+dcv3Y2Fj97W9/05gxY+TtffpbjXt6eio4OLjmERgY6Gg0AEA92ZNbpDvfTFelzdAV/UL08HDuEQRzOVRYKioqlJ6eroSEhJ934OGhhIQErV69+pyC7N69W6GhoYqIiNCNN96ojIyM065bXl6uwsLCWg8AQP3IKy7XxAVrVVhWpejOAZp1XX95cI8gmMyhwpKXlyebzaagoNoTBQUFBSk7O7vOIeLj47VgwQKlpKTo5Zdf1v79+zV06FAVFRWdcv3p06fL39+/5hEWFlbnvxsA8LOySptuXbhOmcdPqFObFpo/Llo+zRgRBPM5xSihSy+9VNddd5369eunxMRErVy5Uvn5+Vq2bNkp158yZYoKCgpqHpmZmY2cGADcT5XNrj8v2qCNmfnyb95Mr0+MVVvf03+UDzQmh26tGRgYKKvVqpycnFrLc3JyznhBraNat26t7t27a8+ePaf8vre39xmvhwEAOMZuN/ToO1v02facn4YvRyuyna/ZsYAaDp1h8fLyUnR0tFJTU2uW2e12paamatCgQfUWqri4WHv37lVISEi97RMAcGqGYeivK7frnfWHZPWwaM7YAYqPaGt2LKAWh86wSFJSUpImTJigmJgYxcXFafbs2SopKdHEiRMlSePHj1eHDh00ffp0SdUX6m7btq3mz4cPH9bGjRvl6+urrl27SpIeeughXXnllercubOysrKUnJwsq9WqsWPH1tfzBACcxstf7tW/v9kvSXpuVD8N71N/Z8yB+uJwYRk9erSOHj2qqVOnKjs7W1FRUUpJSam5EDcjI0MeHj+fuMnKytKAAQNqvp41a5ZmzZqlYcOGadWqVZKkQ4cOaezYsTp27JjatWunCy64QN9//73atWt3jk8PAHAmi9MyNDNlpyTpict76dpo5lqBc7IYhmGYHeJcFRYWyt/fXwUFBfLz8zM7DgC4hJQfjujut9bLbkj3/CFSDycywzgalyPv304xSggA0LhW7z2mexdvlN2QxsaF6SEmhoOTo7AAQBOzNatAt7+xThU2uxL7BOmZkX1lsTAxHJwbhQUAmpCMY6W66fW1KiqvUlyXNvrHmAGyMostXACFBQCaiLzico1/bY2OFpWrZ3ArvTI+hlls4TIoLADQBBSXV2ni62t14FipOgY018Kb4+TfvJnZsYCzRmEBADdXUWXXXf9J15bDBWrT0ktv3BynID8fs2MBDqGwAIAbq55yf7O+3p2n5s2seu2mWEUw5T5cEIUFANzYcx/v0HsbDsvTw6KX/zRQUWGtzY4E1AmFBQDc1Kvf7Ne/vtwnqXrK/Yt6tDc5EVB3FBYAcEPL12Vq2orq+7g9OqKnRjHlPlwchQUA3MyytZl65J3NkqSJQ8J157AIkxMB587hmx8CAJzX0rUZevSdLZKkmwaHa+oVvZnFFm6BMywA4CYWp9UuK8lXUlbgPjjDAgBuYHFahqa8W11WJg7hzArcD4UFAFzc/7Yc0WPvVZeVWy7ooicu70VZgdvhIyEAcGFp+4/rvqUbZRjSjfGdKCtwWxQWAHBRu3OKdOvCtaqosmt47yD95arzKCtwWxQWAHBB2QVlmvBamgrLqhTdOUAvjh0gqwdlBe6LwgIALqawrFI3vZ6mrIIyRbRrqX+Pj5FPM6vZsYAGRWEBABdSXF6lia+v1Y7sIrVr5a2FE+MU0NLL7FhAg6OwAICLKCmv0sTX05R+8Ef5+XhqwcRYhbVpYXYsoFFQWADABZRWVOnmBWu19sCPauXjqf/cGq8+of5mxwIaDYUFAJzciQqbbl24Tmv2H5evt6feuDlO/Tq2NjsW0KgoLADgxEorqnT7m+v03d5jaull1cKbYzWgU4DZsYBGx0y3AOCkjhWX6+YFa7XpUIFaeFm14OY4RXduY3YswBQUFgBwQgePlWjCa2k6cKxUrVs006sTYigraNIoLADgZDYfytfNC9Yqr7hCHVo31xu3xCmyna/ZsQBTUVgAwIl8ueuo7vpPukorbOod4qcFE2PV3s/H7FiA6SgsAOAk3k4/pMnvbFaV3dAFXQP18p8GqpVPM7NjAU6BwgIAJjMMQ/9ctVd/+3inJGlkVKhmXttfXp4M5AROorAAgIlsdkNPfbBVb35/UJJ0x7AIPZrYUx7cyBCohcICACYpq7Tp/iUblbI1WxaLNPWK3po4pIvZsQCnRGEBABMUnKjUbW+sU9r+4/KyeuiF0VG6vF+I2bEAp0VhAYBGlltYpvGvpWlHdpFaeXvqlQkxOj+irdmxAKdGYQGARrQ/r0TjXl2jQz+eULtW3lo4MU69Q/3MjgU4PQoLADSSzYfyNfH1tTpWUqHwti30xs3x6tS2hdmxAJdAYQGARvDFjlzds2i9Sits6tvBX69PjFWgr7fZsQCXQWEBgAb2n+8Paup/f5DdkC7oGqh546Ll683LL+AIfmMAoIHY7YZmfrxT877cK0m6Nrqjpl/TV82sTAgHOIrCAgANoKzSpoff3qwPN2VJkpL+2F2TLu4qi4UJ4YC6oLAAQD3LPF6qu99ary2HC+TpYdFzo/ppVHRHs2MBLo3CAgD16NNtOXpw2UYVllWpdYtmmnvDQA3pGmh2LMDlUVgAoB5U2uya9fFO/eurfZKkqLDWmnvjQHVo3dzkZIB7oLAAwDk6WlSue95ar7QDxyVJE4eEa8qlvbjbMlCPKCwAcA5+OFyg299Yp6yCMvl6e2rmtf10WV/uCQTUNwoLANTRyi1H9OCyTTpRaVNEYEu9MiFGke18zY4FuCUKCwA4yG439I/U3fpH6m5J0tBugZozdqD8WzQzORngvigsAOCA4vIqPbRsk1K2ZkuSbh7SRY9d1lOeTAYHNCgKCwCcpX1Hi3XHm+nanVusZlaLnh3ZV9fHhpkdC2gSKCwAcBZSt+fo/iUbVVRepSA/b/3zxmhFdw4wOxbQZFBYAOAM7HZDL36+W7M/q75eJTY8QHNvHKj2rXxMTgY0LRQWADiNo0XlSlq2UV/vzpMkjR/UWU9c3pv5VQATUFgA4BS+25On+5Zu1NGicvk089AzI/vqWu4HBJiGwgIAv2CzG3oxdbde/Hy3DEPqHuSrOTcMVPegVmZHA5o0CgsA/OTQj6V6cNkmrdlfPcX+mNgwJV/ZR829rCYnA1CnD2Lnzp2r8PBw+fj4KD4+Xmlpaaddd+vWrRo1apTCw8NlsVg0e/bsc94nANQnwzD0/obDunT211qz/7haeln1jzFRmjGqH2UFcBIOF5alS5cqKSlJycnJWr9+vfr376/ExETl5uaecv3S0lJFRERoxowZCg4Orpd9AkB9KSit1KTFG3T/0uohywM7tdbK+4bqqqgOZkcD8AsWwzAMRzaIj49XbGys5syZI0my2+0KCwvTpEmTNHny5DNuGx4ervvvv1/3339/ve1TkgoLC+Xv76+CggL5+fk58nQANGFr9h3TfUs2KruwTFYPi+67pJvuviiSWWuBRuLI+7dDv5UVFRVKT09XQkLCzzvw8FBCQoJWr15dp7B12Wd5ebkKCwtrPQDgbBmGoX9/vU83/HuNsgvLFBHYUu/eNVj3XtKNsgI4KYd+M/Py8mSz2RQUFFRreVBQkLKzs+sUoC77nD59uvz9/WseYWFMjQ3g7JSUV+nPizfomY+2y2Y3dPWADlpx7wXqH9ba7GgAzsAl/1diypQpKigoqHlkZmaaHQmAC9iTW6yr5n6rjzYfkaeHRX+5qo+ev76/WngxYBJwdg79lgYGBspqtSonJ6fW8pycnNNeUNsQ+/T29pa3t3ed/j4ATdOHm7I0+Z3NKqmw/XQvoIGK7tzG7FgAzpJDZ1i8vLwUHR2t1NTUmmV2u12pqakaNGhQnQI0xD4B4KSySpueeH+LJi3eoJIKm+K7tNGHky6grAAuxuHzoElJSZowYYJiYmIUFxen2bNnq6SkRBMnTpQkjR8/Xh06dND06dMlVV9Uu23btpo/Hz58WBs3bpSvr6+6du16VvsEgLo4eKxE9yxarx8OV1+Yf88fIvVAQncurAVckMOFZfTo0Tp69KimTp2q7OxsRUVFKSUlpeai2YyMDHl4/PxikJWVpQEDBtR8PWvWLM2aNUvDhg3TqlWrzmqfAOColB+y9fDyTSoqr1JAi2Z6YXSULurR3uxYAOrI4XlYnBHzsAA4qcpm198+3ql/fbVPkhTdOUAvjR2g0NbNTU4G4Nccef/m0ngAbuNoUbkmLV6v7/dV3wvo1gu66NFLe6oZHwEBLo/CAsAtpB88rrvfWq+cwnK19LJq5rX9dXm/ELNjAagnFBYALs1mN/Svr/bq+U92qcpuKLJdS/1rXLS6tm9ldjQA9YjCAsBlZR4vVdKyjVp74EdJ0uV9Q/Tctf3k681LG+Bu+K0G4HIMw9Db6Yf09IfbVFxepZZeViX/Xx9dF91RFovF7HgAGgCFBYBLKSit1JT3Nmvllup7jcV0DtDz10epU9sWJicD0JAoLABcxtoDx3Xf4g3KKiiTp4dFD/yxu+4cFimrB2dVAHdHYQHg9Gx2Q3M+36N/pO6S3ZA6t22hF8cM4A7LQBNCYQHg1I4UnND9SzZqzf7quVWuHtBB00aex4W1QBPDbzwAp/XBpiw98d4WFZZVX1g7beR5umZgR7NjATABhQWA0yk4Uank//6g9zdmSZL6d/TX7DED1CWwpcnJAJiFwgLAqXy/75geXLZJh/NPyMMi/fnibpp0cVem1weaOAoLAKdQVFapmSk79eb3ByVJndq00AujoxTdOcDkZACcAYUFgOm+2JGrx9/boqyCMknSmNgwPXFFby6sBVCDVwMApjleUqG/fLi15lqVTm1aaPo1fTWka6DJyQA4GwoLgEZnGIbe23BY01Zs04+llfKwSDcP6aKk4d3VwouXJQC/xSsDgEaVcaxUj7+/RV/vzpMk9QxupRmj+imKSeAAnAGFBUCjqLLZ9dq3+/X8p7tUVmmXl6eH7rukm26/MIIRQAB+F4UFQIPbmV2kR97epE2HCiRJgyLa6q/X9GVeFQBnjcICoMFU2uyat2qvXvx8typthvx8PPXE5b11XUxHWSzcsBDA2aOwAGgQ248U6qHlm7Q1q1CSlNCrvZ69uq+C/HxMTgbAFVFYANQrm93Q/K/26flPd6rSZqh1i2Z66so+uioqlLMqAOqMwgKg3mQeL9WDyzYp7UD1nZX/2DtIz159ntq34qwKgHNDYQFwzgzD0LvrDyv5g60qLq++s3LylX24VgVAvaGwADgnx0sq9MT7W7RyS7YkKbpzgF64Pkqd2rYwORkAd0JhAVBnqdtz9Og7W5RXXC5PD4vuu6Sb7rooUp7MqwKgnlFYADisuLxKz6zYpiVrMyVJXdv76oXro9S3o7/JyQC4KwoLAId8sztPU97brMzjJ2SxSLcM6aKHEnvIp5nV7GgA3BiFBcBZ+bGkQs98tF3vrD8kSerQurlmXddfgyLbmpwMQFNAYQFwRoZh6MPNR/T0B1t1rKRCFos0/vzOenhET/l68xICoHHwagPgtHbnFOkvK7bV3Fm5W3tfzRjVT9GdA0xOBqCpobAA+I380gq98Oku/WdNhmx2Q15WD93zh66666JIeXkyAghA46OwAKhRabPrre8P6oXPdqvgRKUkaXjvID12WS+Fc2dlACaisACQYRj6Ymeunv1ou/YeLZEk9QxupalX9NbgroEmpwMACgvQ5O3ILtSzH22vuU6lTUsvJf2xu8bEhjEBHACnQWEBmqiCE5X628c7tGhNhuyG5GX10MQh4brn4q7y82lmdjwAqIXCAjQxhmHofz9kK/mDrTpaVC5JuqxvsCaP6MX9fwA4LQoL0IRk5Z/Q1P/+oM+250qSItq11LMj+zL5GwCnR2EBmoBKm10LvzugFz7dpZIKm5pZLbrroq66+6JIptQH4BIoLICb+25PnqZ+sFV7coslSTGdAzT9mr7qFtTK5GQAcPYoLICbyso/oWdXbtdHm49Iqh79M3lET10b3VEeHhaT0wGAYygsgJspr7Lp1W/266XUPTpRaZOHRRp3fmcl/bGH/Fsw+geAa6KwAG5k1c5cPf3hNu3Pq578LTY8QE//33nqHepncjIAODcUFsANZB4v1bQV2/TJthxJUrtW3nrssp4aGdVBFgsf/wBwfRQWwIWVlFfpn6v26JWv96uiyi6rh0UTB4frvoRuasXkbwDcCIUFcEF2u6H3NhzWcyk7lPvT5G+DI9vqqf/ro+6M/gHghigsgIvZkPGjnvpwmzZl5kuSOrVpoccv76XhvYP4+AeA26KwAC4ip7BMz/1vh97dcFiS1NLLqkmXdNPEIeHy9mTyNwDujcICOLmTw5Tnfr5HJRU2SdJ10R318Igeat/Kx+R0ANA4KCyAkzIMQys2H9HfPt6pjOOlkqQBnVrrqSv7qH9Ya3PDAUAjo7AATuj7fcc0feV2bTpUIKl6mPLkET119YAOzFILoEmisABOZE9usWb8b3vN3ZRbeFl1x4WRunVoF7X05tcVQNPFKyDgBPJLKzT7s9168/uDstkNWT0sGhsXpnsv6cZ1KgAgCgtgqiqbXYvSMvT8p7uUX1opSUro1V6TL+2lru19TU4HAM6DwgKYwDAMfbw1R3//ZKd25xZLkroH+erJK3praLd2JqcDAOfjUZeN5s6dq/DwcPn4+Cg+Pl5paWlnXH/58uXq2bOnfHx81LdvX61cubLW92+66SZZLJZajxEjRtQlGuDUDMPQl7uO6qq53+rO/6Rrd26xAlo007Sr+mjlvUMpKwBwGg6fYVm6dKmSkpI0b948xcfHa/bs2UpMTNTOnTvVvn3736z/3XffaezYsZo+fbquuOIKLVq0SCNHjtT69et13nnn1aw3YsQIvf766zVfe3t71/EpAc5p3YHjmpmyU2kHjkuqvqD25iFddNuFEfJvzn1/AOBMLIZhGI5sEB8fr9jYWM2ZM0eSZLfbFRYWpkmTJmny5Mm/WX/06NEqKSnRihUrapadf/75ioqK0rx58yRVn2HJz8/X+++/X6cnUVhYKH9/fxUUFMjPz69O+wAayq6cIs1M2anPtlffSdnL00Pjzu+suy6KVKAvxRxA0+XI+7dDZ1gqKiqUnp6uKVOm1Czz8PBQQkKCVq9efcptVq9eraSkpFrLEhMTf1NOVq1apfbt2ysgIEAXX3yxnnnmGbVt2/aU+ywvL1d5eXnN14WFhY48DaBRZOWf0OzPdunt9EOyG5KHRbo+Jkz3JXRTiH9zs+MBgEtxqLDk5eXJZrMpKCio1vKgoCDt2LHjlNtkZ2efcv3s7Oyar0eMGKFrrrlGXbp00d69e/XYY4/p0ksv1erVq2W1/vYeKdOnT9fTTz/tSHSg0WQeL9X8r/Zp6bpMVVTZJUkj+gTrocQejPwBgDpyilFCY8aMqflz37591a9fP0VGRmrVqlW65JJLfrP+lClTap21KSwsVFhYWKNkBU5nR3ahXl61Vys2H5HNXv1Ja1x4G02+rKcGdgowOR0AuDaHCktgYKCsVqtycnJqLc/JyVFwcPAptwkODnZofUmKiIhQYGCg9uzZc8rC4u3tzUW5cBp7jxZrxv926NNtP/+cX9i9ne4aFqnzI9rIYmEqfQA4Vw4Na/by8lJ0dLRSU1NrltntdqWmpmrQoEGn3GbQoEG11pekTz/99LTrS9KhQ4d07NgxhYSEOBIPaFQ/llToqQ+2KvGFr/Tpthx5WKQr+oVoxaQL9MbNcRoU2ZayAgD1xOGPhJKSkjRhwgTFxMQoLi5Os2fPVklJiSZOnChJGj9+vDp06KDp06dLku677z4NGzZMf//733X55ZdryZIlWrdunebPny9JKi4u1tNPP61Ro0YpODhYe/fu1SOPPKKuXbsqMTGxHp8qUD/Kq2x6c/VBvZi6W4VlVZKYnRYAGprDhWX06NE6evSopk6dquzsbEVFRSklJaXmwtqMjAx5ePx84mbw4MFatGiRnnjiCT322GPq1q2b3n///Zo5WKxWqzZv3qyFCxcqPz9foaGhGj58uKZNm8bHPnAq5VU2LVt3SC9/sUdZBWWSpJ7BrfTkFb01pGugyekAwL05PA+LM2IeFjSkskqblq3L1Mur9urIT0UlyM9bSX/srmujw2T14GMfAKiLBpuHBWhKTp5Rmfv5HmUXVheVYD8f3XVRpEbHhsmn2W+H3AMAGgaFBfiVSptd76Qf0kuf79Hh/BOSqovK3X+I1PUxFBUAMAOFBfiFlVuOaMb/dijjeKkkqX0rb93zh66cUQEAk1FYAEnHSyr05Ps/6KMtRyRJgb5eunNYpP50fmeKCgA4AQoLmryUH7L1xPtblFdcIauHRXdfFKm7LopUCy9+PQDAWfCKjCbr4LESPf/pLv13Y5YkqUdQK826rr/6dvQ3ORkA4NcoLGhS7HZDX+/J08LvDuiLnbkyfrqL8l0XRereS7rJ25OPfwDAGVFY0CQUl1fpnfRDWvjdAe3LK6lZ/oce7XR/Qnf1D2ttXjgAwO+isMCtHcgr0cLVB7R83SEVl1dPo+/r7anrYjpq/KBwdQlsaXJCAMDZoLDA7RiGoW/3HNNr3+6v+dhHkiLatdSEQeEaFd1Rvt786AOAK+FVG26jrNKm/248rNe+OaCdOUU1y//Qo51uGtJFQ7sGyoNp9AHAJVFY4PIO/ViqZWsz9daaDB0rqZAktfCy6rrojrppSBc+9gEAN0BhgUsqr7Lps225WrI2Q9/syav52KdD6+aaMLizRsd2kn/zZuaGBADUGwoLXMqe3CItScvUuxsO6/hPZ1MkaXBkW90Q30kj+gTL0+phYkIAQEOgsMDpnaiwacXmLC1dm6l1B3+sWR7k563rosN0fUyYOrVtYWJCAEBDo7DAae3MLtKiNQf17vrDKvppSLLVw6KLe7bXmNgwDevejrMpANBEUFjgVMoqbfrfD0f01vcZtc6mdGrTQqNjw3RddEe19/MxMSEAwAwUFjiFPbnFWpyWoXfWH1J+aaWk6rMpw3sH6cb4zhoc2ZYhyQDQhFFYYJryKptSfsjWW2sylLb/eM3yDq2ba2xc9bUpnE0BAEgUFpjg4LESLVqToeXph2pG+nhYpIt7BunG+E66sHs7WTmbAgD4BQoLGkWlza7U7bl6a81Bfb07r2Z5sJ+PRseGaXRsmEJbNzcxIQDAmVFY0KB25RRp+bpMvbfhsPKKq8+mWCzShd3a6cb4Trq4Z3tG+gAAfheFBfWuqKxSH246omXrMrUxM79meaCvt66N7qgb4joxbwoAwCEUFtQLwzC09sCPWro2Uyu3HNGJSpskyfOneVOujwnTsB7t1IyzKQCAOqCw4JzkFpbpnfWHtXxdpvblldQsj2zXUqNjw3T1gI5q18rbxIQAAHdAYYHDKm12fb4jV8vXZeqLnUdls1ffebCFl1VX9AvR6NgwDewUIIuFkT4AgPpBYcFZO5BXoiVrM/V2+iHlFZfXLI/uHKDRMWG6rF+IfL35kQIA1D/eXXBG5VU2fbI1R4vTMvTd3mM1ywN9vTVqYAddFxOmru19TUwIAGgKKCw4pb1Hi7UkLUNvpx/Sjz9NlX9yOPLYuE66pFd7LqAFADQaCgtqnKiwKWXrES1Oy6w1VX6wn4+ujw3T9TEd1TGA4cgAgMZHYWniDMPQ+ox8vZ2eqRWbjqiovErSyany22tsXCcN696Oyd0AAKaisDRRuUVleif9sJanZ2rf0Z+HI4e1aa7rosN0XUxHhfgzVT4AwDlQWJqQKptdX+0+qiVpmUrdkVszHLl5M6su6xuia6M7Kr5LG3lw40EAgJOhsLg5wzC0ITNfH20+ohWbs5RT+PNw5IGdWmt0bJgu7xfKcGQAgFPjXcoNGYahHw4X6sPNWfpo8xEdzj9R8702Lb10zYAOGh0bpm5BrUxMCQDA2aOwuJG9R4v1wcYsfbApS/t/MU1+Sy+rEnoH6fK+IRrWo528Pa0mpgQAwHEUFhdXWlGld9cf1tK1mdpyuKBmuU8zD13SK0hX9gvRRT3ay6cZJQUA4LooLC7q4LESvbH6oJaty1RRWfVQZKuHRUO7BeqqqFD9sXcw16UAANwG72gupKKq+qaDS9dmaNWuozKqB/moc9sWGnd+Z109oIPa+nJnZACA+6GwuIBdOUVatjZT7204rGMlFTXLh3Vvp5sGh2tY93YMRQYAuDUKi5P6saRCH27O0jvph7Tp0M/XpgT6emtUdAeNjglTRDtuOggAaBooLE6kymbXFzuP6p30Q0rdkaNKW/VnPp4eFl3cs72ujwnTsB7tuOkgAKDJobA4gdyiMi1Jy9SiNRnKLiyrWd47xE+jojvqqqhQBXJtCgCgCaOwmMQwDK098KPeWH1AKT9kq+qnafJPTuw2KrqjeoX4mZwSAADnQGFpZGWVNn24KUsLvjugrVmFNcsHdmqt8YPCdWnfYCZ2AwDgVygsjSQr/4QWp2Vo0ZqMmpE+3p4eunpAB/3p/M46r4O/yQkBAHBeFJYGVFZp0yfbcrR8Xaa+2ZNXM29KqL+Pxg0K15jYMAW09DI3JAAALoDC0gAOHivRa9/s13sbDqvwp1loJWlQRFuNG9RZw3sHyZORPgAAnDUKSz364XCB5n25Vyu3HNFP19CqQ+vmGhXdUddFd1RYmxbmBgQAwEVRWOpB2v7jeunz3fp6d17Nsot6tNMtF3TRkMhAZqEFAOAcUVjOwQ+HC/S3j3fqy11HJVXffPDKfiG6Y1gkQ5IBAKhHFJY62J9Xor9/slMrNh+RVD0T7fWxYbprWCQf+wAA0AAoLA7ILSzT7NTdWro2Uza7IYtF+r/+oXogobvCA1uaHQ8AALdFYTkLRWWVmv/VPv376/06UWmTJF3cs70eGt5DvUP56AcAgIZGYTmDiiq73lpzUC99vkfHf5rsbUCn1po8oqfiI9qanA4AgKaDwnIGB46VaNqKbbIbUkRgSz0yoocS+wTLYmHUDwAAjalOs5fNnTtX4eHh8vHxUXx8vNLS0s64/vLly9WzZ0/5+Piob9++WrlyZa3vG4ahqVOnKiQkRM2bN1dCQoJ2795dl2j1qntQK91+YaSevfo8ffLAhRpxXghlBQAAEzhcWJYuXaqkpCQlJydr/fr16t+/vxITE5Wbm3vK9b/77juNHTtWt9xyizZs2KCRI0dq5MiR+uGHH2rWmTlzpl588UXNmzdPa9asUcuWLZWYmKiysrK6P7N6MvnSnroxvjMz0wIAYCKLYZy8w83ZiY+PV2xsrObMmSNJstvtCgsL06RJkzR58uTfrD969GiVlJRoxYoVNcvOP/98RUVFad68eTIMQ6GhoXrwwQf10EMPSZIKCgoUFBSkBQsWaMyYMb+bqbCwUP7+/iooKJCfHxfBAgDgChx5/3botEFFRYXS09OVkJDw8w48PJSQkKDVq1efcpvVq1fXWl+SEhMTa9bfv3+/srOza63j7++v+Pj40+6zvLxchYWFtR4AAMB9OVRY8vLyZLPZFBQUVGt5UFCQsrOzT7lNdnb2Gdc/+V9H9jl9+nT5+/vXPMLCwhx5GgAAwMW45IUZU6ZMUUFBQc0jMzPT7EgAAKABOVRYAgMDZbValZOTU2t5Tk6OgoODT7lNcHDwGdc/+V9H9unt7S0/P79aDwAA4L4cKixeXl6Kjo5WampqzTK73a7U1FQNGjTolNsMGjSo1vqS9Omnn9as36VLFwUHB9dap7CwUGvWrDntPgEAQNPi8MRxSUlJmjBhgmJiYhQXF6fZs2erpKREEydOlCSNHz9eHTp00PTp0yVJ9913n4YNG6a///3vuvzyy7VkyRKtW7dO8+fPlyRZLBbdf//9euaZZ9StWzd16dJFTz75pEJDQzVy5Mj6e6YAAMBlOVxYRo8eraNHj2rq1KnKzs5WVFSUUlJSai6azcjIkIfHzyduBg8erEWLFumJJ57QY489pm7duun999/XeeedV7POI488opKSEt1+++3Kz8/XBRdcoJSUFPn4+NTDUwQAAK7O4XlYnBHzsAAA4HoabB4WAAAAM1BYAACA06OwAAAAp0dhAQAATs/hUULO6OR1w9xTCAAA13Hyfftsxv+4RWEpKiqSJO4pBACACyoqKpK/v/8Z13GLYc12u11ZWVlq1aqVLBZLnfdTWFiosLAwZWZmMjy6EXC8Gw/HuvFwrBsPx7rxNNSxNgxDRUVFCg0NrTWH26m4xRkWDw8PdezYsd72x/2JGhfHu/FwrBsPx7rxcKwbT0Mc6987s3ISF90CAACnR2EBAABOj8LyC97e3kpOTpa3t7fZUZoEjnfj4Vg3Ho514+FYNx5nONZucdEtAABwb5xhAQAATo/CAgAAnB6FBQAAOD0KCwAAcHpNrrDMnTtX4eHh8vHxUXx8vNLS0s64/vLly9WzZ0/5+Piob9++WrlyZSMldX2OHOtXXnlFQ4cOVUBAgAICApSQkPC7/zaozdGf7ZOWLFkii8WikSNHNmxAN+Losc7Pz9c999yjkJAQeXt7q3v37ryWnCVHj/Xs2bPVo0cPNW/eXGFhYXrggQdUVlbWSGld01dffaUrr7xSoaGhslgsev/99393m1WrVmngwIHy9vZW165dtWDBggbPKaMJWbJkieHl5WW89tprxtatW43bbrvNaN26tZGTk3PK9b/99lvDarUaM2fONLZt22Y88cQTRrNmzYwtW7Y0cnLX4+ixvuGGG4y5c+caGzZsMLZv327cdNNNhr+/v3Ho0KFGTu6aHD3eJ+3fv9/o0KGDMXToUOOqq65qnLAuztFjXV5ebsTExBiXXXaZ8c033xj79+83Vq1aZWzcuLGRk7seR4/1W2+9ZXh7extvvfWWsX//fuPjjz82QkJCjAceeKCRk7uWlStXGo8//rjx7rvvGpKM995774zr79u3z2jRooWRlJRkbNu2zXjppZcMq9VqpKSkNGjOJlVY4uLijHvuuafma5vNZoSGhhrTp08/5frXX3+9cfnll9daFh8fb9xxxx0NmtMdOHqsf62qqspo1aqVsXDhwoaK6FbqcryrqqqMwYMHG//+97+NCRMmUFjOkqPH+uWXXzYiIiKMioqKxoroNhw91vfcc49x8cUX11qWlJRkDBkypEFzupOzKSyPPPKI0adPn1rLRo8ebSQmJjZgMsNoMh8JVVRUKD09XQkJCTXLPDw8lJCQoNWrV59ym9WrV9daX5ISExNPuz6q1eVY/1ppaakqKyvVpk2bhorpNup6vP/yl7+offv2uuWWWxojpluoy7H+4IMPNGjQIN1zzz0KCgrSeeedp7/+9a+y2WyNFdsl1eVYDx48WOnp6TUfG+3bt08rV67UZZdd1iiZmwqz3hvd4uaHZyMvL082m01BQUG1lgcFBWnHjh2n3CY7O/uU62dnZzdYTndQl2P9a48++qhCQ0N/80uB36rL8f7mm2/06quvauPGjY2Q0H3U5Vjv27dPn3/+uW688UatXLlSe/bs0d13363KykolJyc3RmyXVJdjfcMNNygvL08XXHCBDMNQVVWV7rzzTj322GONEbnJON17Y2FhoU6cOKHmzZs3yN/bZM6wwHXMmDFDS5Ys0XvvvScfHx+z47idoqIijRs3Tq+88ooCAwPNjuP27Ha72rdvr/nz5ys6OlqjR4/W448/rnnz5pkdze2sWrVKf/3rX/XPf/5T69ev17vvvquPPvpI06ZNMzsa6kGTOcMSGBgoq9WqnJycWstzcnIUHBx8ym2Cg4MdWh/V6nKsT5o1a5ZmzJihzz77TP369WvImG7D0eO9d+9eHThwQFdeeWXNMrvdLkny9PTUzp07FRkZ2bChXVRdfrZDQkLUrFkzWa3WmmW9evVSdna2Kioq5OXl1aCZXVVdjvWTTz6pcePG6dZbb5Uk9e3bVyUlJbr99tv1+OOPy8OD/0evD6d7b/Tz82uwsytSEzrD4uXlpejoaKWmptYss9vtSk1N1aBBg065zaBBg2qtL0mffvrpaddHtboca0maOXOmpk2bppSUFMXExDRGVLfg6PHu2bOntmzZoo0bN9Y8/u///k9/+MMftHHjRoWFhTVmfJdSl5/tIUOGaM+ePTWlUJJ27dqlkJAQysoZ1OVYl5aW/qaUnCyKBrfNqzemvTc26CW9TmbJkiWGt7e3sWDBAmPbtm3G7bffbrRu3drIzs42DMMwxo0bZ0yePLlm/W+//dbw9PQ0Zs2aZWzfvt1ITk5mWPNZcvRYz5gxw/Dy8jLefvtt48iRIzWPoqIis56CS3H0eP8ao4TOnqPHOiMjw2jVqpXx5z//2di5c6exYsUKo3379sYzzzxj1lNwGY4e6+TkZKNVq1bG4sWLjX379hmffPKJERkZaVx//fVmPQWXUFRUZGzYsMHYsGGDIcl4/vnnjQ0bNhgHDx40DMMwJk+ebIwbN65m/ZPDmh9++GFj+/btxty5cxnW3BBeeuklo1OnToaXl5cRFxdnfP/99zXfGzZsmDFhwoRa6y9btszo3r274eXlZfTp08f46KOPGjmx63LkWHfu3NmQ9JtHcnJy4wd3UY7+bP8ShcUxjh7r7777zoiPjze8vb2NiIgI49lnnzWqqqoaObVrcuRYV1ZWGk899ZQRGRlp+Pj4GGFhYcbdd99t/Pjjj40f3IV88cUXp3z9PXlsJ0yYYAwbNuw320RFRRleXl5GRESE8frrrzd4TothcJ4MAAA4tyZzDQsAAHBdFBYAAOD0KCwAAMDpUVgAAIDTo7AAAACnR2EBAABOj8ICAACcHoUFAAA4PQoLAABwehQWAADg9CgsAADA6VFYAACA0/t/Jym3231vbR8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(threshold, revenue, label = 'default')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "JwcI4MCZj8mu",
        "outputId": "bfad8a8d-7123-4754-e103-dfaad35b5b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executive Summary"
      ],
      "metadata": {
        "id": "CDPM0upOMTOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conservative Strategy - Threshold = 0.55\n",
        "# Aggressive Strategy - Threshold = 0.4\n",
        "\n",
        "\n",
        "\n",
        "def ex_sum(xdf, actual, pred, c, a, balance = 'B_2', spend = 'S_3'):\n",
        "    summary = pd.DataFrame(columns = ['#Total', 'Default Rate', 'Revenue'], index = ['Conservative', 'Aggressive'])\n",
        "    summary.loc['Conservative', :] = strategy(xdf, actual, pred, c, balance = 'B_2', spend = 'S_3')\n",
        "    summary.loc['Aggressive', :] = strategy(xdf, actual, pred, a, balance = 'B_2', spend = 'S_3')\n",
        "    return summary\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KnCOi9ZJkAu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_sum(xtrain, ytrain['target'], y_pred[:,0], 0.5, 0.4, balance = 'B_2', spend = 'S_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Z1uLtd8wjUw_",
        "outputId": "c3f8fd1f-3e80-4fa6-adea-5a4086bbd765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              #Total Default Rate      Revenue\n",
              "Conservative  201383     0.090862  2370.260123\n",
              "Aggressive    188797     0.066103  2320.595564"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a183b0f-ab1a-45cc-b530-ebbf03dcfbe0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#Total</th>\n",
              "      <th>Default Rate</th>\n",
              "      <th>Revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Conservative</th>\n",
              "      <td>201383</td>\n",
              "      <td>0.090862</td>\n",
              "      <td>2370.260123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aggressive</th>\n",
              "      <td>188797</td>\n",
              "      <td>0.066103</td>\n",
              "      <td>2320.595564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a183b0f-ab1a-45cc-b530-ebbf03dcfbe0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a183b0f-ab1a-45cc-b530-ebbf03dcfbe0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a183b0f-ab1a-45cc-b530-ebbf03dcfbe0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_sum(xtest1, ytest1['target'], ytest1_pred[:,0], 0.5, 0.4, balance = 'B_2', spend = 'S_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "VWWY1b87nd19",
        "outputId": "90276f4b-1017-4d0f-f0ee-5b3c1c56c485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             #Total Default Rate     Revenue\n",
              "Conservative  23928     0.096498  277.573557\n",
              "Aggressive    22475     0.072036  272.171131"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7e510e0-7650-46ba-9fac-0ae834360ddd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#Total</th>\n",
              "      <th>Default Rate</th>\n",
              "      <th>Revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Conservative</th>\n",
              "      <td>23928</td>\n",
              "      <td>0.096498</td>\n",
              "      <td>277.573557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aggressive</th>\n",
              "      <td>22475</td>\n",
              "      <td>0.072036</td>\n",
              "      <td>272.171131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7e510e0-7650-46ba-9fac-0ae834360ddd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7e510e0-7650-46ba-9fac-0ae834360ddd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7e510e0-7650-46ba-9fac-0ae834360ddd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_sum(xtest2, ytest2['target'], ytest2_pred[:,0], 0.5, 0.4, balance = 'B_2', spend = 'S_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "qLvOQ2AZnweF",
        "outputId": "ba776a22-bca8-4a2d-baf3-fbd45f7cf420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             #Total Default Rate     Revenue\n",
              "Conservative  63354     0.083641  740.679005\n",
              "Aggressive    59051     0.059017  721.551229"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d28e101-d83a-4b2d-b722-df7c0b2c8a3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#Total</th>\n",
              "      <th>Default Rate</th>\n",
              "      <th>Revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Conservative</th>\n",
              "      <td>63354</td>\n",
              "      <td>0.083641</td>\n",
              "      <td>740.679005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aggressive</th>\n",
              "      <td>59051</td>\n",
              "      <td>0.059017</td>\n",
              "      <td>721.551229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d28e101-d83a-4b2d-b722-df7c0b2c8a3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d28e101-d83a-4b2d-b722-df7c0b2c8a3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d28e101-d83a-4b2d-b722-df7c0b2c8a3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtest2.shape)\n",
        "print(xtest1.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8AT83ymjwYZ",
        "outputId": "6db505bf-8284-4e7e-e9c2-e6aff0f57fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(88750, 44)\n",
            "(30730, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest1_pred )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnezfRcps3BH",
        "outputId": "cffaf7d5-2890-45a3-c12a-d7e40fd17cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00281386]\n",
            " [0.00556373]\n",
            " [0.04376058]\n",
            " ...\n",
            " [0.39005342]\n",
            " [0.07992009]\n",
            " [0.9369414 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpWAUvbmuQ8J",
        "outputId": "e36ecd53-9fa1-411e-b2d4-a86d6f98e6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(269243, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = np.concatenate((ytest1_pred , ytrain), axis = 0)\n",
        "yhat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTM5ewDKuN-M",
        "outputId": "4d8ba60b-3e83-4537-d5e4-6c11870d6d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(299973, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.concat([xtest1, xtrain, xtest2], axis = 0)\n",
        "y = pd.concat([ytest1, ytrain, ytest2], axis = 0)\n",
        "yhat = np.concatenate((ytest1_pred , y_pred, ytest2_pred), axis = 0)\n",
        "\n",
        "\n",
        "ex_sum(x, y['target'], yhat[:,0], 0.5, 0.4, balance = 'B_2', spend = 'S_3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "hGqYnEfiDUKq",
        "outputId": "aec7f87a-184c-4d1c-81e8-16c4dd647543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              #Total Default Rate      Revenue\n",
              "Conservative  288665     0.089744  3388.512685\n",
              "Aggressive    270323     0.065048  3314.317924"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5431886-455b-4bce-a52e-6a0e2fc70d76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#Total</th>\n",
              "      <th>Default Rate</th>\n",
              "      <th>Revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Conservative</th>\n",
              "      <td>288665</td>\n",
              "      <td>0.089744</td>\n",
              "      <td>3388.512685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aggressive</th>\n",
              "      <td>270323</td>\n",
              "      <td>0.065048</td>\n",
              "      <td>3314.317924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5431886-455b-4bce-a52e-6a0e2fc70d76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5431886-455b-4bce-a52e-6a0e2fc70d76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5431886-455b-4bce-a52e-6a0e2fc70d76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(ytest1, ytest1_pred[:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I5j78UmtQwN",
        "outputId": "c60a35c1-a00d-4bbe-f2cb-a391fd8e8641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9212237935088915"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest1.mean()"
      ],
      "metadata": {
        "id": "SBZy_2iBts8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62ed61b-5197-4a65-838f-0fe9f882ef99"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target    0.233355\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest2.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTBXHrb1y6ji",
        "outputId": "0e7d2125-8339-412f-e1a2-9e61adfd98d0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target    0.278287\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJcYZxH1y8hY",
        "outputId": "4d3eb80f-17d1-4956-bf67-5cbc50e1ee36"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target    0.256378\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while 2 != 0:\n",
        "    i +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "9V1RrnYwy-sC",
        "outputId": "718881a4-e22a-4cf0-8ecd-74cf4ad4c006"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-30b0de8250de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "zbwSrpMrjdzF",
        "outputId": "de8bf67c-ca8a-4184-a0bf-713c11b8afe4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-397d543883c5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBIvWdvQA9QE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}