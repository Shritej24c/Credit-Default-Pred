{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Applications/anaconda3/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras~=2.6 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: clang~=5.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.53.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Applications/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Applications/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Applications/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (6.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Applications/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Applications/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Applications/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: keras in /Applications/anaconda3/lib/python3.8/site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20 in /Applications/anaconda3/lib/python3.8/site-packages (3.20.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'protobuf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7a8f51706131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprotobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'protobuf'"
     ]
    }
   ],
   "source": [
    "import protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/core/framework/function_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr_value_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_attr__value__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_node__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_op__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/core/framework/attr_value_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/core/framework/tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_resource__handle__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/core/framework/resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mcontaining_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   fields=[\n\u001b[0;32m---> 36\u001b[0;31m     _descriptor.FieldDescriptor(\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorflow.TensorShapeProto.Dim.size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpp_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFindFieldByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m   def __init__(self, name, full_name, index, number, type, cpp_type, label,\n\u001b[1;32m    563\u001b[0m                \u001b[0mdefault_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menum_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontaining_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.7 in /Applications/anaconda3/lib/python3.8/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /Applications/anaconda3/lib/python3.8/site-packages (from scipy==1.7) (1.19.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy==1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Applications/anaconda3/lib/python3.8/site-packages (1.23.5)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.2-cp38-cp38-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in method __contains__ of dict object at 0x7f89daa165c0> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-d6579f534729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tf_session\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TF_SetConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement protoc (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for protoc\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install protoc >= 3.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time as t\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_49</th>\n",
       "      <th>B_6</th>\n",
       "      <th>B_7</th>\n",
       "      <th>B_8</th>\n",
       "      <th>D_50</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>D_52</th>\n",
       "      <th>P_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>D_53</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>D_54</th>\n",
       "      <th>R_4</th>\n",
       "      <th>S_7</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>D_55</th>\n",
       "      <th>D_56</th>\n",
       "      <th>B_13</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>S_9</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_59</th>\n",
       "      <th>D_60</th>\n",
       "      <th>D_61</th>\n",
       "      <th>B_15</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_63</th>\n",
       "      <th>D_64</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_17</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>D_66</th>\n",
       "      <th>B_20</th>\n",
       "      <th>D_68</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_69</th>\n",
       "      <th>B_22</th>\n",
       "      <th>D_70</th>\n",
       "      <th>D_71</th>\n",
       "      <th>D_72</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>D_73</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_74</th>\n",
       "      <th>D_75</th>\n",
       "      <th>D_76</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>D_77</th>\n",
       "      <th>B_25</th>\n",
       "      <th>B_26</th>\n",
       "      <th>D_78</th>\n",
       "      <th>D_79</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>S_16</th>\n",
       "      <th>D_80</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>B_27</th>\n",
       "      <th>D_81</th>\n",
       "      <th>D_82</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>D_83</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>D_84</th>\n",
       "      <th>R_16</th>\n",
       "      <th>B_29</th>\n",
       "      <th>B_30</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>D_87</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>D_88</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>B_33</th>\n",
       "      <th>D_89</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_91</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>D_103</th>\n",
       "      <th>D_104</th>\n",
       "      <th>D_105</th>\n",
       "      <th>D_106</th>\n",
       "      <th>D_107</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_108</th>\n",
       "      <th>D_109</th>\n",
       "      <th>D_110</th>\n",
       "      <th>D_111</th>\n",
       "      <th>B_39</th>\n",
       "      <th>D_112</th>\n",
       "      <th>B_40</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_113</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_115</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_118</th>\n",
       "      <th>D_119</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_121</th>\n",
       "      <th>D_122</th>\n",
       "      <th>D_123</th>\n",
       "      <th>D_124</th>\n",
       "      <th>D_125</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_127</th>\n",
       "      <th>D_128</th>\n",
       "      <th>D_129</th>\n",
       "      <th>B_41</th>\n",
       "      <th>B_42</th>\n",
       "      <th>D_130</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_132</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_134</th>\n",
       "      <th>D_135</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.008771</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.080986</td>\n",
       "      <td>0.708906</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.358587</td>\n",
       "      <td>0.525351</td>\n",
       "      <td>0.255736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.059416</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.148698</td>\n",
       "      <td>1.335856</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.207334</td>\n",
       "      <td>0.736463</td>\n",
       "      <td>0.096219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>1.001519</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.161345</td>\n",
       "      <td>0.148266</td>\n",
       "      <td>0.922998</td>\n",
       "      <td>0.354596</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.118075</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.158612</td>\n",
       "      <td>0.065728</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.063646</td>\n",
       "      <td>0.199617</td>\n",
       "      <td>0.308233</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.401619</td>\n",
       "      <td>0.091071</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652984</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.272008</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.108271</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.080422</td>\n",
       "      <td>0.069067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.506612</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>1.009825</td>\n",
       "      <td>0.084683</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>1.001101</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>1.503673</td>\n",
       "      <td>1.006133</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.894090</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.911191</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.766688</td>\n",
       "      <td>1.008691</td>\n",
       "      <td>1.004587</td>\n",
       "      <td>0.893734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670041</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007336</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>0.676922</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.238250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.232120</td>\n",
       "      <td>0.236266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702280</td>\n",
       "      <td>0.434345</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.686516</td>\n",
       "      <td>0.008740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003319</td>\n",
       "      <td>1.007819</td>\n",
       "      <td>1.000080</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.712795</td>\n",
       "      <td>0.113239</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.353630</td>\n",
       "      <td>0.521311</td>\n",
       "      <td>0.223329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065261</td>\n",
       "      <td>0.057744</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.149723</td>\n",
       "      <td>1.339794</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.202778</td>\n",
       "      <td>0.720886</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>1.009033</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.140951</td>\n",
       "      <td>0.143530</td>\n",
       "      <td>0.919414</td>\n",
       "      <td>0.326757</td>\n",
       "      <td>0.156201</td>\n",
       "      <td>0.118737</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.148459</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.065501</td>\n",
       "      <td>0.151387</td>\n",
       "      <td>0.265026</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>0.406326</td>\n",
       "      <td>0.086805</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647093</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.188970</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.509048</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.140611</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>0.040469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.081413</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.500855</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>1.009461</td>\n",
       "      <td>0.081843</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.006779</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>1.503577</td>\n",
       "      <td>1.005791</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.902135</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.919876</td>\n",
       "      <td>0.975624</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.786007</td>\n",
       "      <td>1.000084</td>\n",
       "      <td>1.004118</td>\n",
       "      <td>0.906841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668647</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003205</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007653</td>\n",
       "      <td>0.184093</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.247217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.243532</td>\n",
       "      <td>0.241885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707017</td>\n",
       "      <td>0.430501</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.686414</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.008394</td>\n",
       "      <td>1.004333</td>\n",
       "      <td>1.008344</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007495</td>\n",
       "      <td>0.004931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.009217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.068839</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.060492</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.334650</td>\n",
       "      <td>0.524568</td>\n",
       "      <td>0.189424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>1.337179</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>0.738044</td>\n",
       "      <td>0.134073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048367</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>1.009184</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.112229</td>\n",
       "      <td>0.137014</td>\n",
       "      <td>1.001977</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>0.153795</td>\n",
       "      <td>0.114534</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>0.139504</td>\n",
       "      <td>0.084757</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>0.070607</td>\n",
       "      <td>0.305883</td>\n",
       "      <td>0.212165</td>\n",
       "      <td>0.063955</td>\n",
       "      <td>0.406768</td>\n",
       "      <td>0.094001</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645819</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.495308</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.075868</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.103239</td>\n",
       "      <td>0.047454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.078891</td>\n",
       "      <td>0.076510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.504606</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>1.004291</td>\n",
       "      <td>0.081954</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>1.001014</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>1.503359</td>\n",
       "      <td>1.005801</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.939654</td>\n",
       "      <td>0.134938</td>\n",
       "      <td>0.958699</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.806840</td>\n",
       "      <td>1.003014</td>\n",
       "      <td>1.009285</td>\n",
       "      <td>0.928719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670901</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004312</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.853498</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.239867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.240768</td>\n",
       "      <td>0.239710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704843</td>\n",
       "      <td>0.434409</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.690101</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.009307</td>\n",
       "      <td>1.007831</td>\n",
       "      <td>1.006878</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.323271</td>\n",
       "      <td>0.530929</td>\n",
       "      <td>0.135586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083720</td>\n",
       "      <td>0.049253</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.151219</td>\n",
       "      <td>1.339909</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.208214</td>\n",
       "      <td>0.741813</td>\n",
       "      <td>0.134437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>1.007456</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.102838</td>\n",
       "      <td>0.129017</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>0.275055</td>\n",
       "      <td>0.155772</td>\n",
       "      <td>0.120740</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.048382</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.065926</td>\n",
       "      <td>0.273553</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.022732</td>\n",
       "      <td>0.405175</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654358</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.508670</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.515282</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.150209</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.206394</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.077490</td>\n",
       "      <td>0.071547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.508998</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>1.004728</td>\n",
       "      <td>0.060634</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>1.002775</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>1.503701</td>\n",
       "      <td>1.007036</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.913205</td>\n",
       "      <td>0.140058</td>\n",
       "      <td>0.926341</td>\n",
       "      <td>0.975499</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>0.808214</td>\n",
       "      <td>1.001517</td>\n",
       "      <td>1.004514</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672620</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005338</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002538</td>\n",
       "      <td>0.153939</td>\n",
       "      <td>0.844667</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.240727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.711546</td>\n",
       "      <td>0.436903</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.687779</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.001671</td>\n",
       "      <td>1.003460</td>\n",
       "      <td>1.007573</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.038862</td>\n",
       "      <td>0.720619</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>0.529305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.154026</td>\n",
       "      <td>1.341735</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.205468</td>\n",
       "      <td>0.691986</td>\n",
       "      <td>0.121518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054221</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>1.003738</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.094311</td>\n",
       "      <td>0.129539</td>\n",
       "      <td>0.917133</td>\n",
       "      <td>0.231110</td>\n",
       "      <td>0.154914</td>\n",
       "      <td>0.095178</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.126443</td>\n",
       "      <td>0.039259</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.233103</td>\n",
       "      <td>0.175655</td>\n",
       "      <td>0.031171</td>\n",
       "      <td>0.487460</td>\n",
       "      <td>0.093915</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650112</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.216507</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.507712</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.096441</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.076561</td>\n",
       "      <td>0.074432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.506213</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>1.006536</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>1.509905</td>\n",
       "      <td>1.002915</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.131620</td>\n",
       "      <td>0.933479</td>\n",
       "      <td>0.978027</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.005735</td>\n",
       "      <td>0.953363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673869</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003175</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.811199</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.247939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.244199</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705343</td>\n",
       "      <td>0.437433</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.688774</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.009886</td>\n",
       "      <td>1.005053</td>\n",
       "      <td>1.008132</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.009827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  0.938469   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  0.936665   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  0.954180   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13  0.960384   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  D_42  \\\n",
       "0  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771  0.004709   NaN   \n",
       "1  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798  0.002714   NaN   \n",
       "2  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598  0.009423   NaN   \n",
       "3  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685  0.005531   NaN   \n",
       "4  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653  0.009312   NaN   \n",
       "\n",
       "   D_43      D_44       B_4      D_45       B_5       R_2      D_46      D_47  \\\n",
       "0   NaN  0.000630  0.080986  0.708906  0.170600  0.006204  0.358587  0.525351   \n",
       "1   NaN  0.002526  0.069419  0.712795  0.113239  0.006206  0.353630  0.521311   \n",
       "2   NaN  0.007605  0.068839  0.720884  0.060492  0.003259  0.334650  0.524568   \n",
       "3   NaN  0.006406  0.055630  0.723997  0.166782  0.009918  0.323271  0.530929   \n",
       "4   NaN  0.007731  0.038862  0.720619  0.143630  0.006667  0.231009  0.529305   \n",
       "\n",
       "       D_48  D_49       B_6       B_7       B_8      D_50      D_51       B_9  \\\n",
       "0  0.255736   NaN  0.063902  0.059416  0.006466  0.148698  1.335856  0.008207   \n",
       "1  0.223329   NaN  0.065261  0.057744  0.001614  0.149723  1.339794  0.008373   \n",
       "2  0.189424   NaN  0.066982  0.056647  0.005126  0.151955  1.337179  0.009355   \n",
       "3  0.135586   NaN  0.083720  0.049253  0.001418  0.151219  1.339909  0.006782   \n",
       "4       NaN   NaN  0.075900  0.048918  0.001199  0.154026  1.341735  0.000519   \n",
       "\n",
       "        R_3      D_52       P_3      B_10  D_53       S_5      B_11       S_6  \\\n",
       "0  0.001423  0.207334  0.736463  0.096219   NaN  0.023381  0.002768  0.008322   \n",
       "1  0.001984  0.202778  0.720886  0.099804   NaN  0.030599  0.002749  0.002482   \n",
       "2  0.007426  0.206629  0.738044  0.134073   NaN  0.048367  0.010077  0.000530   \n",
       "3  0.003515  0.208214  0.741813  0.134437   NaN  0.030063  0.009667  0.000783   \n",
       "4  0.001362  0.205468  0.691986  0.121518   NaN  0.054221  0.009484  0.006698   \n",
       "\n",
       "       D_54       R_4       S_7      B_12       S_8      D_55      D_56  \\\n",
       "0  1.001519  0.008298  0.161345  0.148266  0.922998  0.354596  0.152025   \n",
       "1  1.009033  0.005136  0.140951  0.143530  0.919414  0.326757  0.156201   \n",
       "2  1.009184  0.006961  0.112229  0.137014  1.001977  0.304124  0.153795   \n",
       "3  1.007456  0.008706  0.102838  0.129017  0.704016  0.275055  0.155772   \n",
       "4  1.003738  0.003846  0.094311  0.129539  0.917133  0.231110  0.154914   \n",
       "\n",
       "       B_13       R_5      D_58       S_9      B_14      D_59      D_60  \\\n",
       "0  0.118075  0.001882  0.158612  0.065728  0.018385  0.063646  0.199617   \n",
       "1  0.118737  0.001610  0.148459  0.093935  0.013035  0.065501  0.151387   \n",
       "2  0.114534  0.006328  0.139504  0.084757  0.056653  0.070607  0.305883   \n",
       "3  0.120740  0.004980  0.138100  0.048382  0.012498  0.065926  0.273553   \n",
       "4  0.095178  0.001653  0.126443  0.039259  0.027897  0.063697  0.233103   \n",
       "\n",
       "       D_61      B_15      S_11      D_62 D_63 D_64      D_65      B_16  B_17  \\\n",
       "0  0.308233  0.016361  0.401619  0.091071   CR    O  0.007126  0.007665   NaN   \n",
       "1  0.265026  0.017688  0.406326  0.086805   CR    O  0.002413  0.007148   NaN   \n",
       "2  0.212165  0.063955  0.406768  0.094001   CR    O  0.001878  0.003636   NaN   \n",
       "3  0.204300  0.022732  0.405175  0.094854   CR    O  0.005899  0.005896   NaN   \n",
       "4  0.175655  0.031171  0.487460  0.093915   CR    O  0.009479  0.001714   NaN   \n",
       "\n",
       "       B_18      B_19  D_66      B_20  D_68      S_12       R_6      S_13  \\\n",
       "0  0.652984  0.008520   NaN  0.004730   6.0  0.272008  0.008363  0.515222   \n",
       "1  0.647093  0.002238   NaN  0.003879   6.0  0.188970  0.004030  0.509048   \n",
       "2  0.645819  0.000408   NaN  0.004578   6.0  0.495308  0.006838  0.679257   \n",
       "3  0.654358  0.005897   NaN  0.005207   6.0  0.508670  0.008183  0.515282   \n",
       "4  0.650112  0.007773   NaN  0.005851   6.0  0.216507  0.008605  0.507712   \n",
       "\n",
       "       B_21      D_69      B_22      D_70      D_71      D_72      S_15  \\\n",
       "0  0.002644  0.009013  0.004808  0.008342  0.119403  0.004802  0.108271   \n",
       "1  0.004193  0.007842  0.001283  0.006524  0.140611  0.000094  0.101018   \n",
       "2  0.001337  0.006025  0.009393  0.002615  0.075868  0.007152  0.103239   \n",
       "3  0.008716  0.005271  0.004554  0.002052  0.150209  0.005364  0.206394   \n",
       "4  0.006821  0.000152  0.000104  0.001419  0.096441  0.007972  0.106020   \n",
       "\n",
       "       B_23  D_73       P_4      D_74      D_75  D_76      B_24       R_7  \\\n",
       "0  0.050882   NaN  0.007554  0.080422  0.069067   NaN  0.004327  0.007562   \n",
       "1  0.040469   NaN  0.004832  0.081413  0.074166   NaN  0.004203  0.005304   \n",
       "2  0.047454   NaN  0.006561  0.078891  0.076510   NaN  0.001782  0.001422   \n",
       "3  0.031705   NaN  0.009559  0.077490  0.071547   NaN  0.005595  0.006363   \n",
       "4  0.032733   NaN  0.008156  0.076561  0.074432   NaN  0.004933  0.004831   \n",
       "\n",
       "   D_77      B_25      B_26      D_78      D_79       R_8  R_9      S_16  \\\n",
       "0   NaN  0.007729  0.000272  0.001576  0.004239  0.001434  NaN  0.002271   \n",
       "1   NaN  0.001864  0.000979  0.009896  0.007597  0.000509  NaN  0.009810   \n",
       "2   NaN  0.005419  0.006149  0.009629  0.003094  0.008295  NaN  0.009362   \n",
       "3   NaN  0.000646  0.009193  0.008568  0.003895  0.005153  NaN  0.004876   \n",
       "4   NaN  0.001833  0.005738  0.003289  0.002608  0.007338  NaN  0.007447   \n",
       "\n",
       "       D_80      R_10      R_11      B_27      D_81      D_82      S_17  \\\n",
       "0  0.004061  0.007121  0.002456  0.002310  0.003532  0.506612  0.008033   \n",
       "1  0.000127  0.005966  0.000395  0.001327  0.007773  0.500855  0.000760   \n",
       "2  0.000954  0.005447  0.007345  0.007624  0.008811  0.504606  0.004056   \n",
       "3  0.005665  0.001888  0.004961  0.000034  0.004652  0.508998  0.006969   \n",
       "4  0.004465  0.006111  0.002246  0.002109  0.001141  0.506213  0.001770   \n",
       "\n",
       "       R_12      B_28      R_13      D_83      R_14      R_15      D_84  \\\n",
       "0  1.009825  0.084683  0.003820  0.007043  0.000438  0.006452  0.000830   \n",
       "1  1.009461  0.081843  0.000347  0.007789  0.004311  0.002332  0.009469   \n",
       "2  1.004291  0.081954  0.002709  0.004093  0.007139  0.008358  0.002325   \n",
       "3  1.004728  0.060634  0.009982  0.008817  0.008690  0.007364  0.005924   \n",
       "4  1.000904  0.062492  0.005860  0.001845  0.007816  0.002470  0.005516   \n",
       "\n",
       "       R_16  B_29  B_30      S_18      D_86  D_87      R_17      R_18  D_88  \\\n",
       "0  0.005055   NaN   0.0  0.005720  0.007084   NaN  0.000198  0.008907   NaN   \n",
       "1  0.003753   NaN   0.0  0.007584  0.006677   NaN  0.001142  0.005907   NaN   \n",
       "2  0.007381   NaN   0.0  0.005901  0.001185   NaN  0.008013  0.008882   NaN   \n",
       "3  0.008802   NaN   0.0  0.002520  0.003324   NaN  0.009455  0.008348   NaN   \n",
       "4  0.007166   NaN   0.0  0.000155  0.001504   NaN  0.002019  0.002678   NaN   \n",
       "\n",
       "   B_31      S_19      R_19      B_32      S_20      R_20      R_21      B_33  \\\n",
       "0     1  0.002537  0.005177  0.006626  0.009705  0.007782  0.002450  1.001101   \n",
       "1     1  0.008427  0.008979  0.001854  0.009924  0.005987  0.002247  1.006779   \n",
       "2     1  0.007327  0.002016  0.008686  0.008446  0.007291  0.007794  1.001014   \n",
       "3     1  0.007053  0.003909  0.002478  0.006614  0.009977  0.007686  1.002775   \n",
       "4     1  0.007728  0.003432  0.002199  0.005511  0.004105  0.009656  1.006536   \n",
       "\n",
       "       D_89      R_22      R_23      D_91      D_92      D_93      D_94  \\\n",
       "0  0.002665  0.007479  0.006893  1.503673  1.006133  0.003569  0.008871   \n",
       "1  0.002508  0.006827  0.002837  1.503577  1.005791  0.000571  0.000391   \n",
       "2  0.009634  0.009820  0.005080  1.503359  1.005801  0.007425  0.009234   \n",
       "3  0.007791  0.000458  0.007320  1.503701  1.007036  0.000664  0.003200   \n",
       "4  0.005158  0.003341  0.000264  1.509905  1.002915  0.003079  0.003845   \n",
       "\n",
       "       R_24      R_25      D_96      S_22      S_23      S_24      S_25  \\\n",
       "0  0.003950  0.003647  0.004950  0.894090  0.135561  0.911191  0.974539   \n",
       "1  0.008351  0.008850  0.003180  0.902135  0.136333  0.919876  0.975624   \n",
       "2  0.002471  0.009769  0.005433  0.939654  0.134938  0.958699  0.974067   \n",
       "3  0.008507  0.004858  0.000063  0.913205  0.140058  0.926341  0.975499   \n",
       "4  0.007190  0.002983  0.000535  0.921026  0.131620  0.933479  0.978027   \n",
       "\n",
       "       S_26     D_102     D_103     D_104     D_105  D_106     D_107  \\\n",
       "0  0.001243  0.766688  1.008691  1.004587  0.893734    NaN  0.670041   \n",
       "1  0.004561  0.786007  1.000084  1.004118  0.906841    NaN  0.668647   \n",
       "2  0.011736  0.806840  1.003014  1.009285  0.928719    NaN  0.670901   \n",
       "3  0.007571  0.808214  1.001517  1.004514  0.935383    NaN  0.672620   \n",
       "4  0.018200  0.822281  1.006125  1.005735  0.953363    NaN  0.673869   \n",
       "\n",
       "       B_36      B_37  R_26      R_27  B_38  D_108     D_109  D_110  D_111  \\\n",
       "0  0.009968  0.004572   NaN  1.008949   2.0    NaN  0.004326    NaN    NaN   \n",
       "1  0.003921  0.004654   NaN  1.003205   2.0    NaN  0.008707    NaN    NaN   \n",
       "2  0.001264  0.019176   NaN  1.000754   2.0    NaN  0.004092    NaN    NaN   \n",
       "3  0.002729  0.011720   NaN  1.005338   2.0    NaN  0.009703    NaN    NaN   \n",
       "4  0.009998  0.017598   NaN  1.003175   2.0    NaN  0.009120    NaN    NaN   \n",
       "\n",
       "   B_39     D_112      B_40      S_27     D_113  D_114     D_115  D_116  \\\n",
       "0   NaN  1.007336  0.210060  0.676922  0.007871    1.0  0.238250    0.0   \n",
       "1   NaN  1.007653  0.184093  0.822281  0.003444    1.0  0.247217    0.0   \n",
       "2   NaN  1.004312  0.154837  0.853498  0.003269    1.0  0.239867    0.0   \n",
       "3   NaN  1.002538  0.153939  0.844667  0.000053    1.0  0.240910    0.0   \n",
       "4   NaN  1.000130  0.120717  0.811199  0.008724    1.0  0.247939    0.0   \n",
       "\n",
       "   D_117     D_118     D_119  D_120     D_121     D_122     D_123     D_124  \\\n",
       "0    4.0  0.232120  0.236266    0.0  0.702280  0.434345  0.003057  0.686516   \n",
       "1    4.0  0.243532  0.241885    0.0  0.707017  0.430501  0.001306  0.686414   \n",
       "2    4.0  0.240768  0.239710    0.0  0.704843  0.434409  0.003954  0.690101   \n",
       "3    4.0  0.239400  0.240727    0.0  0.711546  0.436903  0.005135  0.687779   \n",
       "4    4.0  0.244199  0.242325    0.0  0.705343  0.437433  0.002849  0.688774   \n",
       "\n",
       "      D_125  D_126     D_127     D_128     D_129      B_41  B_42     D_130  \\\n",
       "0  0.008740    1.0  1.003319  1.007819  1.000080  0.006805   NaN  0.002052   \n",
       "1  0.000755    1.0  1.008394  1.004333  1.008344  0.004407   NaN  0.001034   \n",
       "2  0.009617    1.0  1.009307  1.007831  1.006878  0.003221   NaN  0.005681   \n",
       "3  0.004649    1.0  1.001671  1.003460  1.007573  0.007703   NaN  0.007108   \n",
       "4  0.000097    1.0  1.009886  1.005053  1.008132  0.009823   NaN  0.009680   \n",
       "\n",
       "      D_131  D_132     D_133      R_28  D_134  D_135  D_136  D_137  D_138  \\\n",
       "0  0.005972    NaN  0.004345  0.001535    NaN    NaN    NaN    NaN    NaN   \n",
       "1  0.004838    NaN  0.007495  0.004931    NaN    NaN    NaN    NaN    NaN   \n",
       "2  0.005497    NaN  0.009227  0.009123    NaN    NaN    NaN    NaN    NaN   \n",
       "3  0.008261    NaN  0.007206  0.002409    NaN    NaN    NaN    NaN    NaN   \n",
       "4  0.004848    NaN  0.006312  0.004462    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "      D_139     D_140     D_141  D_142     D_143     D_144     D_145  \n",
       "0  0.002427  0.003706  0.003818    NaN  0.000569  0.000610  0.002674  \n",
       "1  0.003954  0.003167  0.005032    NaN  0.009576  0.005492  0.009217  \n",
       "2  0.003269  0.007329  0.000427    NaN  0.003429  0.006986  0.002603  \n",
       "3  0.006117  0.004516  0.003200    NaN  0.008419  0.006527  0.009600  \n",
       "4  0.003671  0.004946  0.008889    NaN  0.001670  0.008126  0.009827  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_data.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  target\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...       0\n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...       0\n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...       0\n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...       0\n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...       0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"train_labels.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['S_2'] = pd.to_datetime(train['S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_49</th>\n",
       "      <th>B_6</th>\n",
       "      <th>B_7</th>\n",
       "      <th>B_8</th>\n",
       "      <th>D_50</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>D_52</th>\n",
       "      <th>P_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>D_53</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>D_54</th>\n",
       "      <th>R_4</th>\n",
       "      <th>S_7</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>D_55</th>\n",
       "      <th>D_56</th>\n",
       "      <th>B_13</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>S_9</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_59</th>\n",
       "      <th>D_60</th>\n",
       "      <th>D_61</th>\n",
       "      <th>B_15</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_63</th>\n",
       "      <th>D_64</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_17</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>D_66</th>\n",
       "      <th>B_20</th>\n",
       "      <th>D_68</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_69</th>\n",
       "      <th>B_22</th>\n",
       "      <th>D_70</th>\n",
       "      <th>D_71</th>\n",
       "      <th>D_72</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>D_73</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_74</th>\n",
       "      <th>D_75</th>\n",
       "      <th>D_76</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>D_77</th>\n",
       "      <th>B_25</th>\n",
       "      <th>B_26</th>\n",
       "      <th>D_78</th>\n",
       "      <th>D_79</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>S_16</th>\n",
       "      <th>D_80</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>B_27</th>\n",
       "      <th>D_81</th>\n",
       "      <th>D_82</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>D_83</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>D_84</th>\n",
       "      <th>R_16</th>\n",
       "      <th>B_29</th>\n",
       "      <th>B_30</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>D_87</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>D_88</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>B_33</th>\n",
       "      <th>D_89</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_91</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>D_103</th>\n",
       "      <th>D_104</th>\n",
       "      <th>D_105</th>\n",
       "      <th>D_106</th>\n",
       "      <th>D_107</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_108</th>\n",
       "      <th>D_109</th>\n",
       "      <th>D_110</th>\n",
       "      <th>D_111</th>\n",
       "      <th>B_39</th>\n",
       "      <th>D_112</th>\n",
       "      <th>B_40</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_113</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_115</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_118</th>\n",
       "      <th>D_119</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_121</th>\n",
       "      <th>D_122</th>\n",
       "      <th>D_123</th>\n",
       "      <th>D_124</th>\n",
       "      <th>D_125</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_127</th>\n",
       "      <th>D_128</th>\n",
       "      <th>D_129</th>\n",
       "      <th>B_41</th>\n",
       "      <th>B_42</th>\n",
       "      <th>D_130</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_132</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_134</th>\n",
       "      <th>D_135</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.008771</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.080986</td>\n",
       "      <td>0.708906</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.358587</td>\n",
       "      <td>0.525351</td>\n",
       "      <td>0.255736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.059416</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.148698</td>\n",
       "      <td>1.335856</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.207334</td>\n",
       "      <td>0.736463</td>\n",
       "      <td>0.096219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>1.001519</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.161345</td>\n",
       "      <td>0.148266</td>\n",
       "      <td>0.922998</td>\n",
       "      <td>0.354596</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.118075</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.158612</td>\n",
       "      <td>0.065728</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.063646</td>\n",
       "      <td>0.199617</td>\n",
       "      <td>0.308233</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.401619</td>\n",
       "      <td>0.091071</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652984</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.272008</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.108271</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.080422</td>\n",
       "      <td>0.069067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.506612</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>1.009825</td>\n",
       "      <td>0.084683</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>1.001101</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>1.503673</td>\n",
       "      <td>1.006133</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.894090</td>\n",
       "      <td>0.135561</td>\n",
       "      <td>0.911191</td>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.766688</td>\n",
       "      <td>1.008691</td>\n",
       "      <td>1.004587</td>\n",
       "      <td>0.893734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670041</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007336</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>0.676922</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.238250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.232120</td>\n",
       "      <td>0.236266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702280</td>\n",
       "      <td>0.434345</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.686516</td>\n",
       "      <td>0.008740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003319</td>\n",
       "      <td>1.007819</td>\n",
       "      <td>1.000080</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.712795</td>\n",
       "      <td>0.113239</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.353630</td>\n",
       "      <td>0.521311</td>\n",
       "      <td>0.223329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065261</td>\n",
       "      <td>0.057744</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.149723</td>\n",
       "      <td>1.339794</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.202778</td>\n",
       "      <td>0.720886</td>\n",
       "      <td>0.099804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030599</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>1.009033</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.140951</td>\n",
       "      <td>0.143530</td>\n",
       "      <td>0.919414</td>\n",
       "      <td>0.326757</td>\n",
       "      <td>0.156201</td>\n",
       "      <td>0.118737</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.148459</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.065501</td>\n",
       "      <td>0.151387</td>\n",
       "      <td>0.265026</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>0.406326</td>\n",
       "      <td>0.086805</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647093</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.188970</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.509048</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.140611</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>0.040469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.081413</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.500855</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>1.009461</td>\n",
       "      <td>0.081843</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.006779</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>1.503577</td>\n",
       "      <td>1.005791</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.902135</td>\n",
       "      <td>0.136333</td>\n",
       "      <td>0.919876</td>\n",
       "      <td>0.975624</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.786007</td>\n",
       "      <td>1.000084</td>\n",
       "      <td>1.004118</td>\n",
       "      <td>0.906841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668647</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003205</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007653</td>\n",
       "      <td>0.184093</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.247217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.243532</td>\n",
       "      <td>0.241885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707017</td>\n",
       "      <td>0.430501</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.686414</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.008394</td>\n",
       "      <td>1.004333</td>\n",
       "      <td>1.008344</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007495</td>\n",
       "      <td>0.004931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.068839</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.060492</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.334650</td>\n",
       "      <td>0.524568</td>\n",
       "      <td>0.189424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.151955</td>\n",
       "      <td>1.337179</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.206629</td>\n",
       "      <td>0.738044</td>\n",
       "      <td>0.134073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048367</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>1.009184</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>0.112229</td>\n",
       "      <td>0.137014</td>\n",
       "      <td>1.001977</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>0.153795</td>\n",
       "      <td>0.114534</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>0.139504</td>\n",
       "      <td>0.084757</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>0.070607</td>\n",
       "      <td>0.305883</td>\n",
       "      <td>0.212165</td>\n",
       "      <td>0.063955</td>\n",
       "      <td>0.406768</td>\n",
       "      <td>0.094001</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645819</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.495308</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.075868</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.103239</td>\n",
       "      <td>0.047454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.078891</td>\n",
       "      <td>0.076510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.504606</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>1.004291</td>\n",
       "      <td>0.081954</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>1.001014</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>1.503359</td>\n",
       "      <td>1.005801</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.939654</td>\n",
       "      <td>0.134938</td>\n",
       "      <td>0.958699</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.806840</td>\n",
       "      <td>1.003014</td>\n",
       "      <td>1.009285</td>\n",
       "      <td>0.928719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670901</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004312</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.853498</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.239867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.240768</td>\n",
       "      <td>0.239710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704843</td>\n",
       "      <td>0.434409</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.690101</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.009307</td>\n",
       "      <td>1.007831</td>\n",
       "      <td>1.006878</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.323271</td>\n",
       "      <td>0.530929</td>\n",
       "      <td>0.135586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083720</td>\n",
       "      <td>0.049253</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.151219</td>\n",
       "      <td>1.339909</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.208214</td>\n",
       "      <td>0.741813</td>\n",
       "      <td>0.134437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>1.007456</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.102838</td>\n",
       "      <td>0.129017</td>\n",
       "      <td>0.704016</td>\n",
       "      <td>0.275055</td>\n",
       "      <td>0.155772</td>\n",
       "      <td>0.120740</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.048382</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.065926</td>\n",
       "      <td>0.273553</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.022732</td>\n",
       "      <td>0.405175</td>\n",
       "      <td>0.094854</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654358</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.508670</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.515282</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.150209</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.206394</td>\n",
       "      <td>0.031705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.077490</td>\n",
       "      <td>0.071547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.508998</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>1.004728</td>\n",
       "      <td>0.060634</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>1.002775</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>1.503701</td>\n",
       "      <td>1.007036</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.913205</td>\n",
       "      <td>0.140058</td>\n",
       "      <td>0.926341</td>\n",
       "      <td>0.975499</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>0.808214</td>\n",
       "      <td>1.001517</td>\n",
       "      <td>1.004514</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672620</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005338</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002538</td>\n",
       "      <td>0.153939</td>\n",
       "      <td>0.844667</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.240910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.240727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.711546</td>\n",
       "      <td>0.436903</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.687779</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.001671</td>\n",
       "      <td>1.003460</td>\n",
       "      <td>1.007573</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.038862</td>\n",
       "      <td>0.720619</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>0.529305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.154026</td>\n",
       "      <td>1.341735</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.205468</td>\n",
       "      <td>0.691986</td>\n",
       "      <td>0.121518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054221</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>1.003738</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.094311</td>\n",
       "      <td>0.129539</td>\n",
       "      <td>0.917133</td>\n",
       "      <td>0.231110</td>\n",
       "      <td>0.154914</td>\n",
       "      <td>0.095178</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.126443</td>\n",
       "      <td>0.039259</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.233103</td>\n",
       "      <td>0.175655</td>\n",
       "      <td>0.031171</td>\n",
       "      <td>0.487460</td>\n",
       "      <td>0.093915</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650112</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.216507</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.507712</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.096441</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.076561</td>\n",
       "      <td>0.074432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.506213</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>1.006536</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>1.509905</td>\n",
       "      <td>1.002915</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.131620</td>\n",
       "      <td>0.933479</td>\n",
       "      <td>0.978027</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.005735</td>\n",
       "      <td>0.953363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673869</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003175</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.811199</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.247939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.244199</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705343</td>\n",
       "      <td>0.437433</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.688774</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.009886</td>\n",
       "      <td>1.005053</td>\n",
       "      <td>1.008132</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID        S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-03-09  0.938469   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-04-07  0.936665   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-05-28  0.954180   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-06-13  0.960384   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-07-16  0.947248   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  D_42  \\\n",
       "0  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771  0.004709   NaN   \n",
       "1  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798  0.002714   NaN   \n",
       "2  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598  0.009423   NaN   \n",
       "3  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685  0.005531   NaN   \n",
       "4  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653  0.009312   NaN   \n",
       "\n",
       "   D_43      D_44       B_4      D_45       B_5       R_2      D_46      D_47  \\\n",
       "0   NaN  0.000630  0.080986  0.708906  0.170600  0.006204  0.358587  0.525351   \n",
       "1   NaN  0.002526  0.069419  0.712795  0.113239  0.006206  0.353630  0.521311   \n",
       "2   NaN  0.007605  0.068839  0.720884  0.060492  0.003259  0.334650  0.524568   \n",
       "3   NaN  0.006406  0.055630  0.723997  0.166782  0.009918  0.323271  0.530929   \n",
       "4   NaN  0.007731  0.038862  0.720619  0.143630  0.006667  0.231009  0.529305   \n",
       "\n",
       "       D_48  D_49       B_6       B_7       B_8      D_50      D_51       B_9  \\\n",
       "0  0.255736   NaN  0.063902  0.059416  0.006466  0.148698  1.335856  0.008207   \n",
       "1  0.223329   NaN  0.065261  0.057744  0.001614  0.149723  1.339794  0.008373   \n",
       "2  0.189424   NaN  0.066982  0.056647  0.005126  0.151955  1.337179  0.009355   \n",
       "3  0.135586   NaN  0.083720  0.049253  0.001418  0.151219  1.339909  0.006782   \n",
       "4       NaN   NaN  0.075900  0.048918  0.001199  0.154026  1.341735  0.000519   \n",
       "\n",
       "        R_3      D_52       P_3      B_10  D_53       S_5      B_11       S_6  \\\n",
       "0  0.001423  0.207334  0.736463  0.096219   NaN  0.023381  0.002768  0.008322   \n",
       "1  0.001984  0.202778  0.720886  0.099804   NaN  0.030599  0.002749  0.002482   \n",
       "2  0.007426  0.206629  0.738044  0.134073   NaN  0.048367  0.010077  0.000530   \n",
       "3  0.003515  0.208214  0.741813  0.134437   NaN  0.030063  0.009667  0.000783   \n",
       "4  0.001362  0.205468  0.691986  0.121518   NaN  0.054221  0.009484  0.006698   \n",
       "\n",
       "       D_54       R_4       S_7      B_12       S_8      D_55      D_56  \\\n",
       "0  1.001519  0.008298  0.161345  0.148266  0.922998  0.354596  0.152025   \n",
       "1  1.009033  0.005136  0.140951  0.143530  0.919414  0.326757  0.156201   \n",
       "2  1.009184  0.006961  0.112229  0.137014  1.001977  0.304124  0.153795   \n",
       "3  1.007456  0.008706  0.102838  0.129017  0.704016  0.275055  0.155772   \n",
       "4  1.003738  0.003846  0.094311  0.129539  0.917133  0.231110  0.154914   \n",
       "\n",
       "       B_13       R_5      D_58       S_9      B_14      D_59      D_60  \\\n",
       "0  0.118075  0.001882  0.158612  0.065728  0.018385  0.063646  0.199617   \n",
       "1  0.118737  0.001610  0.148459  0.093935  0.013035  0.065501  0.151387   \n",
       "2  0.114534  0.006328  0.139504  0.084757  0.056653  0.070607  0.305883   \n",
       "3  0.120740  0.004980  0.138100  0.048382  0.012498  0.065926  0.273553   \n",
       "4  0.095178  0.001653  0.126443  0.039259  0.027897  0.063697  0.233103   \n",
       "\n",
       "       D_61      B_15      S_11      D_62 D_63 D_64      D_65      B_16  B_17  \\\n",
       "0  0.308233  0.016361  0.401619  0.091071   CR    O  0.007126  0.007665   NaN   \n",
       "1  0.265026  0.017688  0.406326  0.086805   CR    O  0.002413  0.007148   NaN   \n",
       "2  0.212165  0.063955  0.406768  0.094001   CR    O  0.001878  0.003636   NaN   \n",
       "3  0.204300  0.022732  0.405175  0.094854   CR    O  0.005899  0.005896   NaN   \n",
       "4  0.175655  0.031171  0.487460  0.093915   CR    O  0.009479  0.001714   NaN   \n",
       "\n",
       "       B_18      B_19  D_66      B_20  D_68      S_12       R_6      S_13  \\\n",
       "0  0.652984  0.008520   NaN  0.004730   6.0  0.272008  0.008363  0.515222   \n",
       "1  0.647093  0.002238   NaN  0.003879   6.0  0.188970  0.004030  0.509048   \n",
       "2  0.645819  0.000408   NaN  0.004578   6.0  0.495308  0.006838  0.679257   \n",
       "3  0.654358  0.005897   NaN  0.005207   6.0  0.508670  0.008183  0.515282   \n",
       "4  0.650112  0.007773   NaN  0.005851   6.0  0.216507  0.008605  0.507712   \n",
       "\n",
       "       B_21      D_69      B_22      D_70      D_71      D_72      S_15  \\\n",
       "0  0.002644  0.009013  0.004808  0.008342  0.119403  0.004802  0.108271   \n",
       "1  0.004193  0.007842  0.001283  0.006524  0.140611  0.000094  0.101018   \n",
       "2  0.001337  0.006025  0.009393  0.002615  0.075868  0.007152  0.103239   \n",
       "3  0.008716  0.005271  0.004554  0.002052  0.150209  0.005364  0.206394   \n",
       "4  0.006821  0.000152  0.000104  0.001419  0.096441  0.007972  0.106020   \n",
       "\n",
       "       B_23  D_73       P_4      D_74      D_75  D_76      B_24       R_7  \\\n",
       "0  0.050882   NaN  0.007554  0.080422  0.069067   NaN  0.004327  0.007562   \n",
       "1  0.040469   NaN  0.004832  0.081413  0.074166   NaN  0.004203  0.005304   \n",
       "2  0.047454   NaN  0.006561  0.078891  0.076510   NaN  0.001782  0.001422   \n",
       "3  0.031705   NaN  0.009559  0.077490  0.071547   NaN  0.005595  0.006363   \n",
       "4  0.032733   NaN  0.008156  0.076561  0.074432   NaN  0.004933  0.004831   \n",
       "\n",
       "   D_77      B_25      B_26      D_78      D_79       R_8  R_9      S_16  \\\n",
       "0   NaN  0.007729  0.000272  0.001576  0.004239  0.001434  NaN  0.002271   \n",
       "1   NaN  0.001864  0.000979  0.009896  0.007597  0.000509  NaN  0.009810   \n",
       "2   NaN  0.005419  0.006149  0.009629  0.003094  0.008295  NaN  0.009362   \n",
       "3   NaN  0.000646  0.009193  0.008568  0.003895  0.005153  NaN  0.004876   \n",
       "4   NaN  0.001833  0.005738  0.003289  0.002608  0.007338  NaN  0.007447   \n",
       "\n",
       "       D_80      R_10      R_11      B_27      D_81      D_82      S_17  \\\n",
       "0  0.004061  0.007121  0.002456  0.002310  0.003532  0.506612  0.008033   \n",
       "1  0.000127  0.005966  0.000395  0.001327  0.007773  0.500855  0.000760   \n",
       "2  0.000954  0.005447  0.007345  0.007624  0.008811  0.504606  0.004056   \n",
       "3  0.005665  0.001888  0.004961  0.000034  0.004652  0.508998  0.006969   \n",
       "4  0.004465  0.006111  0.002246  0.002109  0.001141  0.506213  0.001770   \n",
       "\n",
       "       R_12      B_28      R_13      D_83      R_14      R_15      D_84  \\\n",
       "0  1.009825  0.084683  0.003820  0.007043  0.000438  0.006452  0.000830   \n",
       "1  1.009461  0.081843  0.000347  0.007789  0.004311  0.002332  0.009469   \n",
       "2  1.004291  0.081954  0.002709  0.004093  0.007139  0.008358  0.002325   \n",
       "3  1.004728  0.060634  0.009982  0.008817  0.008690  0.007364  0.005924   \n",
       "4  1.000904  0.062492  0.005860  0.001845  0.007816  0.002470  0.005516   \n",
       "\n",
       "       R_16  B_29  B_30      S_18      D_86  D_87      R_17      R_18  D_88  \\\n",
       "0  0.005055   NaN   0.0  0.005720  0.007084   NaN  0.000198  0.008907   NaN   \n",
       "1  0.003753   NaN   0.0  0.007584  0.006677   NaN  0.001142  0.005907   NaN   \n",
       "2  0.007381   NaN   0.0  0.005901  0.001185   NaN  0.008013  0.008882   NaN   \n",
       "3  0.008802   NaN   0.0  0.002520  0.003324   NaN  0.009455  0.008348   NaN   \n",
       "4  0.007166   NaN   0.0  0.000155  0.001504   NaN  0.002019  0.002678   NaN   \n",
       "\n",
       "   B_31      S_19      R_19      B_32      S_20      R_20      R_21      B_33  \\\n",
       "0     1  0.002537  0.005177  0.006626  0.009705  0.007782  0.002450  1.001101   \n",
       "1     1  0.008427  0.008979  0.001854  0.009924  0.005987  0.002247  1.006779   \n",
       "2     1  0.007327  0.002016  0.008686  0.008446  0.007291  0.007794  1.001014   \n",
       "3     1  0.007053  0.003909  0.002478  0.006614  0.009977  0.007686  1.002775   \n",
       "4     1  0.007728  0.003432  0.002199  0.005511  0.004105  0.009656  1.006536   \n",
       "\n",
       "       D_89      R_22      R_23      D_91      D_92      D_93      D_94  \\\n",
       "0  0.002665  0.007479  0.006893  1.503673  1.006133  0.003569  0.008871   \n",
       "1  0.002508  0.006827  0.002837  1.503577  1.005791  0.000571  0.000391   \n",
       "2  0.009634  0.009820  0.005080  1.503359  1.005801  0.007425  0.009234   \n",
       "3  0.007791  0.000458  0.007320  1.503701  1.007036  0.000664  0.003200   \n",
       "4  0.005158  0.003341  0.000264  1.509905  1.002915  0.003079  0.003845   \n",
       "\n",
       "       R_24      R_25      D_96      S_22      S_23      S_24      S_25  \\\n",
       "0  0.003950  0.003647  0.004950  0.894090  0.135561  0.911191  0.974539   \n",
       "1  0.008351  0.008850  0.003180  0.902135  0.136333  0.919876  0.975624   \n",
       "2  0.002471  0.009769  0.005433  0.939654  0.134938  0.958699  0.974067   \n",
       "3  0.008507  0.004858  0.000063  0.913205  0.140058  0.926341  0.975499   \n",
       "4  0.007190  0.002983  0.000535  0.921026  0.131620  0.933479  0.978027   \n",
       "\n",
       "       S_26     D_102     D_103     D_104     D_105  D_106     D_107  \\\n",
       "0  0.001243  0.766688  1.008691  1.004587  0.893734    NaN  0.670041   \n",
       "1  0.004561  0.786007  1.000084  1.004118  0.906841    NaN  0.668647   \n",
       "2  0.011736  0.806840  1.003014  1.009285  0.928719    NaN  0.670901   \n",
       "3  0.007571  0.808214  1.001517  1.004514  0.935383    NaN  0.672620   \n",
       "4  0.018200  0.822281  1.006125  1.005735  0.953363    NaN  0.673869   \n",
       "\n",
       "       B_36      B_37  R_26      R_27  B_38  D_108     D_109  D_110  D_111  \\\n",
       "0  0.009968  0.004572   NaN  1.008949   2.0    NaN  0.004326    NaN    NaN   \n",
       "1  0.003921  0.004654   NaN  1.003205   2.0    NaN  0.008707    NaN    NaN   \n",
       "2  0.001264  0.019176   NaN  1.000754   2.0    NaN  0.004092    NaN    NaN   \n",
       "3  0.002729  0.011720   NaN  1.005338   2.0    NaN  0.009703    NaN    NaN   \n",
       "4  0.009998  0.017598   NaN  1.003175   2.0    NaN  0.009120    NaN    NaN   \n",
       "\n",
       "   B_39     D_112      B_40      S_27     D_113  D_114     D_115  D_116  \\\n",
       "0   NaN  1.007336  0.210060  0.676922  0.007871    1.0  0.238250    0.0   \n",
       "1   NaN  1.007653  0.184093  0.822281  0.003444    1.0  0.247217    0.0   \n",
       "2   NaN  1.004312  0.154837  0.853498  0.003269    1.0  0.239867    0.0   \n",
       "3   NaN  1.002538  0.153939  0.844667  0.000053    1.0  0.240910    0.0   \n",
       "4   NaN  1.000130  0.120717  0.811199  0.008724    1.0  0.247939    0.0   \n",
       "\n",
       "   D_117     D_118     D_119  D_120     D_121     D_122     D_123     D_124  \\\n",
       "0    4.0  0.232120  0.236266    0.0  0.702280  0.434345  0.003057  0.686516   \n",
       "1    4.0  0.243532  0.241885    0.0  0.707017  0.430501  0.001306  0.686414   \n",
       "2    4.0  0.240768  0.239710    0.0  0.704843  0.434409  0.003954  0.690101   \n",
       "3    4.0  0.239400  0.240727    0.0  0.711546  0.436903  0.005135  0.687779   \n",
       "4    4.0  0.244199  0.242325    0.0  0.705343  0.437433  0.002849  0.688774   \n",
       "\n",
       "      D_125  D_126     D_127     D_128     D_129      B_41  B_42     D_130  \\\n",
       "0  0.008740    1.0  1.003319  1.007819  1.000080  0.006805   NaN  0.002052   \n",
       "1  0.000755    1.0  1.008394  1.004333  1.008344  0.004407   NaN  0.001034   \n",
       "2  0.009617    1.0  1.009307  1.007831  1.006878  0.003221   NaN  0.005681   \n",
       "3  0.004649    1.0  1.001671  1.003460  1.007573  0.007703   NaN  0.007108   \n",
       "4  0.000097    1.0  1.009886  1.005053  1.008132  0.009823   NaN  0.009680   \n",
       "\n",
       "      D_131  D_132     D_133      R_28  D_134  D_135  D_136  D_137  D_138  \\\n",
       "0  0.005972    NaN  0.004345  0.001535    NaN    NaN    NaN    NaN    NaN   \n",
       "1  0.004838    NaN  0.007495  0.004931    NaN    NaN    NaN    NaN    NaN   \n",
       "2  0.005497    NaN  0.009227  0.009123    NaN    NaN    NaN    NaN    NaN   \n",
       "3  0.008261    NaN  0.007206  0.002409    NaN    NaN    NaN    NaN    NaN   \n",
       "4  0.004848    NaN  0.006312  0.004462    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "      D_139     D_140     D_141  D_142     D_143     D_144     D_145  target  \n",
       "0  0.002427  0.003706  0.003818    NaN  0.000569  0.000610  0.002674       0  \n",
       "1  0.003954  0.003167  0.005032    NaN  0.009576  0.005492  0.009217       0  \n",
       "2  0.003269  0.007329  0.000427    NaN  0.003429  0.006986  0.002603       0  \n",
       "3  0.006117  0.004516  0.003200    NaN  0.008419  0.006527  0.009600       0  \n",
       "4  0.003671  0.004946  0.008889    NaN  0.001670  0.008126  0.009827       0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(train, labels, on = 'customer_ID', how = 'left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 191)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458913"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['customer_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 191)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['customer_ID'] == df.iloc[1,0], :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.053376130116165"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5531451/458913"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Selecting 1 month of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min : 2017-03-01 00:00:00 Max:  2018-03-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(458913, 191)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df12 = df.sample(frac=1, random_state = 21)  #shuffling the data\n",
    "df1 = df12.groupby('customer_ID',as_index=False).first()\n",
    "print(\"Min :\", df1['S_2'].min(), \"Max: \", df1['S_2'].max())\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_49</th>\n",
       "      <th>B_6</th>\n",
       "      <th>B_7</th>\n",
       "      <th>B_8</th>\n",
       "      <th>D_50</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>D_52</th>\n",
       "      <th>P_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>D_53</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>D_54</th>\n",
       "      <th>R_4</th>\n",
       "      <th>S_7</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>D_55</th>\n",
       "      <th>D_56</th>\n",
       "      <th>B_13</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>S_9</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_59</th>\n",
       "      <th>D_60</th>\n",
       "      <th>D_61</th>\n",
       "      <th>B_15</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_63</th>\n",
       "      <th>D_64</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_17</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>D_66</th>\n",
       "      <th>B_20</th>\n",
       "      <th>D_68</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_69</th>\n",
       "      <th>B_22</th>\n",
       "      <th>D_70</th>\n",
       "      <th>D_71</th>\n",
       "      <th>D_72</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>D_73</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_74</th>\n",
       "      <th>D_75</th>\n",
       "      <th>D_76</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>D_77</th>\n",
       "      <th>B_25</th>\n",
       "      <th>B_26</th>\n",
       "      <th>D_78</th>\n",
       "      <th>D_79</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>S_16</th>\n",
       "      <th>D_80</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>B_27</th>\n",
       "      <th>D_81</th>\n",
       "      <th>D_82</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>D_83</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>D_84</th>\n",
       "      <th>R_16</th>\n",
       "      <th>B_29</th>\n",
       "      <th>B_30</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>D_87</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>D_88</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>B_33</th>\n",
       "      <th>D_89</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_91</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>D_103</th>\n",
       "      <th>D_104</th>\n",
       "      <th>D_105</th>\n",
       "      <th>D_106</th>\n",
       "      <th>D_107</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_108</th>\n",
       "      <th>D_109</th>\n",
       "      <th>D_110</th>\n",
       "      <th>D_111</th>\n",
       "      <th>B_39</th>\n",
       "      <th>D_112</th>\n",
       "      <th>B_40</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_113</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_115</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_118</th>\n",
       "      <th>D_119</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_121</th>\n",
       "      <th>D_122</th>\n",
       "      <th>D_123</th>\n",
       "      <th>D_124</th>\n",
       "      <th>D_125</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_127</th>\n",
       "      <th>D_128</th>\n",
       "      <th>D_129</th>\n",
       "      <th>B_41</th>\n",
       "      <th>B_42</th>\n",
       "      <th>D_130</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_132</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_134</th>\n",
       "      <th>D_135</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>30730</td>\n",
       "      <td>30600</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>26787</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>4606</td>\n",
       "      <td>24965</td>\n",
       "      <td>29565</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>26658</td>\n",
       "      <td>30730</td>\n",
       "      <td>28845</td>\n",
       "      <td>3931</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30715</td>\n",
       "      <td>14705</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30676</td>\n",
       "      <td>30599</td>\n",
       "      <td>30730</td>\n",
       "      <td>10143</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>26787</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30674</td>\n",
       "      <td>17489</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>20853</td>\n",
       "      <td>30730</td>\n",
       "      <td>30680</td>\n",
       "      <td>30730</td>\n",
       "      <td>29206</td>\n",
       "      <td>30687</td>\n",
       "      <td>30730</td>\n",
       "      <td>28822</td>\n",
       "      <td>30730</td>\n",
       "      <td>30724</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>17104</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>4156</td>\n",
       "      <td>30730</td>\n",
       "      <td>30724</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30724</td>\n",
       "      <td>30730</td>\n",
       "      <td>30639</td>\n",
       "      <td>30730</td>\n",
       "      <td>30676</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>325</td>\n",
       "      <td>30730</td>\n",
       "      <td>30641</td>\n",
       "      <td>30730</td>\n",
       "      <td>4108</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>24320</td>\n",
       "      <td>30687</td>\n",
       "      <td>30730</td>\n",
       "      <td>29565</td>\n",
       "      <td>30631</td>\n",
       "      <td>30730</td>\n",
       "      <td>2442</td>\n",
       "      <td>30730</td>\n",
       "      <td>30641</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30694</td>\n",
       "      <td>9038</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30724</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30676</td>\n",
       "      <td>30730</td>\n",
       "      <td>2655</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>59</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>170</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30676</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30695</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30729</td>\n",
       "      <td>30730</td>\n",
       "      <td>30729</td>\n",
       "      <td>30726</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30631</td>\n",
       "      <td>30631</td>\n",
       "      <td>15821</td>\n",
       "      <td>3925</td>\n",
       "      <td>30631</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>3268</td>\n",
       "      <td>30329</td>\n",
       "      <td>30730</td>\n",
       "      <td>1383</td>\n",
       "      <td>30730</td>\n",
       "      <td>344</td>\n",
       "      <td>344</td>\n",
       "      <td>345</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>26216</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>30631</td>\n",
       "      <td>30631</td>\n",
       "      <td>30730</td>\n",
       "      <td>482</td>\n",
       "      <td>30631</td>\n",
       "      <td>30631</td>\n",
       "      <td>3931</td>\n",
       "      <td>30730</td>\n",
       "      <td>30730</td>\n",
       "      <td>2270</td>\n",
       "      <td>2270</td>\n",
       "      <td>2270</td>\n",
       "      <td>2270</td>\n",
       "      <td>2270</td>\n",
       "      <td>30631</td>\n",
       "      <td>30730</td>\n",
       "      <td>30631</td>\n",
       "      <td>5477</td>\n",
       "      <td>30631</td>\n",
       "      <td>30730</td>\n",
       "      <td>30631</td>\n",
       "      <td>30730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-30</th>\n",
       "      <td>31233</td>\n",
       "      <td>31097</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>27205</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>4907</td>\n",
       "      <td>25305</td>\n",
       "      <td>30024</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>26900</td>\n",
       "      <td>31233</td>\n",
       "      <td>29248</td>\n",
       "      <td>3970</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31216</td>\n",
       "      <td>14866</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31175</td>\n",
       "      <td>31106</td>\n",
       "      <td>31233</td>\n",
       "      <td>10274</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>27205</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31167</td>\n",
       "      <td>17580</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>21162</td>\n",
       "      <td>31233</td>\n",
       "      <td>31176</td>\n",
       "      <td>31233</td>\n",
       "      <td>29613</td>\n",
       "      <td>31186</td>\n",
       "      <td>31233</td>\n",
       "      <td>29154</td>\n",
       "      <td>31233</td>\n",
       "      <td>31226</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>17203</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>4159</td>\n",
       "      <td>31233</td>\n",
       "      <td>31226</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31226</td>\n",
       "      <td>31233</td>\n",
       "      <td>31141</td>\n",
       "      <td>31233</td>\n",
       "      <td>31175</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>362</td>\n",
       "      <td>31233</td>\n",
       "      <td>31142</td>\n",
       "      <td>31233</td>\n",
       "      <td>4087</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>24690</td>\n",
       "      <td>31186</td>\n",
       "      <td>31233</td>\n",
       "      <td>30024</td>\n",
       "      <td>31126</td>\n",
       "      <td>31233</td>\n",
       "      <td>2494</td>\n",
       "      <td>31233</td>\n",
       "      <td>31142</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31199</td>\n",
       "      <td>9012</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31226</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31175</td>\n",
       "      <td>31233</td>\n",
       "      <td>2667</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>62</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>154</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31175</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31191</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31232</td>\n",
       "      <td>31233</td>\n",
       "      <td>31232</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31126</td>\n",
       "      <td>31126</td>\n",
       "      <td>16191</td>\n",
       "      <td>3964</td>\n",
       "      <td>31126</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>3281</td>\n",
       "      <td>30830</td>\n",
       "      <td>31233</td>\n",
       "      <td>1457</td>\n",
       "      <td>31233</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>300</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>26683</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>31126</td>\n",
       "      <td>31126</td>\n",
       "      <td>31233</td>\n",
       "      <td>479</td>\n",
       "      <td>31126</td>\n",
       "      <td>31126</td>\n",
       "      <td>3970</td>\n",
       "      <td>31233</td>\n",
       "      <td>31233</td>\n",
       "      <td>2253</td>\n",
       "      <td>2253</td>\n",
       "      <td>2253</td>\n",
       "      <td>2253</td>\n",
       "      <td>2253</td>\n",
       "      <td>31126</td>\n",
       "      <td>31233</td>\n",
       "      <td>31126</td>\n",
       "      <td>5593</td>\n",
       "      <td>31126</td>\n",
       "      <td>31233</td>\n",
       "      <td>31126</td>\n",
       "      <td>31233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>31048</td>\n",
       "      <td>30901</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>27106</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>5182</td>\n",
       "      <td>25095</td>\n",
       "      <td>29842</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>26824</td>\n",
       "      <td>31048</td>\n",
       "      <td>29086</td>\n",
       "      <td>4030</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31029</td>\n",
       "      <td>14811</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>30987</td>\n",
       "      <td>30909</td>\n",
       "      <td>31048</td>\n",
       "      <td>10327</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>27106</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>30976</td>\n",
       "      <td>17402</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>21161</td>\n",
       "      <td>31048</td>\n",
       "      <td>30982</td>\n",
       "      <td>31048</td>\n",
       "      <td>29472</td>\n",
       "      <td>30988</td>\n",
       "      <td>31048</td>\n",
       "      <td>29031</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>17198</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>4171</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>30951</td>\n",
       "      <td>31048</td>\n",
       "      <td>30987</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>374</td>\n",
       "      <td>31048</td>\n",
       "      <td>30952</td>\n",
       "      <td>31048</td>\n",
       "      <td>4071</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>24521</td>\n",
       "      <td>30988</td>\n",
       "      <td>31048</td>\n",
       "      <td>29842</td>\n",
       "      <td>30934</td>\n",
       "      <td>31048</td>\n",
       "      <td>2563</td>\n",
       "      <td>31048</td>\n",
       "      <td>30952</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31009</td>\n",
       "      <td>8944</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>30987</td>\n",
       "      <td>31048</td>\n",
       "      <td>2327</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>67</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>144</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>30987</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31000</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31046</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>30934</td>\n",
       "      <td>30934</td>\n",
       "      <td>16014</td>\n",
       "      <td>4027</td>\n",
       "      <td>30934</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>3381</td>\n",
       "      <td>30637</td>\n",
       "      <td>31048</td>\n",
       "      <td>1431</td>\n",
       "      <td>31048</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "      <td>312</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>26598</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>30934</td>\n",
       "      <td>30934</td>\n",
       "      <td>31048</td>\n",
       "      <td>493</td>\n",
       "      <td>30934</td>\n",
       "      <td>30934</td>\n",
       "      <td>4030</td>\n",
       "      <td>31048</td>\n",
       "      <td>31048</td>\n",
       "      <td>2248</td>\n",
       "      <td>2248</td>\n",
       "      <td>2248</td>\n",
       "      <td>2248</td>\n",
       "      <td>2248</td>\n",
       "      <td>30934</td>\n",
       "      <td>31048</td>\n",
       "      <td>30934</td>\n",
       "      <td>5593</td>\n",
       "      <td>30934</td>\n",
       "      <td>31048</td>\n",
       "      <td>30934</td>\n",
       "      <td>31048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>31815</td>\n",
       "      <td>31683</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>27846</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>5885</td>\n",
       "      <td>25718</td>\n",
       "      <td>30623</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>27520</td>\n",
       "      <td>31815</td>\n",
       "      <td>29881</td>\n",
       "      <td>4187</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31793</td>\n",
       "      <td>14952</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31755</td>\n",
       "      <td>31683</td>\n",
       "      <td>31815</td>\n",
       "      <td>10632</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>27846</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31752</td>\n",
       "      <td>17718</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>21793</td>\n",
       "      <td>31815</td>\n",
       "      <td>31748</td>\n",
       "      <td>31815</td>\n",
       "      <td>30301</td>\n",
       "      <td>31755</td>\n",
       "      <td>31815</td>\n",
       "      <td>29836</td>\n",
       "      <td>31815</td>\n",
       "      <td>31809</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>17763</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>4234</td>\n",
       "      <td>31815</td>\n",
       "      <td>31807</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31812</td>\n",
       "      <td>31815</td>\n",
       "      <td>31732</td>\n",
       "      <td>31815</td>\n",
       "      <td>31755</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>446</td>\n",
       "      <td>31815</td>\n",
       "      <td>31732</td>\n",
       "      <td>31815</td>\n",
       "      <td>4069</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>25212</td>\n",
       "      <td>31755</td>\n",
       "      <td>31815</td>\n",
       "      <td>30623</td>\n",
       "      <td>31714</td>\n",
       "      <td>31815</td>\n",
       "      <td>2801</td>\n",
       "      <td>31815</td>\n",
       "      <td>31732</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31773</td>\n",
       "      <td>9042</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31812</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31755</td>\n",
       "      <td>31815</td>\n",
       "      <td>2557</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>68</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>156</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31755</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31767</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31813</td>\n",
       "      <td>31815</td>\n",
       "      <td>31813</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31713</td>\n",
       "      <td>31713</td>\n",
       "      <td>16558</td>\n",
       "      <td>4181</td>\n",
       "      <td>31713</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>3560</td>\n",
       "      <td>31439</td>\n",
       "      <td>31815</td>\n",
       "      <td>1483</td>\n",
       "      <td>31815</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>27327</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31812</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>31713</td>\n",
       "      <td>31713</td>\n",
       "      <td>31815</td>\n",
       "      <td>505</td>\n",
       "      <td>31713</td>\n",
       "      <td>31713</td>\n",
       "      <td>4187</td>\n",
       "      <td>31815</td>\n",
       "      <td>31815</td>\n",
       "      <td>2423</td>\n",
       "      <td>2423</td>\n",
       "      <td>2423</td>\n",
       "      <td>2423</td>\n",
       "      <td>2423</td>\n",
       "      <td>31713</td>\n",
       "      <td>31815</td>\n",
       "      <td>31713</td>\n",
       "      <td>5938</td>\n",
       "      <td>31713</td>\n",
       "      <td>31815</td>\n",
       "      <td>31713</td>\n",
       "      <td>31815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>32620</td>\n",
       "      <td>32491</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>28477</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>6541</td>\n",
       "      <td>26228</td>\n",
       "      <td>31410</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>28199</td>\n",
       "      <td>32620</td>\n",
       "      <td>30677</td>\n",
       "      <td>4321</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32594</td>\n",
       "      <td>15321</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32548</td>\n",
       "      <td>32486</td>\n",
       "      <td>32620</td>\n",
       "      <td>10505</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>28477</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32547</td>\n",
       "      <td>17996</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>22449</td>\n",
       "      <td>32620</td>\n",
       "      <td>32548</td>\n",
       "      <td>32620</td>\n",
       "      <td>31121</td>\n",
       "      <td>32549</td>\n",
       "      <td>32620</td>\n",
       "      <td>30600</td>\n",
       "      <td>32620</td>\n",
       "      <td>32609</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>17970</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>4366</td>\n",
       "      <td>32620</td>\n",
       "      <td>32609</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32614</td>\n",
       "      <td>32620</td>\n",
       "      <td>32520</td>\n",
       "      <td>32620</td>\n",
       "      <td>32548</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>489</td>\n",
       "      <td>32620</td>\n",
       "      <td>32522</td>\n",
       "      <td>32620</td>\n",
       "      <td>4049</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>26044</td>\n",
       "      <td>32549</td>\n",
       "      <td>32620</td>\n",
       "      <td>31410</td>\n",
       "      <td>32501</td>\n",
       "      <td>32620</td>\n",
       "      <td>2769</td>\n",
       "      <td>32620</td>\n",
       "      <td>32522</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32576</td>\n",
       "      <td>9192</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32614</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32548</td>\n",
       "      <td>32620</td>\n",
       "      <td>2608</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>60</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>203</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32548</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32566</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32617</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32501</td>\n",
       "      <td>32501</td>\n",
       "      <td>16889</td>\n",
       "      <td>4312</td>\n",
       "      <td>32501</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>3720</td>\n",
       "      <td>32176</td>\n",
       "      <td>32620</td>\n",
       "      <td>1629</td>\n",
       "      <td>32620</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>27942</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32614</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>32501</td>\n",
       "      <td>32501</td>\n",
       "      <td>32620</td>\n",
       "      <td>431</td>\n",
       "      <td>32501</td>\n",
       "      <td>32501</td>\n",
       "      <td>4319</td>\n",
       "      <td>32620</td>\n",
       "      <td>32620</td>\n",
       "      <td>2453</td>\n",
       "      <td>2453</td>\n",
       "      <td>2453</td>\n",
       "      <td>2453</td>\n",
       "      <td>2453</td>\n",
       "      <td>32501</td>\n",
       "      <td>32620</td>\n",
       "      <td>32501</td>\n",
       "      <td>6049</td>\n",
       "      <td>32501</td>\n",
       "      <td>32620</td>\n",
       "      <td>32501</td>\n",
       "      <td>32620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>33253</td>\n",
       "      <td>33131</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>29175</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>7147</td>\n",
       "      <td>26644</td>\n",
       "      <td>32039</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>28736</td>\n",
       "      <td>33253</td>\n",
       "      <td>31272</td>\n",
       "      <td>4480</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33239</td>\n",
       "      <td>15530</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33190</td>\n",
       "      <td>33125</td>\n",
       "      <td>33253</td>\n",
       "      <td>10861</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>29175</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33191</td>\n",
       "      <td>18210</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>23063</td>\n",
       "      <td>33253</td>\n",
       "      <td>33196</td>\n",
       "      <td>33253</td>\n",
       "      <td>31696</td>\n",
       "      <td>33201</td>\n",
       "      <td>33253</td>\n",
       "      <td>31214</td>\n",
       "      <td>33253</td>\n",
       "      <td>33235</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>18362</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>4382</td>\n",
       "      <td>33253</td>\n",
       "      <td>33237</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33247</td>\n",
       "      <td>33253</td>\n",
       "      <td>33162</td>\n",
       "      <td>33253</td>\n",
       "      <td>33190</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>523</td>\n",
       "      <td>33253</td>\n",
       "      <td>33165</td>\n",
       "      <td>33253</td>\n",
       "      <td>4130</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>26539</td>\n",
       "      <td>33201</td>\n",
       "      <td>33253</td>\n",
       "      <td>32039</td>\n",
       "      <td>33133</td>\n",
       "      <td>33253</td>\n",
       "      <td>2901</td>\n",
       "      <td>33253</td>\n",
       "      <td>33165</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33213</td>\n",
       "      <td>9393</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33247</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33190</td>\n",
       "      <td>33253</td>\n",
       "      <td>2696</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>70</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>193</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33190</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33214</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33251</td>\n",
       "      <td>33253</td>\n",
       "      <td>33251</td>\n",
       "      <td>33251</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33133</td>\n",
       "      <td>33133</td>\n",
       "      <td>17288</td>\n",
       "      <td>4474</td>\n",
       "      <td>33133</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>3954</td>\n",
       "      <td>32825</td>\n",
       "      <td>33253</td>\n",
       "      <td>1599</td>\n",
       "      <td>33253</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>323</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>28638</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33246</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>33133</td>\n",
       "      <td>33133</td>\n",
       "      <td>33253</td>\n",
       "      <td>473</td>\n",
       "      <td>33133</td>\n",
       "      <td>33133</td>\n",
       "      <td>4480</td>\n",
       "      <td>33253</td>\n",
       "      <td>33253</td>\n",
       "      <td>2620</td>\n",
       "      <td>2620</td>\n",
       "      <td>2620</td>\n",
       "      <td>2620</td>\n",
       "      <td>2620</td>\n",
       "      <td>33133</td>\n",
       "      <td>33253</td>\n",
       "      <td>33133</td>\n",
       "      <td>6244</td>\n",
       "      <td>33133</td>\n",
       "      <td>33253</td>\n",
       "      <td>33133</td>\n",
       "      <td>33253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>33427</td>\n",
       "      <td>33314</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>29398</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>7648</td>\n",
       "      <td>26894</td>\n",
       "      <td>32204</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>28951</td>\n",
       "      <td>33427</td>\n",
       "      <td>31441</td>\n",
       "      <td>4546</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33416</td>\n",
       "      <td>15487</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33384</td>\n",
       "      <td>33303</td>\n",
       "      <td>33427</td>\n",
       "      <td>10955</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>29398</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33381</td>\n",
       "      <td>18067</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>23206</td>\n",
       "      <td>33427</td>\n",
       "      <td>33389</td>\n",
       "      <td>33427</td>\n",
       "      <td>31941</td>\n",
       "      <td>33391</td>\n",
       "      <td>33427</td>\n",
       "      <td>31408</td>\n",
       "      <td>33427</td>\n",
       "      <td>33388</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>18540</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>4446</td>\n",
       "      <td>33427</td>\n",
       "      <td>33390</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33409</td>\n",
       "      <td>33427</td>\n",
       "      <td>33355</td>\n",
       "      <td>33427</td>\n",
       "      <td>33384</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>571</td>\n",
       "      <td>33427</td>\n",
       "      <td>33365</td>\n",
       "      <td>33427</td>\n",
       "      <td>4251</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>26975</td>\n",
       "      <td>33391</td>\n",
       "      <td>33427</td>\n",
       "      <td>32204</td>\n",
       "      <td>33338</td>\n",
       "      <td>33427</td>\n",
       "      <td>2909</td>\n",
       "      <td>33427</td>\n",
       "      <td>33365</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33396</td>\n",
       "      <td>9125</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33409</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33384</td>\n",
       "      <td>33427</td>\n",
       "      <td>2683</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>65</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>173</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33384</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33399</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33426</td>\n",
       "      <td>33427</td>\n",
       "      <td>33426</td>\n",
       "      <td>33425</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33338</td>\n",
       "      <td>33338</td>\n",
       "      <td>17432</td>\n",
       "      <td>4542</td>\n",
       "      <td>33338</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>4025</td>\n",
       "      <td>32987</td>\n",
       "      <td>33427</td>\n",
       "      <td>1548</td>\n",
       "      <td>33427</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>325</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>28864</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33411</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>33338</td>\n",
       "      <td>33338</td>\n",
       "      <td>33427</td>\n",
       "      <td>508</td>\n",
       "      <td>33338</td>\n",
       "      <td>33338</td>\n",
       "      <td>4546</td>\n",
       "      <td>33427</td>\n",
       "      <td>33427</td>\n",
       "      <td>2635</td>\n",
       "      <td>2635</td>\n",
       "      <td>2635</td>\n",
       "      <td>2635</td>\n",
       "      <td>2635</td>\n",
       "      <td>33338</td>\n",
       "      <td>33427</td>\n",
       "      <td>33338</td>\n",
       "      <td>6237</td>\n",
       "      <td>33338</td>\n",
       "      <td>33427</td>\n",
       "      <td>33338</td>\n",
       "      <td>33427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>34439</td>\n",
       "      <td>34294</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>30296</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>8438</td>\n",
       "      <td>27355</td>\n",
       "      <td>33103</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>29708</td>\n",
       "      <td>34439</td>\n",
       "      <td>32338</td>\n",
       "      <td>4724</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34417</td>\n",
       "      <td>15778</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34375</td>\n",
       "      <td>34254</td>\n",
       "      <td>34439</td>\n",
       "      <td>11028</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>30296</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34373</td>\n",
       "      <td>18595</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>23988</td>\n",
       "      <td>34439</td>\n",
       "      <td>34381</td>\n",
       "      <td>34439</td>\n",
       "      <td>32877</td>\n",
       "      <td>34384</td>\n",
       "      <td>34439</td>\n",
       "      <td>32247</td>\n",
       "      <td>34439</td>\n",
       "      <td>34395</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>18707</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>4494</td>\n",
       "      <td>34439</td>\n",
       "      <td>34396</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34425</td>\n",
       "      <td>34439</td>\n",
       "      <td>34337</td>\n",
       "      <td>34439</td>\n",
       "      <td>34375</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>637</td>\n",
       "      <td>34439</td>\n",
       "      <td>34344</td>\n",
       "      <td>34439</td>\n",
       "      <td>4355</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>27811</td>\n",
       "      <td>34384</td>\n",
       "      <td>34439</td>\n",
       "      <td>33103</td>\n",
       "      <td>34322</td>\n",
       "      <td>34439</td>\n",
       "      <td>3029</td>\n",
       "      <td>34439</td>\n",
       "      <td>34344</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34395</td>\n",
       "      <td>9432</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34425</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34375</td>\n",
       "      <td>34439</td>\n",
       "      <td>2678</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>69</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>210</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34375</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34399</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34437</td>\n",
       "      <td>34439</td>\n",
       "      <td>34437</td>\n",
       "      <td>34438</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34322</td>\n",
       "      <td>34322</td>\n",
       "      <td>17864</td>\n",
       "      <td>4718</td>\n",
       "      <td>34322</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>4150</td>\n",
       "      <td>33941</td>\n",
       "      <td>34439</td>\n",
       "      <td>1712</td>\n",
       "      <td>34439</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>29787</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34425</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>34322</td>\n",
       "      <td>34322</td>\n",
       "      <td>34439</td>\n",
       "      <td>486</td>\n",
       "      <td>34322</td>\n",
       "      <td>34322</td>\n",
       "      <td>4724</td>\n",
       "      <td>34439</td>\n",
       "      <td>34439</td>\n",
       "      <td>2746</td>\n",
       "      <td>2746</td>\n",
       "      <td>2746</td>\n",
       "      <td>2746</td>\n",
       "      <td>2746</td>\n",
       "      <td>34322</td>\n",
       "      <td>34439</td>\n",
       "      <td>34322</td>\n",
       "      <td>6416</td>\n",
       "      <td>34322</td>\n",
       "      <td>34439</td>\n",
       "      <td>34322</td>\n",
       "      <td>34439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>35664</td>\n",
       "      <td>35550</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>31552</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>9465</td>\n",
       "      <td>28037</td>\n",
       "      <td>34470</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>30477</td>\n",
       "      <td>35664</td>\n",
       "      <td>33620</td>\n",
       "      <td>4835</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35662</td>\n",
       "      <td>16203</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35643</td>\n",
       "      <td>35224</td>\n",
       "      <td>35664</td>\n",
       "      <td>11380</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>31552</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35645</td>\n",
       "      <td>18809</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>24996</td>\n",
       "      <td>35664</td>\n",
       "      <td>35660</td>\n",
       "      <td>35664</td>\n",
       "      <td>34193</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>33509</td>\n",
       "      <td>35664</td>\n",
       "      <td>35585</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>19466</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>4714</td>\n",
       "      <td>35664</td>\n",
       "      <td>35591</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35643</td>\n",
       "      <td>35664</td>\n",
       "      <td>35604</td>\n",
       "      <td>35664</td>\n",
       "      <td>35643</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>753</td>\n",
       "      <td>35664</td>\n",
       "      <td>35620</td>\n",
       "      <td>35664</td>\n",
       "      <td>4234</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>29005</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>34470</td>\n",
       "      <td>35588</td>\n",
       "      <td>35664</td>\n",
       "      <td>3163</td>\n",
       "      <td>35664</td>\n",
       "      <td>35620</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35647</td>\n",
       "      <td>9593</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35643</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35643</td>\n",
       "      <td>35664</td>\n",
       "      <td>2812</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>59</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>192</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35643</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35527</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35662</td>\n",
       "      <td>35664</td>\n",
       "      <td>35662</td>\n",
       "      <td>35660</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35588</td>\n",
       "      <td>35588</td>\n",
       "      <td>18460</td>\n",
       "      <td>4826</td>\n",
       "      <td>35588</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>4413</td>\n",
       "      <td>35205</td>\n",
       "      <td>35664</td>\n",
       "      <td>1702</td>\n",
       "      <td>35664</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>337</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>30943</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35643</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>35588</td>\n",
       "      <td>35588</td>\n",
       "      <td>35664</td>\n",
       "      <td>494</td>\n",
       "      <td>35588</td>\n",
       "      <td>35588</td>\n",
       "      <td>4835</td>\n",
       "      <td>35664</td>\n",
       "      <td>35664</td>\n",
       "      <td>2871</td>\n",
       "      <td>2871</td>\n",
       "      <td>2871</td>\n",
       "      <td>2871</td>\n",
       "      <td>2871</td>\n",
       "      <td>35588</td>\n",
       "      <td>35664</td>\n",
       "      <td>35588</td>\n",
       "      <td>6738</td>\n",
       "      <td>35588</td>\n",
       "      <td>35664</td>\n",
       "      <td>35588</td>\n",
       "      <td>35664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>36977</td>\n",
       "      <td>36885</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>32729</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>10632</td>\n",
       "      <td>28646</td>\n",
       "      <td>35637</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>30778</td>\n",
       "      <td>36977</td>\n",
       "      <td>34708</td>\n",
       "      <td>5078</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36972</td>\n",
       "      <td>16655</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36967</td>\n",
       "      <td>35710</td>\n",
       "      <td>36977</td>\n",
       "      <td>11456</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>32729</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36963</td>\n",
       "      <td>19491</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>25836</td>\n",
       "      <td>36977</td>\n",
       "      <td>36971</td>\n",
       "      <td>36977</td>\n",
       "      <td>35400</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>34642</td>\n",
       "      <td>36977</td>\n",
       "      <td>36906</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>19753</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>4845</td>\n",
       "      <td>36977</td>\n",
       "      <td>36903</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36947</td>\n",
       "      <td>36977</td>\n",
       "      <td>36921</td>\n",
       "      <td>36977</td>\n",
       "      <td>36967</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>825</td>\n",
       "      <td>36977</td>\n",
       "      <td>36947</td>\n",
       "      <td>36977</td>\n",
       "      <td>4216</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>30060</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>35637</td>\n",
       "      <td>36919</td>\n",
       "      <td>36977</td>\n",
       "      <td>3327</td>\n",
       "      <td>36977</td>\n",
       "      <td>36947</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36968</td>\n",
       "      <td>9690</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36947</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36967</td>\n",
       "      <td>36977</td>\n",
       "      <td>2785</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>83</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>203</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36967</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36786</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36974</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36919</td>\n",
       "      <td>36919</td>\n",
       "      <td>19327</td>\n",
       "      <td>5072</td>\n",
       "      <td>36919</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>4316</td>\n",
       "      <td>35375</td>\n",
       "      <td>36977</td>\n",
       "      <td>1676</td>\n",
       "      <td>36977</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>32118</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36948</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>36919</td>\n",
       "      <td>36919</td>\n",
       "      <td>36977</td>\n",
       "      <td>555</td>\n",
       "      <td>36919</td>\n",
       "      <td>36919</td>\n",
       "      <td>5078</td>\n",
       "      <td>36977</td>\n",
       "      <td>36977</td>\n",
       "      <td>2847</td>\n",
       "      <td>2847</td>\n",
       "      <td>2847</td>\n",
       "      <td>2847</td>\n",
       "      <td>2847</td>\n",
       "      <td>36919</td>\n",
       "      <td>36977</td>\n",
       "      <td>36919</td>\n",
       "      <td>7058</td>\n",
       "      <td>36919</td>\n",
       "      <td>36977</td>\n",
       "      <td>36919</td>\n",
       "      <td>36977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>38957</td>\n",
       "      <td>38745</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>34485</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>12200</td>\n",
       "      <td>29596</td>\n",
       "      <td>37454</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>31198</td>\n",
       "      <td>38957</td>\n",
       "      <td>36525</td>\n",
       "      <td>5480</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38828</td>\n",
       "      <td>17018</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38878</td>\n",
       "      <td>36137</td>\n",
       "      <td>38957</td>\n",
       "      <td>11790</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>34485</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38712</td>\n",
       "      <td>19882</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>27302</td>\n",
       "      <td>38957</td>\n",
       "      <td>38880</td>\n",
       "      <td>38957</td>\n",
       "      <td>37301</td>\n",
       "      <td>38885</td>\n",
       "      <td>38957</td>\n",
       "      <td>36283</td>\n",
       "      <td>38957</td>\n",
       "      <td>38751</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>20313</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>5018</td>\n",
       "      <td>38957</td>\n",
       "      <td>38752</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38822</td>\n",
       "      <td>38957</td>\n",
       "      <td>38722</td>\n",
       "      <td>38957</td>\n",
       "      <td>38878</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>935</td>\n",
       "      <td>38957</td>\n",
       "      <td>38818</td>\n",
       "      <td>38957</td>\n",
       "      <td>4355</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>31730</td>\n",
       "      <td>38885</td>\n",
       "      <td>38957</td>\n",
       "      <td>37454</td>\n",
       "      <td>38804</td>\n",
       "      <td>38957</td>\n",
       "      <td>3436</td>\n",
       "      <td>38957</td>\n",
       "      <td>38818</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38904</td>\n",
       "      <td>9942</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38822</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38878</td>\n",
       "      <td>38957</td>\n",
       "      <td>3191</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>51</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>195</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38878</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>37626</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38953</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38804</td>\n",
       "      <td>38804</td>\n",
       "      <td>20155</td>\n",
       "      <td>5477</td>\n",
       "      <td>38804</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>4423</td>\n",
       "      <td>35495</td>\n",
       "      <td>38957</td>\n",
       "      <td>1800</td>\n",
       "      <td>38957</td>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "      <td>331</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>33861</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38825</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>38804</td>\n",
       "      <td>38804</td>\n",
       "      <td>38957</td>\n",
       "      <td>492</td>\n",
       "      <td>38804</td>\n",
       "      <td>38804</td>\n",
       "      <td>5480</td>\n",
       "      <td>38957</td>\n",
       "      <td>38957</td>\n",
       "      <td>2990</td>\n",
       "      <td>2990</td>\n",
       "      <td>2990</td>\n",
       "      <td>2990</td>\n",
       "      <td>2990</td>\n",
       "      <td>38804</td>\n",
       "      <td>38957</td>\n",
       "      <td>38804</td>\n",
       "      <td>7464</td>\n",
       "      <td>38804</td>\n",
       "      <td>38957</td>\n",
       "      <td>38804</td>\n",
       "      <td>38957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28</th>\n",
       "      <td>41614</td>\n",
       "      <td>41336</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>37024</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>13981</td>\n",
       "      <td>30152</td>\n",
       "      <td>39995</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>31405</td>\n",
       "      <td>41614</td>\n",
       "      <td>38912</td>\n",
       "      <td>5811</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41020</td>\n",
       "      <td>18230</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41502</td>\n",
       "      <td>36220</td>\n",
       "      <td>41614</td>\n",
       "      <td>12059</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>37024</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41106</td>\n",
       "      <td>20848</td>\n",
       "      <td>41389</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>28516</td>\n",
       "      <td>41614</td>\n",
       "      <td>41032</td>\n",
       "      <td>41614</td>\n",
       "      <td>39874</td>\n",
       "      <td>41563</td>\n",
       "      <td>41614</td>\n",
       "      <td>38643</td>\n",
       "      <td>41614</td>\n",
       "      <td>40462</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>21002</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>5221</td>\n",
       "      <td>41614</td>\n",
       "      <td>40467</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>40567</td>\n",
       "      <td>41614</td>\n",
       "      <td>40908</td>\n",
       "      <td>41614</td>\n",
       "      <td>41503</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>899</td>\n",
       "      <td>41614</td>\n",
       "      <td>41432</td>\n",
       "      <td>41614</td>\n",
       "      <td>4709</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>33940</td>\n",
       "      <td>41563</td>\n",
       "      <td>41614</td>\n",
       "      <td>39995</td>\n",
       "      <td>41393</td>\n",
       "      <td>41614</td>\n",
       "      <td>3579</td>\n",
       "      <td>41614</td>\n",
       "      <td>41432</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41523</td>\n",
       "      <td>10293</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>40567</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41502</td>\n",
       "      <td>41614</td>\n",
       "      <td>3580</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>58</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>221</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41502</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>38398</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41611</td>\n",
       "      <td>41614</td>\n",
       "      <td>41611</td>\n",
       "      <td>41610</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41388</td>\n",
       "      <td>41388</td>\n",
       "      <td>21211</td>\n",
       "      <td>5808</td>\n",
       "      <td>41388</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>4429</td>\n",
       "      <td>35252</td>\n",
       "      <td>41614</td>\n",
       "      <td>1736</td>\n",
       "      <td>41614</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>318</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>36258</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>40570</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>41388</td>\n",
       "      <td>41388</td>\n",
       "      <td>41614</td>\n",
       "      <td>567</td>\n",
       "      <td>41388</td>\n",
       "      <td>41388</td>\n",
       "      <td>5812</td>\n",
       "      <td>41614</td>\n",
       "      <td>41614</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>41388</td>\n",
       "      <td>41614</td>\n",
       "      <td>41388</td>\n",
       "      <td>7951</td>\n",
       "      <td>41388</td>\n",
       "      <td>41614</td>\n",
       "      <td>41388</td>\n",
       "      <td>41614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>47136</td>\n",
       "      <td>46452</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47105</td>\n",
       "      <td>47136</td>\n",
       "      <td>40237</td>\n",
       "      <td>47105</td>\n",
       "      <td>47105</td>\n",
       "      <td>16892</td>\n",
       "      <td>31203</td>\n",
       "      <td>44982</td>\n",
       "      <td>47136</td>\n",
       "      <td>47105</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>31591</td>\n",
       "      <td>47136</td>\n",
       "      <td>43544</td>\n",
       "      <td>6222</td>\n",
       "      <td>47096</td>\n",
       "      <td>47136</td>\n",
       "      <td>45033</td>\n",
       "      <td>20336</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>46690</td>\n",
       "      <td>36631</td>\n",
       "      <td>47136</td>\n",
       "      <td>12646</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47105</td>\n",
       "      <td>47136</td>\n",
       "      <td>40237</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>45948</td>\n",
       "      <td>22512</td>\n",
       "      <td>45798</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>29354</td>\n",
       "      <td>47136</td>\n",
       "      <td>44474</td>\n",
       "      <td>47136</td>\n",
       "      <td>44835</td>\n",
       "      <td>47079</td>\n",
       "      <td>47136</td>\n",
       "      <td>43174</td>\n",
       "      <td>47136</td>\n",
       "      <td>43496</td>\n",
       "      <td>47136</td>\n",
       "      <td>47105</td>\n",
       "      <td>22102</td>\n",
       "      <td>47136</td>\n",
       "      <td>47105</td>\n",
       "      <td>5570</td>\n",
       "      <td>47105</td>\n",
       "      <td>43512</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>43642</td>\n",
       "      <td>47105</td>\n",
       "      <td>44803</td>\n",
       "      <td>47136</td>\n",
       "      <td>46704</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>869</td>\n",
       "      <td>47136</td>\n",
       "      <td>46638</td>\n",
       "      <td>47136</td>\n",
       "      <td>5287</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>37378</td>\n",
       "      <td>47079</td>\n",
       "      <td>47105</td>\n",
       "      <td>44982</td>\n",
       "      <td>45991</td>\n",
       "      <td>47136</td>\n",
       "      <td>4123</td>\n",
       "      <td>47136</td>\n",
       "      <td>46638</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47105</td>\n",
       "      <td>46714</td>\n",
       "      <td>10789</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>43642</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>46690</td>\n",
       "      <td>47136</td>\n",
       "      <td>3574</td>\n",
       "      <td>47105</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>58</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>205</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47105</td>\n",
       "      <td>46690</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>39560</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>47032</td>\n",
       "      <td>47135</td>\n",
       "      <td>47033</td>\n",
       "      <td>47120</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>45984</td>\n",
       "      <td>45984</td>\n",
       "      <td>23644</td>\n",
       "      <td>6211</td>\n",
       "      <td>45984</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>4346</td>\n",
       "      <td>35434</td>\n",
       "      <td>47105</td>\n",
       "      <td>1774</td>\n",
       "      <td>47105</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "      <td>309</td>\n",
       "      <td>47105</td>\n",
       "      <td>47136</td>\n",
       "      <td>37941</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>43669</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>45984</td>\n",
       "      <td>45984</td>\n",
       "      <td>47136</td>\n",
       "      <td>544</td>\n",
       "      <td>45984</td>\n",
       "      <td>45984</td>\n",
       "      <td>6221</td>\n",
       "      <td>47136</td>\n",
       "      <td>47136</td>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "      <td>45984</td>\n",
       "      <td>47136</td>\n",
       "      <td>45984</td>\n",
       "      <td>8822</td>\n",
       "      <td>45984</td>\n",
       "      <td>47136</td>\n",
       "      <td>45984</td>\n",
       "      <td>47136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            customer_ID    P_2   D_39    B_1    B_2    R_1    S_3   D_41  \\\n",
       "S_2                                                                        \n",
       "2017-03-31        30730  30600  30730  30730  30730  30730  26787  30730   \n",
       "2017-04-30        31233  31097  31233  31233  31233  31233  27205  31233   \n",
       "2017-05-31        31048  30901  31048  31048  31048  31048  27106  31048   \n",
       "2017-06-30        31815  31683  31815  31815  31815  31815  27846  31815   \n",
       "2017-07-31        32620  32491  32620  32620  32620  32620  28477  32620   \n",
       "2017-08-31        33253  33131  33253  33253  33253  33253  29175  33253   \n",
       "2017-09-30        33427  33314  33427  33427  33427  33427  29398  33427   \n",
       "2017-10-31        34439  34294  34439  34439  34439  34439  30296  34439   \n",
       "2017-11-30        35664  35550  35664  35664  35664  35664  31552  35664   \n",
       "2017-12-31        36977  36885  36977  36977  36977  36977  32729  36977   \n",
       "2018-01-31        38957  38745  38957  38957  38957  38957  34485  38957   \n",
       "2018-02-28        41614  41336  41614  41614  41614  41614  37024  41614   \n",
       "2018-03-31        47136  46452  47136  47136  47105  47136  40237  47105   \n",
       "\n",
       "              B_3   D_42   D_43   D_44    B_4   D_45    B_5    R_2   D_46  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730   4606  24965  29565  30730  30730  30730  30730  26658   \n",
       "2017-04-30  31233   4907  25305  30024  31233  31233  31233  31233  26900   \n",
       "2017-05-31  31048   5182  25095  29842  31048  31048  31048  31048  26824   \n",
       "2017-06-30  31815   5885  25718  30623  31815  31815  31815  31815  27520   \n",
       "2017-07-31  32620   6541  26228  31410  32620  32620  32620  32620  28199   \n",
       "2017-08-31  33253   7147  26644  32039  33253  33253  33253  33253  28736   \n",
       "2017-09-30  33427   7648  26894  32204  33427  33427  33427  33427  28951   \n",
       "2017-10-31  34439   8438  27355  33103  34439  34439  34439  34439  29708   \n",
       "2017-11-30  35664   9465  28037  34470  35664  35664  35664  35664  30477   \n",
       "2017-12-31  36977  10632  28646  35637  36977  36977  36977  36977  30778   \n",
       "2018-01-31  38957  12200  29596  37454  38957  38957  38957  38957  31198   \n",
       "2018-02-28  41614  13981  30152  39995  41614  41614  41614  41614  31405   \n",
       "2018-03-31  47105  16892  31203  44982  47136  47105  47136  47136  31591   \n",
       "\n",
       "             D_47   D_48  D_49    B_6    B_7    B_8   D_50   D_51    B_9  \\\n",
       "S_2                                                                        \n",
       "2017-03-31  30730  28845  3931  30730  30730  30715  14705  30730  30730   \n",
       "2017-04-30  31233  29248  3970  31233  31233  31216  14866  31233  31233   \n",
       "2017-05-31  31048  29086  4030  31048  31048  31029  14811  31048  31048   \n",
       "2017-06-30  31815  29881  4187  31815  31815  31793  14952  31815  31815   \n",
       "2017-07-31  32620  30677  4321  32620  32620  32594  15321  32620  32620   \n",
       "2017-08-31  33253  31272  4480  33253  33253  33239  15530  33253  33253   \n",
       "2017-09-30  33427  31441  4546  33427  33427  33416  15487  33427  33427   \n",
       "2017-10-31  34439  32338  4724  34439  34439  34417  15778  34439  34439   \n",
       "2017-11-30  35664  33620  4835  35664  35664  35662  16203  35664  35664   \n",
       "2017-12-31  36977  34708  5078  36977  36977  36972  16655  36977  36977   \n",
       "2018-01-31  38957  36525  5480  38957  38957  38828  17018  38957  38957   \n",
       "2018-02-28  41614  38912  5811  41614  41614  41020  18230  41614  41614   \n",
       "2018-03-31  47136  43544  6222  47096  47136  45033  20336  47136  47136   \n",
       "\n",
       "              R_3   D_52    P_3   B_10   D_53    S_5   B_11    S_6   D_54  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730  30676  30599  30730  10143  30730  30730  30730  30730   \n",
       "2017-04-30  31233  31175  31106  31233  10274  31233  31233  31233  31233   \n",
       "2017-05-31  31048  30987  30909  31048  10327  31048  31048  31048  31048   \n",
       "2017-06-30  31815  31755  31683  31815  10632  31815  31815  31815  31815   \n",
       "2017-07-31  32620  32548  32486  32620  10505  32620  32620  32620  32620   \n",
       "2017-08-31  33253  33190  33125  33253  10861  33253  33253  33253  33253   \n",
       "2017-09-30  33427  33384  33303  33427  10955  33427  33427  33427  33427   \n",
       "2017-10-31  34439  34375  34254  34439  11028  34439  34439  34439  34439   \n",
       "2017-11-30  35664  35643  35224  35664  11380  35664  35664  35664  35664   \n",
       "2017-12-31  36977  36967  35710  36977  11456  36977  36977  36977  36977   \n",
       "2018-01-31  38957  38878  36137  38957  11790  38957  38957  38957  38957   \n",
       "2018-02-28  41614  41502  36220  41614  12059  41614  41614  41614  41614   \n",
       "2018-03-31  47136  46690  36631  47136  12646  47136  47136  47136  47105   \n",
       "\n",
       "              R_4    S_7   B_12    S_8   D_55   D_56   B_13    R_5   D_58  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730  26787  30730  30730  30674  17489  30730  30730  30730   \n",
       "2017-04-30  31233  27205  31233  31233  31167  17580  31233  31233  31233   \n",
       "2017-05-31  31048  27106  31048  31048  30976  17402  31048  31048  31048   \n",
       "2017-06-30  31815  27846  31815  31815  31752  17718  31815  31815  31815   \n",
       "2017-07-31  32620  28477  32620  32620  32547  17996  32620  32620  32620   \n",
       "2017-08-31  33253  29175  33253  33253  33191  18210  33253  33253  33253   \n",
       "2017-09-30  33427  29398  33427  33427  33381  18067  33427  33427  33427   \n",
       "2017-10-31  34439  30296  34439  34439  34373  18595  34439  34439  34439   \n",
       "2017-11-30  35664  31552  35664  35664  35645  18809  35664  35664  35664   \n",
       "2017-12-31  36977  32729  36977  36977  36963  19491  36977  36977  36977   \n",
       "2018-01-31  38957  34485  38957  38957  38712  19882  38957  38957  38957   \n",
       "2018-02-28  41614  37024  41614  41614  41106  20848  41389  41614  41614   \n",
       "2018-03-31  47136  40237  47136  47136  45948  22512  45798  47136  47136   \n",
       "\n",
       "              S_9   B_14   D_59   D_60   D_61   B_15   S_11   D_62   D_63  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  20853  30730  30680  30730  29206  30687  30730  28822  30730   \n",
       "2017-04-30  21162  31233  31176  31233  29613  31186  31233  29154  31233   \n",
       "2017-05-31  21161  31048  30982  31048  29472  30988  31048  29031  31048   \n",
       "2017-06-30  21793  31815  31748  31815  30301  31755  31815  29836  31815   \n",
       "2017-07-31  22449  32620  32548  32620  31121  32549  32620  30600  32620   \n",
       "2017-08-31  23063  33253  33196  33253  31696  33201  33253  31214  33253   \n",
       "2017-09-30  23206  33427  33389  33427  31941  33391  33427  31408  33427   \n",
       "2017-10-31  23988  34439  34381  34439  32877  34384  34439  32247  34439   \n",
       "2017-11-30  24996  35664  35660  35664  34193  35664  35664  33509  35664   \n",
       "2017-12-31  25836  36977  36971  36977  35400  36977  36977  34642  36977   \n",
       "2018-01-31  27302  38957  38880  38957  37301  38885  38957  36283  38957   \n",
       "2018-02-28  28516  41614  41032  41614  39874  41563  41614  38643  41614   \n",
       "2018-03-31  29354  47136  44474  47136  44835  47079  47136  43174  47136   \n",
       "\n",
       "             D_64   D_65   B_16   B_17   B_18   B_19  D_66   B_20   D_68  \\\n",
       "S_2                                                                        \n",
       "2017-03-31  30724  30730  30730  17104  30730  30730  4156  30730  30724   \n",
       "2017-04-30  31226  31233  31233  17203  31233  31233  4159  31233  31226   \n",
       "2017-05-31  31048  31048  31048  17198  31048  31048  4171  31048  31048   \n",
       "2017-06-30  31809  31815  31815  17763  31815  31815  4234  31815  31807   \n",
       "2017-07-31  32609  32620  32620  17970  32620  32620  4366  32620  32609   \n",
       "2017-08-31  33235  33253  33253  18362  33253  33253  4382  33253  33237   \n",
       "2017-09-30  33388  33427  33427  18540  33427  33427  4446  33427  33390   \n",
       "2017-10-31  34395  34439  34439  18707  34439  34439  4494  34439  34396   \n",
       "2017-11-30  35585  35664  35664  19466  35664  35664  4714  35664  35591   \n",
       "2017-12-31  36906  36977  36977  19753  36977  36977  4845  36977  36903   \n",
       "2018-01-31  38751  38957  38957  20313  38957  38957  5018  38957  38752   \n",
       "2018-02-28  40462  41614  41614  21002  41614  41614  5221  41614  40467   \n",
       "2018-03-31  43496  47136  47105  22102  47136  47105  5570  47105  43512   \n",
       "\n",
       "             S_12    R_6   S_13   B_21   D_69   B_22   D_70   D_71   D_72  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730  30730  30730  30730  30724  30730  30639  30730  30676   \n",
       "2017-04-30  31233  31233  31233  31233  31226  31233  31141  31233  31175   \n",
       "2017-05-31  31048  31048  31048  31048  31048  31048  30951  31048  30987   \n",
       "2017-06-30  31815  31815  31815  31815  31812  31815  31732  31815  31755   \n",
       "2017-07-31  32620  32620  32620  32620  32614  32620  32520  32620  32548   \n",
       "2017-08-31  33253  33253  33253  33253  33247  33253  33162  33253  33190   \n",
       "2017-09-30  33427  33427  33427  33427  33409  33427  33355  33427  33384   \n",
       "2017-10-31  34439  34439  34439  34439  34425  34439  34337  34439  34375   \n",
       "2017-11-30  35664  35664  35664  35664  35643  35664  35604  35664  35643   \n",
       "2017-12-31  36977  36977  36977  36977  36947  36977  36921  36977  36967   \n",
       "2018-01-31  38957  38957  38957  38957  38822  38957  38722  38957  38878   \n",
       "2018-02-28  41614  41614  41614  41614  40567  41614  40908  41614  41503   \n",
       "2018-03-31  47136  47136  47136  47136  43642  47105  44803  47136  46704   \n",
       "\n",
       "             S_15   B_23  D_73    P_4   D_74   D_75  D_76   B_24    R_7  \\\n",
       "S_2                                                                       \n",
       "2017-03-31  30730  30730   325  30730  30641  30730  4108  30730  30730   \n",
       "2017-04-30  31233  31233   362  31233  31142  31233  4087  31233  31233   \n",
       "2017-05-31  31048  31048   374  31048  30952  31048  4071  31048  31048   \n",
       "2017-06-30  31815  31815   446  31815  31732  31815  4069  31815  31815   \n",
       "2017-07-31  32620  32620   489  32620  32522  32620  4049  32620  32620   \n",
       "2017-08-31  33253  33253   523  33253  33165  33253  4130  33253  33253   \n",
       "2017-09-30  33427  33427   571  33427  33365  33427  4251  33427  33427   \n",
       "2017-10-31  34439  34439   637  34439  34344  34439  4355  34439  34439   \n",
       "2017-11-30  35664  35664   753  35664  35620  35664  4234  35664  35664   \n",
       "2017-12-31  36977  36977   825  36977  36947  36977  4216  36977  36977   \n",
       "2018-01-31  38957  38957   935  38957  38818  38957  4355  38957  38957   \n",
       "2018-02-28  41614  41614   899  41614  41432  41614  4709  41614  41614   \n",
       "2018-03-31  47136  47136   869  47136  46638  47136  5287  47136  47136   \n",
       "\n",
       "             D_77   B_25   B_26   D_78   D_79    R_8   R_9   S_16   D_80  \\\n",
       "S_2                                                                        \n",
       "2017-03-31  24320  30687  30730  29565  30631  30730  2442  30730  30641   \n",
       "2017-04-30  24690  31186  31233  30024  31126  31233  2494  31233  31142   \n",
       "2017-05-31  24521  30988  31048  29842  30934  31048  2563  31048  30952   \n",
       "2017-06-30  25212  31755  31815  30623  31714  31815  2801  31815  31732   \n",
       "2017-07-31  26044  32549  32620  31410  32501  32620  2769  32620  32522   \n",
       "2017-08-31  26539  33201  33253  32039  33133  33253  2901  33253  33165   \n",
       "2017-09-30  26975  33391  33427  32204  33338  33427  2909  33427  33365   \n",
       "2017-10-31  27811  34384  34439  33103  34322  34439  3029  34439  34344   \n",
       "2017-11-30  29005  35664  35664  34470  35588  35664  3163  35664  35620   \n",
       "2017-12-31  30060  36977  36977  35637  36919  36977  3327  36977  36947   \n",
       "2018-01-31  31730  38885  38957  37454  38804  38957  3436  38957  38818   \n",
       "2018-02-28  33940  41563  41614  39995  41393  41614  3579  41614  41432   \n",
       "2018-03-31  37378  47079  47105  44982  45991  47136  4123  47136  46638   \n",
       "\n",
       "             R_10   R_11   B_27   D_81   D_82   S_17   R_12   B_28   R_13  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730  30730  30730  30694   9038  30730  30730  30730  30730   \n",
       "2017-04-30  31233  31233  31233  31199   9012  31233  31233  31233  31233   \n",
       "2017-05-31  31048  31048  31048  31009   8944  31048  31048  31048  31048   \n",
       "2017-06-30  31815  31815  31815  31773   9042  31815  31815  31815  31815   \n",
       "2017-07-31  32620  32620  32620  32576   9192  32620  32620  32620  32620   \n",
       "2017-08-31  33253  33253  33253  33213   9393  33253  33253  33253  33253   \n",
       "2017-09-30  33427  33427  33427  33396   9125  33427  33427  33427  33427   \n",
       "2017-10-31  34439  34439  34439  34395   9432  34439  34439  34439  34439   \n",
       "2017-11-30  35664  35664  35664  35647   9593  35664  35664  35664  35664   \n",
       "2017-12-31  36977  36977  36977  36968   9690  36977  36977  36977  36977   \n",
       "2018-01-31  38957  38957  38957  38904   9942  38957  38957  38957  38957   \n",
       "2018-02-28  41614  41614  41614  41523  10293  41614  41614  41614  41614   \n",
       "2018-03-31  47136  47136  47105  46714  10789  47136  47136  47136  47136   \n",
       "\n",
       "             D_83   R_14   R_15   D_84   R_16  B_29   B_30   S_18   D_86  \\\n",
       "S_2                                                                        \n",
       "2017-03-31  30724  30730  30730  30676  30730  2655  30730  30730  30730   \n",
       "2017-04-30  31226  31233  31233  31175  31233  2667  31233  31233  31233   \n",
       "2017-05-31  31048  31048  31048  30987  31048  2327  31048  31048  31048   \n",
       "2017-06-30  31812  31815  31815  31755  31815  2557  31815  31815  31815   \n",
       "2017-07-31  32614  32620  32620  32548  32620  2608  32620  32620  32620   \n",
       "2017-08-31  33247  33253  33253  33190  33253  2696  33253  33253  33253   \n",
       "2017-09-30  33409  33427  33427  33384  33427  2683  33427  33427  33427   \n",
       "2017-10-31  34425  34439  34439  34375  34439  2678  34439  34439  34439   \n",
       "2017-11-30  35643  35664  35664  35643  35664  2812  35664  35664  35664   \n",
       "2017-12-31  36947  36977  36977  36967  36977  2785  36977  36977  36977   \n",
       "2018-01-31  38822  38957  38957  38878  38957  3191  38957  38957  38957   \n",
       "2018-02-28  40567  41614  41614  41502  41614  3580  41614  41614  41614   \n",
       "2018-03-31  43642  47136  47136  46690  47136  3574  47105  47136  47136   \n",
       "\n",
       "            D_87   R_17   R_18  D_88   B_31   S_19   R_19   B_32   S_20  \\\n",
       "S_2                                                                       \n",
       "2017-03-31    59  30730  30730   170  30730  30730  30730  30730  30730   \n",
       "2017-04-30    62  31233  31233   154  31233  31233  31233  31233  31233   \n",
       "2017-05-31    67  31048  31048   144  31048  31048  31048  31048  31048   \n",
       "2017-06-30    68  31815  31815   156  31815  31815  31815  31815  31815   \n",
       "2017-07-31    60  32620  32620   203  32620  32620  32620  32620  32620   \n",
       "2017-08-31    70  33253  33253   193  33253  33253  33253  33253  33253   \n",
       "2017-09-30    65  33427  33427   173  33427  33427  33427  33427  33427   \n",
       "2017-10-31    69  34439  34439   210  34439  34439  34439  34439  34439   \n",
       "2017-11-30    59  35664  35664   192  35664  35664  35664  35664  35664   \n",
       "2017-12-31    83  36977  36977   203  36977  36977  36977  36977  36977   \n",
       "2018-01-31    51  38957  38957   195  38957  38957  38957  38957  38957   \n",
       "2018-02-28    58  41614  41614   221  41614  41614  41614  41614  41614   \n",
       "2018-03-31    58  47136  47136   205  47136  47136  47136  47136  47136   \n",
       "\n",
       "             R_20   R_21   B_33   D_89   R_22   R_23   D_91   D_92   D_93  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730  30730  30730  30676  30730  30730  30695  30730  30730   \n",
       "2017-04-30  31233  31233  31233  31175  31233  31233  31191  31233  31233   \n",
       "2017-05-31  31048  31048  31048  30987  31048  31048  31000  31048  31048   \n",
       "2017-06-30  31815  31815  31815  31755  31815  31815  31767  31815  31815   \n",
       "2017-07-31  32620  32620  32620  32548  32620  32620  32566  32620  32620   \n",
       "2017-08-31  33253  33253  33253  33190  33253  33253  33214  33253  33253   \n",
       "2017-09-30  33427  33427  33427  33384  33427  33427  33399  33427  33427   \n",
       "2017-10-31  34439  34439  34439  34375  34439  34439  34399  34439  34439   \n",
       "2017-11-30  35664  35664  35664  35643  35664  35664  35527  35664  35664   \n",
       "2017-12-31  36977  36977  36977  36967  36977  36977  36786  36977  36977   \n",
       "2018-01-31  38957  38957  38957  38878  38957  38957  37626  38957  38957   \n",
       "2018-02-28  41614  41614  41614  41502  41614  41614  38398  41614  41614   \n",
       "2018-03-31  47136  47136  47105  46690  47136  47136  39560  47136  47136   \n",
       "\n",
       "             D_94   R_24   R_25   D_96   S_22   S_23   S_24   S_25   S_26  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730  30730  30730  30730  30729  30730  30729  30726  30730   \n",
       "2017-04-30  31233  31233  31233  31233  31232  31233  31232  31233  31233   \n",
       "2017-05-31  31048  31048  31048  31048  31048  31048  31048  31046  31048   \n",
       "2017-06-30  31815  31815  31815  31815  31813  31815  31813  31815  31815   \n",
       "2017-07-31  32620  32620  32620  32620  32620  32620  32620  32617  32620   \n",
       "2017-08-31  33253  33253  33253  33253  33251  33253  33251  33251  33253   \n",
       "2017-09-30  33427  33427  33427  33427  33426  33427  33426  33425  33427   \n",
       "2017-10-31  34439  34439  34439  34439  34437  34439  34437  34438  34439   \n",
       "2017-11-30  35664  35664  35664  35664  35662  35664  35662  35660  35664   \n",
       "2017-12-31  36977  36977  36977  36977  36977  36977  36977  36974  36977   \n",
       "2018-01-31  38957  38957  38957  38957  38957  38957  38957  38953  38957   \n",
       "2018-02-28  41614  41614  41614  41614  41611  41614  41611  41610  41614   \n",
       "2018-03-31  47136  47136  47136  47136  47032  47135  47033  47120  47136   \n",
       "\n",
       "            D_102  D_103  D_104  D_105  D_106  D_107   B_36   B_37  R_26  \\\n",
       "S_2                                                                        \n",
       "2017-03-31  30730  30631  30631  15821   3925  30631  30730  30730  3268   \n",
       "2017-04-30  31233  31126  31126  16191   3964  31126  31233  31233  3281   \n",
       "2017-05-31  31048  30934  30934  16014   4027  30934  31048  31048  3381   \n",
       "2017-06-30  31815  31713  31713  16558   4181  31713  31815  31815  3560   \n",
       "2017-07-31  32620  32501  32501  16889   4312  32501  32620  32620  3720   \n",
       "2017-08-31  33253  33133  33133  17288   4474  33133  33253  33253  3954   \n",
       "2017-09-30  33427  33338  33338  17432   4542  33338  33427  33427  4025   \n",
       "2017-10-31  34439  34322  34322  17864   4718  34322  34439  34439  4150   \n",
       "2017-11-30  35664  35588  35588  18460   4826  35588  35664  35664  4413   \n",
       "2017-12-31  36977  36919  36919  19327   5072  36919  36977  36977  4316   \n",
       "2018-01-31  38957  38804  38804  20155   5477  38804  38957  38957  4423   \n",
       "2018-02-28  41614  41388  41388  21211   5808  41388  41614  41614  4429   \n",
       "2018-03-31  47136  45984  45984  23644   6211  45984  47136  47136  4346   \n",
       "\n",
       "             R_27   B_38  D_108  D_109  D_110  D_111  B_39  D_112   B_40  \\\n",
       "S_2                                                                        \n",
       "2017-03-31  30329  30730   1383  30730    344    344   345  30730  30730   \n",
       "2017-04-30  30830  31233   1457  31233    299    299   300  31233  31233   \n",
       "2017-05-31  30637  31048   1431  31048    308    308   312  31048  31048   \n",
       "2017-06-30  31439  31815   1483  31815    307    307   307  31815  31815   \n",
       "2017-07-31  32176  32620   1629  32620    314    314   314  32620  32620   \n",
       "2017-08-31  32825  33253   1599  33253    320    320   323  33253  33253   \n",
       "2017-09-30  32987  33427   1548  33427    323    323   325  33427  33427   \n",
       "2017-10-31  33941  34439   1712  34439    293    293   294  34439  34439   \n",
       "2017-11-30  35205  35664   1702  35664    334    334   337  35664  35664   \n",
       "2017-12-31  35375  36977   1676  36977    291    291   291  36977  36977   \n",
       "2018-01-31  35495  38957   1800  38957    330    330   331  38957  38957   \n",
       "2018-02-28  35252  41614   1736  41614    316    316   318  41614  41614   \n",
       "2018-03-31  35434  47105   1774  47105    308    308   309  47105  47136   \n",
       "\n",
       "             S_27  D_113  D_114  D_115  D_116  D_117  D_118  D_119  D_120  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  26216  30730  30730  30730  30730  30730  30730  30730  30730   \n",
       "2017-04-30  26683  31233  31233  31233  31233  31233  31233  31233  31233   \n",
       "2017-05-31  26598  31048  31048  31048  31048  31048  31048  31048  31048   \n",
       "2017-06-30  27327  31812  31812  31812  31812  31812  31812  31812  31812   \n",
       "2017-07-31  27942  32614  32614  32614  32614  32614  32614  32614  32614   \n",
       "2017-08-31  28638  33246  33246  33246  33246  33246  33246  33246  33246   \n",
       "2017-09-30  28864  33411  33411  33411  33411  33411  33411  33411  33411   \n",
       "2017-10-31  29787  34425  34425  34425  34425  34425  34425  34425  34425   \n",
       "2017-11-30  30943  35643  35643  35643  35643  35643  35643  35643  35643   \n",
       "2017-12-31  32118  36948  36948  36948  36948  36948  36948  36948  36948   \n",
       "2018-01-31  33861  38825  38825  38825  38825  38825  38825  38825  38825   \n",
       "2018-02-28  36258  40570  40570  40570  40570  40570  40570  40570  40570   \n",
       "2018-03-31  37941  43669  43669  43669  43669  43669  43669  43669  43669   \n",
       "\n",
       "            D_121  D_122  D_123  D_124  D_125  D_126  D_127  D_128  D_129  \\\n",
       "S_2                                                                         \n",
       "2017-03-31  30730  30730  30730  30730  30730  30730  30730  30631  30631   \n",
       "2017-04-30  31233  31233  31233  31233  31233  31233  31233  31126  31126   \n",
       "2017-05-31  31048  31048  31048  31048  31048  31048  31048  30934  30934   \n",
       "2017-06-30  31812  31812  31812  31812  31812  31815  31815  31713  31713   \n",
       "2017-07-31  32614  32614  32614  32614  32614  32620  32620  32501  32501   \n",
       "2017-08-31  33246  33246  33246  33246  33246  33253  33253  33133  33133   \n",
       "2017-09-30  33411  33411  33411  33411  33411  33427  33427  33338  33338   \n",
       "2017-10-31  34425  34425  34425  34425  34425  34439  34439  34322  34322   \n",
       "2017-11-30  35643  35643  35643  35643  35643  35664  35664  35588  35588   \n",
       "2017-12-31  36948  36948  36948  36948  36948  36977  36977  36919  36919   \n",
       "2018-01-31  38825  38825  38825  38825  38825  38957  38957  38804  38804   \n",
       "2018-02-28  40570  40570  40570  40570  40570  41614  41614  41388  41388   \n",
       "2018-03-31  43669  43669  43669  43669  43669  47136  47136  45984  45984   \n",
       "\n",
       "             B_41  B_42  D_130  D_131  D_132  D_133   R_28  D_134  D_135  \\\n",
       "S_2                                                                        \n",
       "2017-03-31  30730   482  30631  30631   3931  30730  30730   2270   2270   \n",
       "2017-04-30  31233   479  31126  31126   3970  31233  31233   2253   2253   \n",
       "2017-05-31  31048   493  30934  30934   4030  31048  31048   2248   2248   \n",
       "2017-06-30  31815   505  31713  31713   4187  31815  31815   2423   2423   \n",
       "2017-07-31  32620   431  32501  32501   4319  32620  32620   2453   2453   \n",
       "2017-08-31  33253   473  33133  33133   4480  33253  33253   2620   2620   \n",
       "2017-09-30  33427   508  33338  33338   4546  33427  33427   2635   2635   \n",
       "2017-10-31  34439   486  34322  34322   4724  34439  34439   2746   2746   \n",
       "2017-11-30  35664   494  35588  35588   4835  35664  35664   2871   2871   \n",
       "2017-12-31  36977   555  36919  36919   5078  36977  36977   2847   2847   \n",
       "2018-01-31  38957   492  38804  38804   5480  38957  38957   2990   2990   \n",
       "2018-02-28  41614   567  41388  41388   5812  41614  41614   2987   2987   \n",
       "2018-03-31  47136   544  45984  45984   6221  47136  47136   3213   3213   \n",
       "\n",
       "            D_136  D_137  D_138  D_139  D_140  D_141  D_142  D_143  D_144  \\\n",
       "S_2                                                                         \n",
       "2017-03-31   2270   2270   2270  30631  30730  30631   5477  30631  30730   \n",
       "2017-04-30   2253   2253   2253  31126  31233  31126   5593  31126  31233   \n",
       "2017-05-31   2248   2248   2248  30934  31048  30934   5593  30934  31048   \n",
       "2017-06-30   2423   2423   2423  31713  31815  31713   5938  31713  31815   \n",
       "2017-07-31   2453   2453   2453  32501  32620  32501   6049  32501  32620   \n",
       "2017-08-31   2620   2620   2620  33133  33253  33133   6244  33133  33253   \n",
       "2017-09-30   2635   2635   2635  33338  33427  33338   6237  33338  33427   \n",
       "2017-10-31   2746   2746   2746  34322  34439  34322   6416  34322  34439   \n",
       "2017-11-30   2871   2871   2871  35588  35664  35588   6738  35588  35664   \n",
       "2017-12-31   2847   2847   2847  36919  36977  36919   7058  36919  36977   \n",
       "2018-01-31   2990   2990   2990  38804  38957  38804   7464  38804  38957   \n",
       "2018-02-28   2987   2987   2987  41388  41614  41388   7951  41388  41614   \n",
       "2018-03-31   3213   3213   3213  45984  47136  45984   8822  45984  47136   \n",
       "\n",
       "            D_145  target  \n",
       "S_2                        \n",
       "2017-03-31  30631   30730  \n",
       "2017-04-30  31126   31233  \n",
       "2017-05-31  30934   31048  \n",
       "2017-06-30  31713   31815  \n",
       "2017-07-31  32501   32620  \n",
       "2017-08-31  33133   33253  \n",
       "2017-09-30  33338   33427  \n",
       "2017-10-31  34322   34439  \n",
       "2017-11-30  35588   35664  \n",
       "2017-12-31  36919   36977  \n",
       "2018-01-31  38804   38957  \n",
       "2018-02-28  41388   41614  \n",
       "2018-03-31  45984   47136  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.set_index('S_2').groupby(pd.Grouper(freq = 'M')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_ID         0\n",
       "S_2                 0\n",
       "P_2              2434\n",
       "D_39                0\n",
       "B_1                 0\n",
       "                ...  \n",
       "D_142          373333\n",
       "D_143            2532\n",
       "D_144               0\n",
       "D_145            2532\n",
       "target              0\n",
       "Length: 191, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_ID object\n",
      "S_2 datetime64[ns]\n",
      "D_63 object\n",
      "D_64 object\n",
      "B_31 int64\n",
      "target int64\n"
     ]
    }
   ],
   "source": [
    "for i in df1.columns:\n",
    "    if df1[i].dtypes != 'float64':\n",
    "        print(i, df1[i].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CR', 'CO', 'CL', 'XZ', 'XM', 'XL'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['D_63'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'R', 'U', '-1', None], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['D_64'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical Variables to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  2017-03-01 00:00:00 Max:  2018-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: \", df1['S_2'].min(), \"Max: \", df1['S_2'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1 = pd.get_dummies(df1, columns = ['D_63', 'D_64'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 197)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_new1.to_csv('final_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers:\n",
      "\n",
      "read_csv(filepath_or_buffer: Union[ForwardRef('PathLike[str]'), str, IO[~T], io.RawIOBase, io.BufferedIOBase, io.TextIOBase, _io.TextIOWrapper, mmap.mmap], sep=<object object at 0x7f990d789410>, delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal: str = '.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None, storage_options: Union[Dict[str, Any], NoneType] = None)\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : int, str, sequence of int / str, or False, default ``None``\n",
      "      Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "      string name or column index. If a sequence of int / str is given, a\n",
      "      MultiIndex is used.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g. when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : {'c', 'python'}, optional\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.25.0\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and\n",
      "        `filepath_or_buffer` is path-like, then detect compression from the\n",
      "        following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      "        decompression). If using 'zip', the ZIP file must contain only one data\n",
      "        file to be read in. Set to None for no decompression.\n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
      "           ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
      "           This behavior was previously only the case for ``engine=\"python\"``.\n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    error_bad_lines : bool, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned.\n",
      "    warn_bad_lines : bool, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or 'high' for the ordinary converter,\n",
      "        'legacy' for the original lower precision pandas converter, and\n",
      "        'round_trip' for the round-trip converter.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc., if using a URL that will\n",
      "        be parsed by ``fsspec``, e.g., starting \"s3://\", \"gcs://\". An error\n",
      "        will be raised if providing this argument with a non-fsspec URL.\n",
      "        See the fsspec and backend storage implementation docs for the set of\n",
      "        allowed keys and values.\n",
      "    \n",
      "        .. versionadded:: 1.2\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 197)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('final_df.csv', index_col = False)\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_49</th>\n",
       "      <th>B_6</th>\n",
       "      <th>B_7</th>\n",
       "      <th>B_8</th>\n",
       "      <th>D_50</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>D_52</th>\n",
       "      <th>P_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>D_53</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>D_54</th>\n",
       "      <th>R_4</th>\n",
       "      <th>S_7</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>D_55</th>\n",
       "      <th>D_56</th>\n",
       "      <th>B_13</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>S_9</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_59</th>\n",
       "      <th>D_60</th>\n",
       "      <th>D_61</th>\n",
       "      <th>B_15</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_17</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>D_66</th>\n",
       "      <th>B_20</th>\n",
       "      <th>D_68</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_69</th>\n",
       "      <th>B_22</th>\n",
       "      <th>D_70</th>\n",
       "      <th>D_71</th>\n",
       "      <th>D_72</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>D_73</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_74</th>\n",
       "      <th>D_75</th>\n",
       "      <th>D_76</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>D_77</th>\n",
       "      <th>B_25</th>\n",
       "      <th>B_26</th>\n",
       "      <th>D_78</th>\n",
       "      <th>D_79</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>S_16</th>\n",
       "      <th>D_80</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>B_27</th>\n",
       "      <th>D_81</th>\n",
       "      <th>D_82</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>D_83</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>D_84</th>\n",
       "      <th>R_16</th>\n",
       "      <th>B_29</th>\n",
       "      <th>B_30</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>D_87</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>D_88</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>B_33</th>\n",
       "      <th>D_89</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_91</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>D_103</th>\n",
       "      <th>D_104</th>\n",
       "      <th>D_105</th>\n",
       "      <th>D_106</th>\n",
       "      <th>D_107</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_108</th>\n",
       "      <th>D_109</th>\n",
       "      <th>D_110</th>\n",
       "      <th>D_111</th>\n",
       "      <th>B_39</th>\n",
       "      <th>D_112</th>\n",
       "      <th>B_40</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_113</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_115</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_118</th>\n",
       "      <th>D_119</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_121</th>\n",
       "      <th>D_122</th>\n",
       "      <th>D_123</th>\n",
       "      <th>D_124</th>\n",
       "      <th>D_125</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_127</th>\n",
       "      <th>D_128</th>\n",
       "      <th>D_129</th>\n",
       "      <th>B_41</th>\n",
       "      <th>B_42</th>\n",
       "      <th>D_130</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_132</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_134</th>\n",
       "      <th>D_135</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_64_O</th>\n",
       "      <th>D_64_R</th>\n",
       "      <th>D_64_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.038862</td>\n",
       "      <td>0.720619</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>0.529305</td>\n",
       "      <td>0.255736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.154026</td>\n",
       "      <td>1.341735</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.205468</td>\n",
       "      <td>0.691986</td>\n",
       "      <td>0.121518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054221</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>1.003738</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.094311</td>\n",
       "      <td>0.129539</td>\n",
       "      <td>0.917133</td>\n",
       "      <td>0.231110</td>\n",
       "      <td>0.154914</td>\n",
       "      <td>0.095178</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.126443</td>\n",
       "      <td>0.039259</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.233103</td>\n",
       "      <td>0.175655</td>\n",
       "      <td>0.031171</td>\n",
       "      <td>0.487460</td>\n",
       "      <td>0.093915</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650112</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.216507</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.507712</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.096441</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.076561</td>\n",
       "      <td>0.074432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.421334</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.506213</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>1.006536</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>1.509905</td>\n",
       "      <td>1.002915</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.921026</td>\n",
       "      <td>0.131620</td>\n",
       "      <td>0.933479</td>\n",
       "      <td>0.978027</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.005735</td>\n",
       "      <td>0.953363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673869</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003175</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.811199</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.247939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.244199</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705343</td>\n",
       "      <td>0.437433</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.688774</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.009886</td>\n",
       "      <td>1.005053</td>\n",
       "      <td>1.008132</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>0.878856</td>\n",
       "      <td>0.536290</td>\n",
       "      <td>0.034558</td>\n",
       "      <td>1.005419</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.159486</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062028</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.470223</td>\n",
       "      <td>0.398607</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211673</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.340006</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.109444</td>\n",
       "      <td>0.239160</td>\n",
       "      <td>0.517843</td>\n",
       "      <td>0.301616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.005178</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.136180</td>\n",
       "      <td>0.022597</td>\n",
       "      <td>0.319952</td>\n",
       "      <td>0.047516</td>\n",
       "      <td>0.695723</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>0.239134</td>\n",
       "      <td>0.524772</td>\n",
       "      <td>0.103022</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.444329</td>\n",
       "      <td>0.238523</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001247</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.188421</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.288901</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>0.406084</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.224252</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>1.002889</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>1.000591</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.008394</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.994174</td>\n",
       "      <td>0.140244</td>\n",
       "      <td>1.011297</td>\n",
       "      <td>0.975712</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.030284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009403</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000855</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.438787</td>\n",
       "      <td>0.444072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.539496</td>\n",
       "      <td>0.295148</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.138098</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>1.006768</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.819583</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128216</td>\n",
       "      <td>0.014440</td>\n",
       "      <td>0.241352</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.647064</td>\n",
       "      <td>0.328729</td>\n",
       "      <td>0.255134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129857</td>\n",
       "      <td>0.029681</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336649</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.009347</td>\n",
       "      <td>0.202377</td>\n",
       "      <td>0.381123</td>\n",
       "      <td>0.302408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>1.008377</td>\n",
       "      <td>1.008792</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.093894</td>\n",
       "      <td>0.209577</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.233313</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.040357</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.282944</td>\n",
       "      <td>0.438517</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003827</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.192570</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.500918</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.405889</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>1.007309</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>1.003646</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.302575</td>\n",
       "      <td>0.140089</td>\n",
       "      <td>0.046467</td>\n",
       "      <td>0.972811</td>\n",
       "      <td>0.009825</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009074</td>\n",
       "      <td>0.014422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.357183</td>\n",
       "      <td>0.351511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430123</td>\n",
       "      <td>0.145992</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.277472</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.006824</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>1.009999</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.315459</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054156</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>0.074935</td>\n",
       "      <td>0.115955</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>0.426389</td>\n",
       "      <td>0.410036</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195544</td>\n",
       "      <td>0.012364</td>\n",
       "      <td>1.005542</td>\n",
       "      <td>0.446461</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.197941</td>\n",
       "      <td>0.683057</td>\n",
       "      <td>0.401879</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.030321</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>1.004057</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.305570</td>\n",
       "      <td>0.075619</td>\n",
       "      <td>0.174018</td>\n",
       "      <td>0.043256</td>\n",
       "      <td>0.537050</td>\n",
       "      <td>0.060876</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.504869</td>\n",
       "      <td>0.885493</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.367468</td>\n",
       "      <td>0.435120</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.169134</td>\n",
       "      <td>0.688565</td>\n",
       "      <td>1.006742</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.350610</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.423225</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.501547</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.404375</td>\n",
       "      <td>0.036366</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.009142</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>1.003564</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>1.007992</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.938787</td>\n",
       "      <td>0.138968</td>\n",
       "      <td>0.949112</td>\n",
       "      <td>0.977980</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.012525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007662</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007387</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.622480</td>\n",
       "      <td>0.205393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628400</td>\n",
       "      <td>0.291724</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.595189</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>1.005135</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009869</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>0.881317</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>0.813362</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.166190</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.296605</td>\n",
       "      <td>0.064995</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.442626</td>\n",
       "      <td>0.478819</td>\n",
       "      <td>0.249117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>0.165544</td>\n",
       "      <td>1.008826</td>\n",
       "      <td>0.088808</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.249718</td>\n",
       "      <td>0.545050</td>\n",
       "      <td>0.086362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>1.003481</td>\n",
       "      <td>1.004402</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.121961</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.230664</td>\n",
       "      <td>0.190924</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.385253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.460445</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.667046</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.287388</td>\n",
       "      <td>0.425465</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533738</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.186713</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>0.507343</td>\n",
       "      <td>0.152732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.148753</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>0.386079</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.206062</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.009771</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>1.002509</td>\n",
       "      <td>0.267876</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>1.002632</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>0.298209</td>\n",
       "      <td>0.136818</td>\n",
       "      <td>0.078868</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.546465</td>\n",
       "      <td>1.009594</td>\n",
       "      <td>0.962711</td>\n",
       "      <td>0.783085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002060</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004618</td>\n",
       "      <td>0.141804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.433575</td>\n",
       "      <td>0.430817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561551</td>\n",
       "      <td>0.429008</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.188523</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>1.001023</td>\n",
       "      <td>1.001676</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006568</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  2018-02-06  0.878856   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  2017-11-11  0.797670   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  2018-02-03  0.623392   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  2018-01-30  0.881317   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  D_42  \\\n",
       "0  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653  0.009312   NaN   \n",
       "1  0.536290  0.034558  1.005419  0.007248  0.159486  0.006274  0.008733   NaN   \n",
       "2  0.002817  0.003238  0.819583  0.008977       NaN  0.003330  0.003115   NaN   \n",
       "3  0.008380  0.014589  1.009999  0.003768  0.315459  0.008239  0.004804   NaN   \n",
       "4  0.000722  0.009806  0.813362  0.009076  0.166190  0.005905  0.000049   NaN   \n",
       "\n",
       "       D_43      D_44       B_4      D_45       B_5       R_2      D_46  \\\n",
       "0       NaN  0.007731  0.038862  0.720619  0.143630  0.006667  0.231009   \n",
       "1  0.062028  0.000123  0.020876  0.263736  0.010155  0.003805  0.470223   \n",
       "2       NaN  0.128216  0.014440  0.241352  0.002468  0.009580  0.647064   \n",
       "3  0.054156  0.000058  0.008486  0.074935  0.115955  0.009204  0.426389   \n",
       "4  0.043679  0.008814  0.296605  0.064995  0.001682  0.006869  0.442626   \n",
       "\n",
       "       D_47      D_48  D_49       B_6       B_7       B_8      D_50      D_51  \\\n",
       "0  0.529305  0.255736   NaN  0.075900  0.048918  0.001199  0.154026  1.341735   \n",
       "1  0.398607  0.010117   NaN  0.211673  0.033179  0.004795       NaN  0.340006   \n",
       "2  0.328729  0.255134   NaN  0.129857  0.029681  0.003409       NaN  0.336649   \n",
       "3  0.410036  0.013057   NaN  0.195544  0.012364  1.005542  0.446461  0.008012   \n",
       "4  0.478819  0.249117   NaN  0.062706  0.165544  1.008826  0.088808  0.005670   \n",
       "\n",
       "        B_9       R_3      D_52       P_3      B_10      D_53       S_5  \\\n",
       "0  0.000519  0.001362  0.205468  0.691986  0.121518       NaN  0.054221   \n",
       "1  0.011734  0.109444  0.239160  0.517843  0.301616       NaN  0.006361   \n",
       "2  0.006849  0.009347  0.202377  0.381123  0.302408       NaN  0.008730   \n",
       "3  0.034357  0.001734  0.197941  0.683057  0.401879  0.006432  0.030321   \n",
       "4  0.009021  0.002244  0.249718  0.545050  0.086362       NaN  0.002452   \n",
       "\n",
       "       B_11       S_6      D_54       R_4       S_7      B_12       S_8  \\\n",
       "0  0.009484  0.006698  1.003738  0.003846  0.094311  0.129539  0.917133   \n",
       "1  0.015018  0.005666  1.005178  0.000279  0.136180  0.022597  0.319952   \n",
       "2  0.006193  1.008377  1.008792  0.001428       NaN  0.014242  0.004022   \n",
       "3  0.004926  0.009158  1.004057  0.003462  0.305570  0.075619  0.174018   \n",
       "4  0.001964  1.003481  1.004402  0.002839  0.121961  0.005756  0.002977   \n",
       "\n",
       "       D_55      D_56      B_13       R_5      D_58       S_9      B_14  \\\n",
       "0  0.231110  0.154914  0.095178  0.001653  0.126443  0.039259  0.027897   \n",
       "1  0.047516  0.695723  0.008499  0.003330  0.008624  0.017112  0.023292   \n",
       "2  0.093894  0.209577  0.003433  0.004768  0.001512       NaN  0.008507   \n",
       "3  0.043256  0.537050  0.060876  0.003396  0.006757  0.005059  0.016034   \n",
       "4  0.230664  0.190924  0.007514  0.006633  0.385253       NaN  0.008164   \n",
       "\n",
       "       D_59      D_60      D_61      B_15      S_11      D_62      D_65  \\\n",
       "0  0.063697  0.233103  0.175655  0.031171  0.487460  0.093915  0.009479   \n",
       "1  0.239134  0.524772  0.103022  0.003985  0.444329  0.238523  0.000660   \n",
       "2  0.233313  0.005077  0.040357  0.000019  0.282944  0.438517  0.007570   \n",
       "3  0.504869  0.885493  0.089213  0.002995  0.367468  0.435120  0.001220   \n",
       "4  0.460445  0.002601  0.667046  0.009458  0.287388  0.425465  0.006448   \n",
       "\n",
       "       B_16      B_17      B_18      B_19  D_66      B_20  D_68      S_12  \\\n",
       "0  0.001714       NaN  0.650112  0.007773   NaN  0.005851   6.0  0.216507   \n",
       "1  0.003267       NaN  1.001247  0.002385   NaN  0.000350   6.0  0.188421   \n",
       "2  0.006509       NaN  1.003827  0.000319   NaN  0.005271   6.0  0.192570   \n",
       "3  0.169134  0.688565  1.006742  0.002138   NaN  0.001995   3.0  0.350610   \n",
       "4  0.006330       NaN  0.533738  0.000073   1.0  0.004301   6.0  0.186713   \n",
       "\n",
       "        R_6      S_13      B_21      D_69      B_22      D_70      D_71  \\\n",
       "0  0.008605  0.507712  0.006821  0.000152  0.000104  0.001419  0.096441   \n",
       "1  0.002118  0.288901  0.008382  0.005944  0.009769  0.000006  0.010515   \n",
       "2  0.009718  0.002444  0.000078  0.009708  0.001800  0.007461  0.014436   \n",
       "3  0.004044  0.423225  0.009143  0.005034  0.005501  0.003045  0.012520   \n",
       "4  0.009199  0.008576  0.003880  0.000946  0.000351  0.006711  0.015640   \n",
       "\n",
       "       D_72      S_15      B_23  D_73       P_4      D_74      D_75  D_76  \\\n",
       "0  0.007972  0.106020  0.032733   NaN  0.008156  0.076561  0.074432   NaN   \n",
       "1  0.005811  0.406084  0.014946   NaN  0.005555  0.001238  0.009073   NaN   \n",
       "2  0.003765  0.500918  0.017130   NaN  0.008659  0.002719  0.009353   NaN   \n",
       "3  0.006995  0.501547  0.003451   NaN  0.008617  0.004600  0.002992   NaN   \n",
       "4  0.006148  0.507343  0.152732   NaN  0.006779  0.148753  0.143027   NaN   \n",
       "\n",
       "       B_24       R_7      D_77      B_25      B_26      D_78      D_79  \\\n",
       "0  0.004933  0.004831  0.421334  0.001833  0.005738  0.003289  0.002608   \n",
       "1  0.009167  0.009282  0.224252  0.033150  0.007601  0.003151  0.004500   \n",
       "2  0.001681  0.006373  0.405889  0.003890  0.007754  0.003879  0.001095   \n",
       "3  0.005909  0.002774  0.404375  0.036366  0.003175  0.009142  0.006272   \n",
       "4  0.009404  0.008993  0.386079  0.008476  0.000206  0.004842  0.000956   \n",
       "\n",
       "        R_8  R_9      S_16      D_80      R_10      R_11      B_27      D_81  \\\n",
       "0  0.007338  NaN  0.007447  0.004465  0.006111  0.002246  0.002109  0.001141   \n",
       "1  0.006927  NaN  0.000067  0.004264  0.004670  0.005223  0.000015  0.005108   \n",
       "2  0.009628  NaN  0.004503  0.001344  0.006854  0.002483  0.008049  0.002018   \n",
       "3  0.004093  NaN  0.003130  0.001213  0.004100  0.003846  0.000866  0.006263   \n",
       "4  0.007714  NaN  0.004592  0.206062  0.003792  0.001701  0.009771  0.002729   \n",
       "\n",
       "       D_82      S_17      R_12      B_28      R_13      D_83      R_14  \\\n",
       "0  0.506213  0.001770  1.000904  0.062492  0.005860  0.001845  0.007816   \n",
       "1       NaN  0.003619  1.002889  0.014986  0.003408  0.002738  0.009129   \n",
       "2       NaN  0.000739  1.007309  0.013434  0.008990  0.008680  0.005797   \n",
       "3       NaN  0.004267  1.003564  0.017212  0.001522  0.007760  0.006544   \n",
       "4       NaN  0.003111  1.002509  0.267876  0.004610  0.000913  0.001612   \n",
       "\n",
       "       R_15      D_84      R_16  B_29  B_30      S_18      D_86  D_87  \\\n",
       "0  0.002470  0.005516  0.007166   NaN   0.0  0.000155  0.001504   NaN   \n",
       "1  0.003361  0.000091  0.009003   NaN   0.0  0.005150  0.002534   NaN   \n",
       "2  0.003886  0.001189  0.001660   NaN   0.0  0.005308  0.007911   NaN   \n",
       "3  0.009200  0.006185  0.003933   NaN   0.0  0.008703  0.002066   NaN   \n",
       "4  0.003762  0.004152  0.004119   NaN   0.0  0.004694  0.009376   NaN   \n",
       "\n",
       "       R_17      R_18  D_88  B_31      S_19      R_19      B_32      S_20  \\\n",
       "0  0.002019  0.002678   NaN     1  0.007728  0.003432  0.002199  0.005511   \n",
       "1  0.002449  0.007003   NaN     1  0.009282  0.000871  0.005917  0.009783   \n",
       "2  0.001368  0.003798   NaN     1  0.000252  0.004986  0.006025  0.000713   \n",
       "3  0.008195  0.004076   NaN     1  0.009488  0.007342  0.003610  0.002357   \n",
       "4  0.004042  0.005544   NaN     1  0.001490  0.002296  0.004645  0.000262   \n",
       "\n",
       "       R_20      R_21      B_33      D_89      R_22      R_23      D_91  \\\n",
       "0  0.004105  0.009656  1.006536  0.005158  0.003341  0.000264  1.509905   \n",
       "1  0.001053  0.006891  1.000591  0.000540  0.005175  0.001321  0.007013   \n",
       "2  0.002198  0.004641  1.003646  0.002750  0.005280  0.006755  0.006454   \n",
       "3  0.008257  0.006674  1.007992  0.007506  0.001581  0.004146  0.007798   \n",
       "4  0.004536  0.000738  1.002632  0.008701  0.002351  0.006473  0.004809   \n",
       "\n",
       "       D_92      D_93      D_94      R_24      R_25      D_96      S_22  \\\n",
       "0  1.002915  0.003079  0.003845  0.007190  0.002983  0.000535  0.921026   \n",
       "1  0.008394  0.005752  0.009342  0.006949  0.005339  0.002806  0.994174   \n",
       "2  0.000583  0.004940  0.002180  0.003211  0.002368  0.008215  0.302575   \n",
       "3  0.001289  0.005549  0.001761  0.007192  0.005130  0.005974  0.938787   \n",
       "4  0.005078  0.005604  0.000692  0.005538  0.005958  0.008112  0.298209   \n",
       "\n",
       "       S_23      S_24      S_25      S_26     D_102     D_103     D_104  \\\n",
       "0  0.131620  0.933479  0.978027  0.018200  0.822281  1.006125  1.005735   \n",
       "1  0.140244  1.011297  0.975712  0.002006  0.001432  0.008440  0.009310   \n",
       "2  0.140089  0.046467  0.972811  0.009825  0.001250  0.000295  0.006047   \n",
       "3  0.138968  0.949112  0.977980  0.003410  0.003777  0.004194  0.005674   \n",
       "4  0.136818  0.078868  0.969240  0.004642  0.546465  1.009594  0.962711   \n",
       "\n",
       "      D_105  D_106     D_107      B_36      B_37  R_26      R_27  B_38  D_108  \\\n",
       "0  0.953363    NaN  0.673869  0.009998  0.017598   NaN  1.003175   2.0    NaN   \n",
       "1       NaN    NaN  0.000299  0.004645  0.030284   NaN  1.009403   2.0    NaN   \n",
       "2       NaN    NaN  0.004210  0.008693  0.003325   NaN  1.002764   1.0    NaN   \n",
       "3       NaN    NaN  0.006976  0.008666  0.012525   NaN  1.007662   2.0    NaN   \n",
       "4  0.783085    NaN  1.002060  0.000127  0.002286   NaN  1.001764   1.0    NaN   \n",
       "\n",
       "      D_109  D_110  D_111  B_39     D_112      B_40      S_27     D_113  \\\n",
       "0  0.009120    NaN    NaN   NaN  1.000130  0.120717  0.811199  0.008724   \n",
       "1  0.008252    NaN    NaN   NaN  1.000855  0.019818  0.003480  0.008714   \n",
       "2  0.006836    NaN    NaN   NaN  1.009074  0.014422       NaN  0.006476   \n",
       "3  0.005767    NaN    NaN   NaN  1.007387  0.005678  0.622480  0.205393   \n",
       "4  0.006829    NaN    NaN   NaN  1.004618  0.141804       NaN  0.009499   \n",
       "\n",
       "   D_114     D_115  D_116  D_117     D_118     D_119  D_120     D_121  \\\n",
       "0    1.0  0.247939    0.0    4.0  0.244199  0.242325    0.0  0.705343   \n",
       "1    1.0  0.448894    0.0   -1.0  0.438787  0.444072    1.0  0.539496   \n",
       "2    1.0  0.381300    0.0   -1.0  0.357183  0.351511    0.0  0.430123   \n",
       "3    1.0  0.052361    0.0    6.0  0.059829  0.057173    0.0  0.628400   \n",
       "4    1.0  0.444415    0.0    4.0  0.433575  0.430817    0.0  0.561551   \n",
       "\n",
       "      D_122     D_123     D_124     D_125  D_126     D_127     D_128  \\\n",
       "0  0.437433  0.002849  0.688774  0.000097    1.0  1.009886  1.005053   \n",
       "1  0.295148  0.005445  0.138098  0.007310    1.0  0.003569  1.006768   \n",
       "2  0.145992  0.002285  0.277472  0.001474    1.0  0.006043  0.002849   \n",
       "3  0.291724  0.009358  0.595189  0.000705    1.0  0.001997  1.004028   \n",
       "4  0.429008  0.004305  0.188523  0.000918    1.0  0.002336  1.001023   \n",
       "\n",
       "      D_129      B_41  B_42     D_130     D_131  D_132     D_133      R_28  \\\n",
       "0  1.008132  0.009823   NaN  0.009680  0.004848    NaN  0.006312  0.004462   \n",
       "1  0.002430  0.004867   NaN  0.000415  0.001726    NaN  0.009592  0.006052   \n",
       "2  0.004618  0.007190   NaN  0.009441  0.008822    NaN  0.008908  0.005722   \n",
       "3  1.005135  0.006314   NaN  0.001364  0.008404    NaN  0.001157  0.000564   \n",
       "4  1.001676  0.005506   NaN  1.006568  0.004640    NaN  0.008428  0.000974   \n",
       "\n",
       "   D_134  D_135  D_136  D_137  D_138     D_139     D_140     D_141  D_142  \\\n",
       "0    NaN    NaN    NaN    NaN    NaN  0.003671  0.004946  0.008889    NaN   \n",
       "1    NaN    NaN    NaN    NaN    NaN  0.006658  0.004627  0.004820    NaN   \n",
       "2    NaN    NaN    NaN    NaN    NaN  0.007485  0.007834  0.000951    NaN   \n",
       "3    NaN    NaN    NaN    NaN    NaN  0.009312  0.006928  0.001445    NaN   \n",
       "4    NaN    NaN    NaN    NaN    NaN  0.002578  0.001665  0.000579    NaN   \n",
       "\n",
       "      D_143     D_144     D_145  target  D_63_CO  D_63_CR  D_63_XL  D_63_XM  \\\n",
       "0  0.001670  0.008126  0.009827       0        0        1        0        0   \n",
       "1  0.008272  0.002528  0.003584       0        1        0        0        0   \n",
       "2  0.009845  0.004747  0.006824       0        1        0        0        0   \n",
       "3  0.009869  0.004819  0.006847       0        1        0        0        0   \n",
       "4  0.004662  0.002551  0.009652       0        1        0        0        0   \n",
       "\n",
       "   D_63_XZ  D_64_O  D_64_R  D_64_U  \n",
       "0        0       1       0       0  \n",
       "1        0       1       0       0  \n",
       "2        0       0       1       0  \n",
       "3        0       1       0       0  \n",
       "4        0       1       0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['S_2'] = pd.to_datetime(df_new['S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>30730</td>\n",
       "      <td>0.233355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-30</th>\n",
       "      <td>31233</td>\n",
       "      <td>0.235264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>31048</td>\n",
       "      <td>0.237568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>31815</td>\n",
       "      <td>0.247933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>32620</td>\n",
       "      <td>0.247149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>33253</td>\n",
       "      <td>0.256428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>33427</td>\n",
       "      <td>0.261256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>34439</td>\n",
       "      <td>0.264439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>35664</td>\n",
       "      <td>0.263459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>36977</td>\n",
       "      <td>0.268789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>38957</td>\n",
       "      <td>0.271658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28</th>\n",
       "      <td>41614</td>\n",
       "      <td>0.279329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>47136</td>\n",
       "      <td>0.277368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            customer_ID    target\n",
       "S_2                              \n",
       "2017-03-31        30730  0.233355\n",
       "2017-04-30        31233  0.235264\n",
       "2017-05-31        31048  0.237568\n",
       "2017-06-30        31815  0.247933\n",
       "2017-07-31        32620  0.247149\n",
       "2017-08-31        33253  0.256428\n",
       "2017-09-30        33427  0.261256\n",
       "2017-10-31        34439  0.264439\n",
       "2017-11-30        35664  0.263459\n",
       "2017-12-31        36977  0.268789\n",
       "2018-01-31        38957  0.271658\n",
       "2018-02-28        41614  0.279329\n",
       "2018-03-31        47136  0.277368"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[['S_2', 'customer_ID', 'target']].set_index('S_2').groupby(pd.Grouper(freq = 'M')).agg({'customer_ID': 'count', 'target': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_ID\n",
      "S_2\n",
      "P_2\n",
      "D_39\n",
      "B_1\n",
      "B_2\n",
      "R_1\n",
      "S_3\n",
      "D_41\n",
      "B_3\n",
      "D_42\n",
      "D_43\n",
      "D_44\n",
      "B_4\n",
      "D_45\n",
      "B_5\n",
      "R_2\n",
      "D_46\n",
      "D_47\n",
      "D_48\n",
      "D_49\n",
      "B_6\n",
      "B_7\n",
      "B_8\n",
      "D_50\n",
      "D_51\n",
      "B_9\n",
      "R_3\n",
      "D_52\n",
      "P_3\n",
      "B_10\n",
      "D_53\n",
      "S_5\n",
      "B_11\n",
      "S_6\n",
      "D_54\n",
      "R_4\n",
      "S_7\n",
      "B_12\n",
      "S_8\n",
      "D_55\n",
      "D_56\n",
      "B_13\n",
      "R_5\n",
      "D_58\n",
      "S_9\n",
      "B_14\n",
      "D_59\n",
      "D_60\n",
      "D_61\n",
      "B_15\n",
      "S_11\n",
      "D_62\n",
      "D_65\n",
      "B_16\n",
      "B_17\n",
      "B_18\n",
      "B_19\n",
      "D_66\n",
      "B_20\n",
      "D_68\n",
      "S_12\n",
      "R_6\n",
      "S_13\n",
      "B_21\n",
      "D_69\n",
      "B_22\n",
      "D_70\n",
      "D_71\n",
      "D_72\n",
      "S_15\n",
      "B_23\n",
      "D_73\n",
      "P_4\n",
      "D_74\n",
      "D_75\n",
      "D_76\n",
      "B_24\n",
      "R_7\n",
      "D_77\n",
      "B_25\n",
      "B_26\n",
      "D_78\n",
      "D_79\n",
      "R_8\n",
      "R_9\n",
      "S_16\n",
      "D_80\n",
      "R_10\n",
      "R_11\n",
      "B_27\n",
      "D_81\n",
      "D_82\n",
      "S_17\n",
      "R_12\n",
      "B_28\n",
      "R_13\n",
      "D_83\n",
      "R_14\n",
      "R_15\n",
      "D_84\n",
      "R_16\n",
      "B_29\n",
      "B_30\n",
      "S_18\n",
      "D_86\n",
      "D_87\n",
      "R_17\n",
      "R_18\n",
      "D_88\n",
      "B_31\n",
      "S_19\n",
      "R_19\n",
      "B_32\n",
      "S_20\n",
      "R_20\n",
      "R_21\n",
      "B_33\n",
      "D_89\n",
      "R_22\n",
      "R_23\n",
      "D_91\n",
      "D_92\n",
      "D_93\n",
      "D_94\n",
      "R_24\n",
      "R_25\n",
      "D_96\n",
      "S_22\n",
      "S_23\n",
      "S_24\n",
      "S_25\n",
      "S_26\n",
      "D_102\n",
      "D_103\n",
      "D_104\n",
      "D_105\n",
      "D_106\n",
      "D_107\n",
      "B_36\n",
      "B_37\n",
      "R_26\n",
      "R_27\n",
      "B_38\n",
      "D_108\n",
      "D_109\n",
      "D_110\n",
      "D_111\n",
      "B_39\n",
      "D_112\n",
      "B_40\n",
      "S_27\n",
      "D_113\n",
      "D_114\n",
      "D_115\n",
      "D_116\n",
      "D_117\n",
      "D_118\n",
      "D_119\n",
      "D_120\n",
      "D_121\n",
      "D_122\n",
      "D_123\n",
      "D_124\n",
      "D_125\n",
      "D_126\n",
      "D_127\n",
      "D_128\n",
      "D_129\n",
      "B_41\n",
      "B_42\n",
      "D_130\n",
      "D_131\n",
      "D_132\n",
      "D_133\n",
      "R_28\n",
      "D_134\n",
      "D_135\n",
      "D_136\n",
      "D_137\n",
      "D_138\n",
      "D_139\n",
      "D_140\n",
      "D_141\n",
      "D_142\n",
      "D_143\n",
      "D_144\n",
      "D_145\n",
      "target\n",
      "D_63_CO\n",
      "D_63_CR\n",
      "D_63_XL\n",
      "D_63_XM\n",
      "D_63_XZ\n",
      "D_64_O\n",
      "D_64_R\n",
      "D_64_U\n"
     ]
    }
   ],
   "source": [
    "for i in df_new.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset in Train, Test1 & Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-03-01 00:00:00')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['S_2'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_df = df_new.loc[(df_new['S_2'] >= '2017-05-01') & (df_new['S_2'] <= '2018-01-31'), :]\n",
    "test1_df = df_new.loc[(df_new['S_2'] <= '2017-04-30') , :]\n",
    "test2_df = df_new.loc[ (df_new['S_2'] >= '2018-02-01'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308200, 197)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61963, 197)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88750, 197)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458913"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "308200 + 61963 + 88750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388723"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "269243 +30730 +88750\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-31 00:00:00')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['S_2'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train_df.drop(columns = ['target', 'customer_ID', 'S_2'])\n",
    "ytrain = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308200, 194)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=21, ...)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = xgb.XGBClassifier(random_state = 21, scale_pos_weight = 0.5)\n",
    "mm.fit(xtest1, ytest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>feat_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P_2</td>\n",
       "      <td>0.278974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>B_17</td>\n",
       "      <td>0.045130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>D_45</td>\n",
       "      <td>0.039840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>D_53</td>\n",
       "      <td>0.027651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>D_42</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S_3</td>\n",
       "      <td>0.025120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D_88</td>\n",
       "      <td>0.024469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>D_66</td>\n",
       "      <td>0.024159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>B_1</td>\n",
       "      <td>0.023788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D_132</td>\n",
       "      <td>0.021415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>B_18</td>\n",
       "      <td>0.020171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   columns  feat_imp\n",
       "5      P_2  0.278974\n",
       "32    B_17  0.045130\n",
       "43    D_45  0.039840\n",
       "26    D_53  0.027651\n",
       "44    D_42  0.025641\n",
       "18     S_3  0.025120\n",
       "8     D_88  0.024469\n",
       "23    D_66  0.024159\n",
       "27     B_1  0.023788\n",
       "0    D_132  0.021415\n",
       "40    B_18  0.020171"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.DataFrame({'columns': xtest1.columns, 'feat_imp': mm.feature_importances_})\n",
    "fi.loc[fi['feat_imp'] > 0.02,:].sort_values(['feat_imp'], ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244.67144799232483\n"
     ]
    }
   ],
   "source": [
    "t1 = t.time()\n",
    "m1 = xgb.XGBClassifier(random_state = 21)\n",
    "m1.fit(xtrain, ytrain)\n",
    "feat_imp = pd.DataFrame({'columns': xtrain.columns, 'feat_imp': m1.feature_importances_})\n",
    "feat_imp.loc[feat_imp['feat_imp'] > 0.005,:].sort_values(['feat_imp'], ascending = False)\n",
    "feat_imp.to_csv('feat_imp.csv')\n",
    "t2 = t.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(m1.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = pd.read_csv('feat_imp.csv')\n",
    "feat_imp.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "feat_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.sort_values(['feat_imp'], ascending = False, inplace = True)\n",
    "feat_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function xlabel in module matplotlib.pyplot:\n",
      "\n",
      "xlabel(xlabel, fontdict=None, labelpad=None, *, loc=None, **kwargs)\n",
      "    Set the label for the x-axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    xlabel : str\n",
      "        The label text.\n",
      "    \n",
      "    labelpad : float, default: None\n",
      "        Spacing in points from the axes bounding box including ticks\n",
      "        and tick labels.\n",
      "    \n",
      "    loc : {'left', 'center', 'right'}, default: :rc:`xaxis.labellocation`\n",
      "        The label position. This is a high-level alternative for passing\n",
      "        parameters *x* and *horizontalalignment*.\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    **kwargs : `.Text` properties\n",
      "        `.Text` properties control the appearance of the label.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    text : Documents the properties supported by `.Text`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(plt.xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Feature Importance: Model 1 Default Params')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.barh(feat_imp.iloc[ :10, 0][::-1], feat_imp.iloc[:10, 1][::-1])\n",
    "plt.xlabel(\"Feature Importance: Model 1 Default Params\", fontdict = {'family':'sanserif','color':'black','size':15} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on XGBClassifier in module xgboost.sklearn object:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  XGBClassifier(*, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: Union[bool, NoneType] = None, **kwargs: Any) -> None\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |      n_estimators : int\n",
      " |          Number of boosting rounds.\n",
      " |  \n",
      " |      max_depth :  Optional[int]\n",
      " |          Maximum tree depth for base learners.\n",
      " |      max_leaves :\n",
      " |          Maximum number of leaves; 0 indicates no limit.\n",
      " |      max_bin :\n",
      " |          If using histogram-based algorithm, maximum number of bins per feature\n",
      " |      grow_policy :\n",
      " |          Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow\n",
      " |          depth-wise. 1: favor splitting at nodes with highest loss change.\n",
      " |      learning_rate : Optional[float]\n",
      " |          Boosting learning rate (xgb's \"eta\")\n",
      " |      verbosity : Optional[int]\n",
      " |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      " |      objective : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      " |          Specify the learning task and the corresponding learning objective or\n",
      " |          a custom objective function to be used (see note below).\n",
      " |      booster: Optional[str]\n",
      " |          Specify which booster to use: gbtree, gblinear or dart.\n",
      " |      tree_method: Optional[str]\n",
      " |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      " |          default, XGBoost will choose the most conservative option available.  It's\n",
      " |          recommended to study this option from the parameters document :doc:`tree method\n",
      " |          </treemethod>`\n",
      " |      n_jobs : Optional[int]\n",
      " |          Number of parallel threads used to run xgboost.  When used with other\n",
      " |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      " |          parallelize and balance the threads.  Creating thread contention will\n",
      " |          significantly slow down both algorithms.\n",
      " |      gamma : Optional[float]\n",
      " |          (min_split_loss) Minimum loss reduction required to make a further partition on a\n",
      " |          leaf node of the tree.\n",
      " |      min_child_weight : Optional[float]\n",
      " |          Minimum sum of instance weight(hessian) needed in a child.\n",
      " |      max_delta_step : Optional[float]\n",
      " |          Maximum delta step we allow each tree's weight estimation to be.\n",
      " |      subsample : Optional[float]\n",
      " |          Subsample ratio of the training instance.\n",
      " |      sampling_method :\n",
      " |          Sampling method. Used only by `gpu_hist` tree method.\n",
      " |            - `uniform`: select random training instances uniformly.\n",
      " |            - `gradient_based` select random training instances with higher probability when\n",
      " |              the gradient and hessian are larger. (cf. CatBoost)\n",
      " |      colsample_bytree : Optional[float]\n",
      " |          Subsample ratio of columns when constructing each tree.\n",
      " |      colsample_bylevel : Optional[float]\n",
      " |          Subsample ratio of columns for each level.\n",
      " |      colsample_bynode : Optional[float]\n",
      " |          Subsample ratio of columns for each split.\n",
      " |      reg_alpha : Optional[float]\n",
      " |          L1 regularization term on weights (xgb's alpha).\n",
      " |      reg_lambda : Optional[float]\n",
      " |          L2 regularization term on weights (xgb's lambda).\n",
      " |      scale_pos_weight : Optional[float]\n",
      " |          Balancing of positive and negative weights.\n",
      " |      base_score : Optional[float]\n",
      " |          The initial prediction score of all instances, global bias.\n",
      " |      random_state : Optional[Union[numpy.random.RandomState, int]]\n",
      " |          Random number seed.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      " |             it uses Hogwild algorithm.\n",
      " |  \n",
      " |      missing : float, default np.nan\n",
      " |          Value in the data which needs to be present as a missing value.\n",
      " |      num_parallel_tree: Optional[int]\n",
      " |          Used for boosting random forest.\n",
      " |      monotone_constraints : Optional[Union[Dict[str, int], str]]\n",
      " |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      " |          for more information.\n",
      " |      interaction_constraints : Optional[Union[str, List[Tuple[str]]]]\n",
      " |          Constraints for interaction representing permitted interactions.  The\n",
      " |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      " |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      " |          allowed to interact with each other.  See :doc:`tutorial\n",
      " |          </tutorials/feature_interaction_constraint>` for more information\n",
      " |      importance_type: Optional[str]\n",
      " |          The feature importance type for the feature_importances\\_ property:\n",
      " |  \n",
      " |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      " |            \"total_cover\".\n",
      " |          * For linear model, only \"weight\" is defined and it's the normalized coefficients\n",
      " |            without bias.\n",
      " |  \n",
      " |      gpu_id : Optional[int]\n",
      " |          Device ordinal.\n",
      " |      validate_parameters : Optional[bool]\n",
      " |          Give warnings for unknown parameter.\n",
      " |      predictor : Optional[str]\n",
      " |          Force XGBoost to use specific predictor, available choices are [cpu_predictor,\n",
      " |          gpu_predictor].\n",
      " |      enable_categorical : bool\n",
      " |  \n",
      " |          .. versionadded:: 1.5.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame\n",
      " |          should be used to specify categorical data type.  Also, JSON/UBJSON\n",
      " |          serialization format is required.\n",
      " |  \n",
      " |      feature_types : FeatureTypes\n",
      " |  \n",
      " |          .. versionadded:: 1.7.0\n",
      " |  \n",
      " |          Used for specifying feature types without constructing a dataframe. See\n",
      " |          :py:class:`DMatrix` for details.\n",
      " |  \n",
      " |      max_cat_to_onehot : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      " |          for categorical data.  When number of categories is lesser than the threshold\n",
      " |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      " |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      " |          categorical feature support. See :doc:`Categorical Data\n",
      " |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      " |  \n",
      " |      max_cat_threshold : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.7.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          Maximum number of categories considered for each split. Used only by\n",
      " |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      " |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      " |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      " |  \n",
      " |      eval_metric : Optional[Union[str, List[str], Callable]]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      " |          string or list of strings as names of predefined metric in XGBoost (See\n",
      " |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any other\n",
      " |          user defined metric that looks like `sklearn.metrics`.\n",
      " |  \n",
      " |          If custom objective is also provided, then custom metric should implement the\n",
      " |          corresponding reverse link function.\n",
      " |  \n",
      " |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      " |          object is provided, it's assumed to be a cost function and by default XGBoost will\n",
      " |          minimize the result during early stopping.\n",
      " |  \n",
      " |          For advanced usage on Early stopping like directly choosing to maximize instead of\n",
      " |          minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      " |  \n",
      " |          See :doc:`Custom Objective and Evaluation Metric </tutorials/custom_metric_obj>`\n",
      " |          for more.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |               This parameter replaces `eval_metric` in :py:meth:`fit` method.  The old one\n",
      " |               receives un-transformed prediction regardless of whether custom objective is\n",
      " |               being used.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              from sklearn.datasets import load_diabetes\n",
      " |              from sklearn.metrics import mean_absolute_error\n",
      " |              X, y = load_diabetes(return_X_y=True)\n",
      " |              reg = xgb.XGBRegressor(\n",
      " |                  tree_method=\"hist\",\n",
      " |                  eval_metric=mean_absolute_error,\n",
      " |              )\n",
      " |              reg.fit(X, y, eval_set=[(X, y)])\n",
      " |  \n",
      " |      early_stopping_rounds : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Activates early stopping. Validation metric needs to improve at least once in\n",
      " |          every **early_stopping_rounds** round(s) to continue training.  Requires at least\n",
      " |          one item in **eval_set** in :py:meth:`fit`.\n",
      " |  \n",
      " |          The method returns the model from the last iteration (not the best one).  If\n",
      " |          there's more than one item in **eval_set**, the last entry will be used for early\n",
      " |          stopping.  If there's more than one metric in **eval_metric**, the last metric\n",
      " |          will be used for early stopping.\n",
      " |  \n",
      " |          If early stopping occurs, the model will have three additional fields:\n",
      " |          :py:attr:`best_score`, :py:attr:`best_iteration` and\n",
      " |          :py:attr:`best_ntree_limit`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |              This parameter replaces `early_stopping_rounds` in :py:meth:`fit` method.\n",
      " |  \n",
      " |      callbacks : Optional[List[TrainingCallback]]\n",
      " |          List of callback functions that are applied at end of each iteration.\n",
      " |          It is possible to use predefined callbacks by using\n",
      " |          :ref:`Callback API <callback_api>`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             States in callback are not preserved during training, which means callback\n",
      " |             objects can not be reused for multiple training sessions without\n",
      " |             reinitialization or deepcopy.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              for params in parameters_grid:\n",
      " |                  # be sure to (re)initialize the callbacks before each run\n",
      " |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      " |                  xgboost.train(params, Xy, callbacks=callbacks)\n",
      " |  \n",
      " |      kwargs : dict, optional\n",
      " |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      " |          can be found :doc:`here </parameter>`.\n",
      " |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      " |          dict simultaneously will result in a TypeError.\n",
      " |  \n",
      " |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      " |  \n",
      " |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      " |              that parameters passed via this argument will interact properly\n",
      " |              with scikit-learn.\n",
      " |  \n",
      " |          .. note::  Custom objective function\n",
      " |  \n",
      " |              A custom objective function can be provided for the ``objective``\n",
      " |              parameter. In this case, it should have the signature\n",
      " |              ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |              y_true: array_like of shape [n_samples]\n",
      " |                  The target values\n",
      " |              y_pred: array_like of shape [n_samples]\n",
      " |                  The predicted values\n",
      " |  \n",
      " |              grad: array_like of shape [n_samples]\n",
      " |                  The value of the gradient for each sample point.\n",
      " |              hess: array_like of shape [n_samples]\n",
      " |                  The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: Union[bool, NoneType] = None, **kwargs: Any) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X: Any, y: Any, *, sample_weight: Union[Any, NoneType] = None, base_margin: Union[Any, NoneType] = None, eval_set: Union[Sequence[Tuple[Any, Any]], NoneType] = None, eval_metric: Union[str, Sequence[str], Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None, early_stopping_rounds: Union[int, NoneType] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Union[Sequence[Any], NoneType] = None, base_margin_eval_set: Union[Sequence[Any], NoneType] = None, feature_weights: Union[Any, NoneType] = None, callbacks: Union[Sequence[xgboost.callback.TrainingCallback], NoneType] = None) -> 'XGBClassifier'\n",
      " |      Fit gradient boosting classifier.\n",
      " |      \n",
      " |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      " |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      " |      pass ``xgb_model`` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Feature matrix\n",
      " |      y :\n",
      " |          Labels\n",
      " |      sample_weight :\n",
      " |          instance weights\n",
      " |      base_margin :\n",
      " |          global bias for each instance.\n",
      " |      eval_set :\n",
      " |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      " |          metrics will be computed.\n",
      " |          Validation metrics will help us track the performance of the model.\n",
      " |      \n",
      " |      eval_metric : str, list of str, or callable, optional\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `eval_metric` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |      \n",
      " |      early_stopping_rounds : int\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `early_stopping_rounds` in :py:meth:`__init__` or\n",
      " |              :py:meth:`set_params` instead.\n",
      " |      verbose :\n",
      " |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      " |          measured on the validation set is printed to stdout at each boosting stage.\n",
      " |          If `verbose` is an integer, the evaluation metric is printed at each `verbose`\n",
      " |          boosting stage. The last boosting stage / the boosting stage found by using\n",
      " |          `early_stopping_rounds` is also printed.\n",
      " |      xgb_model :\n",
      " |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |      sample_weight_eval_set :\n",
      " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      " |          object storing instance weights for the i-th validation set.\n",
      " |      base_margin_eval_set :\n",
      " |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      " |          object storing base margin for the i-th validation set.\n",
      " |      feature_weights :\n",
      " |          Weight for each feature, defines the probability of each feature being\n",
      " |          selected when colsample is being used.  All values must be greater than 0,\n",
      " |          otherwise a `ValueError` is thrown.\n",
      " |      \n",
      " |      callbacks :\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `callbacks` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |  \n",
      " |  predict(self, X: Any, output_margin: bool = False, ntree_limit: Union[int, NoneType] = None, validate_features: bool = True, base_margin: Union[Any, NoneType] = None, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Predict with `X`.  If the model is trained with early stopping, then `best_iteration`\n",
      " |      is used automatically.  For tree models, when data is on GPU, like cupy array or\n",
      " |      cuDF dataframe and `predictor` is not specified, the prediction is run on GPU\n",
      " |      automatically, otherwise it will run on CPU.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Data to predict with.\n",
      " |      output_margin :\n",
      " |          Whether to output the raw untransformed margin value.\n",
      " |      ntree_limit :\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features :\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin :\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      " |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      " |          are used in this prediction.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction\n",
      " |  \n",
      " |  predict_proba(self, X: Any, ntree_limit: Union[int, NoneType] = None, validate_features: bool = True, base_margin: Union[Any, NoneType] = None, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Predict the probability of each `X` example being of a given class.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix.\n",
      " |      ntree_limit : int\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin : array_like\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      " |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      " |          used in this prediction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      " |          probability of each data example being of a given class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __sklearn_is_fitted__(self) -> bool\n",
      " |  \n",
      " |  apply(self, X: Any, ntree_limit: int = 0, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Return the predicted leaf every tree for each sample. If the model is trained with\n",
      " |      early stopping, then `best_iteration` is used automatically.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      iteration_range :\n",
      " |          See :py:meth:`predict`.\n",
      " |      \n",
      " |      ntree_limit :\n",
      " |          Deprecated, use ``iteration_range`` instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      " |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      " |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      " |      function.\n",
      " |      \n",
      " |      The returned evaluation result is a dictionary:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result\n",
      " |  \n",
      " |  get_booster(self) -> xgboost.core.Booster\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_num_boosting_rounds(self) -> int\n",
      " |      Gets the number of xgboost boosting rounds.\n",
      " |  \n",
      " |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self) -> Dict[str, Any]\n",
      " |      Get xgboost specific parameters.\n",
      " |  \n",
      " |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      " |      Load the model from a file or bytearray. Path to file can be local\n",
      " |      or as an URI.\n",
      " |      \n",
      " |      The model is loaded from XGBoost format which is universal among the various\n",
      " |      XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as\n",
      " |      feature_names) will not be loaded when using binary format.  To save those\n",
      " |      attributes, use JSON/UBJ instead.  See :doc:`Model IO </tutorials/saving_model>`\n",
      " |      for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.load_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.load_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname :\n",
      " |          Input file name or memory buffer(see also save_raw)\n",
      " |  \n",
      " |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      The model is saved in an XGBoost internal format which is universal among the\n",
      " |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      " |      (such as feature_names) will not be saved when using binary format.  To save\n",
      " |      those attributes, use JSON/UBJ instead. See :doc:`Model IO\n",
      " |      </tutorials/saving_model>` for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.save_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.save_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or os.PathLike\n",
      " |          Output file name\n",
      " |  \n",
      " |  set_params(self, **params: Any) -> 'XGBModel'\n",
      " |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      " |      allow unknown kwargs. This allows using the full range of xgboost\n",
      " |      parameters that are not defined as member variables in sklearn grid\n",
      " |      search.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from XGBModel:\n",
      " |  \n",
      " |  best_iteration\n",
      " |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      " |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      " |  \n",
      " |  best_ntree_limit\n",
      " |  \n",
      " |  best_score\n",
      " |      The best score obtained by early stopping.\n",
      " |  \n",
      " |  coef_\n",
      " |      Coefficients property\n",
      " |      \n",
      " |      .. note:: Coefficients are defined only for linear learners\n",
      " |      \n",
      " |          Coefficients are only defined when the linear model is chosen as\n",
      " |          base learner (`booster=gblinear`). It is not defined for other base\n",
      " |          learner types, such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Feature importances property, return depends on `importance_type`\n",
      " |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      " |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      " |      based on the importance type. For instance, if the importance type is\n",
      " |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      " |      trees.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      " |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      " |  \n",
      " |  feature_names_in_\n",
      " |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has feature\n",
      " |      names that are all strings.\n",
      " |  \n",
      " |  intercept_\n",
      " |      Intercept (bias) property\n",
      " |      \n",
      " |      .. note:: Intercept is defined only for linear learners\n",
      " |      \n",
      " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types,\n",
      " |          such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :py:meth:`fit`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.81300926208496\n"
     ]
    }
   ],
   "source": [
    "t1 = t.time()\n",
    "m2 = xgb.XGBClassifier(n_estimators = 300, learning_rate = 0.5, \n",
    "                       max_depth = 4, subsample = .5, colsample_bytree = 0.5, scale_pos_weight = 5, random_state =21 )\n",
    "m2.fit(xtrain, ytrain)\n",
    "feat_imp1 = pd.DataFrame({'columns': xtrain.columns, 'feat_imp': m2.feature_importances_})\n",
    "feat_imp1.loc[feat_imp1['feat_imp'] > 0.005,:].sort_values(['feat_imp'], ascending = False)\n",
    "feat_imp1.to_csv('feat_imp1.csv')\n",
    "t2 = t.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp1.sort_values(['feat_imp'], ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308200, 194)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([193, 189, 188, 108, 101, 153,  58, 186, 135,  95, 178,  36, 112,\n",
       "       163,  94, 137,  68, 129,  41,  92])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort = m2.feature_importances_.argsort()\n",
    "sort[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        P_2\n",
       "2        B_1\n",
       "8       D_42\n",
       "7        B_3\n",
       "53      B_17\n",
       "5        S_3\n",
       "56      D_66\n",
       "69      B_23\n",
       "171    D_132\n",
       "141     B_38\n",
       "Name: columns, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp1.iloc[ :10, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Feature Importance: Model 2 custom Params')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sanserif'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.barh(feat_imp1.iloc[ :10, 0][::-1], feat_imp1.iloc[:10, 1][::-1])\n",
    "plt.xlabel(\"Feature Importance: Model 2 custom Params\", fontdict = {'family':'sanserif','color':'black','size':15} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415602, 190)\n",
      "31.137080669403076\n"
     ]
    }
   ],
   "source": [
    "start = t.time()\n",
    "df_rnd1 = train.loc[(train['S_2'].dt.year == 2017) & (train['S_2'].dt.month == 7), :]\n",
    "print(df_rnd1.shape)\n",
    "end = t.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>R_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>S_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>D_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>B_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>D_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>D_43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>D_44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>B_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>D_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>B_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>D_46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>D_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>D_49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>D_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>R_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>D_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>D_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>D_56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>D_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53</td>\n",
       "      <td>B_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54</td>\n",
       "      <td>B_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>56</td>\n",
       "      <td>D_66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>69</td>\n",
       "      <td>B_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107</td>\n",
       "      <td>D_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127</td>\n",
       "      <td>S_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>128</td>\n",
       "      <td>S_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>140</td>\n",
       "      <td>R_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>141</td>\n",
       "      <td>B_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>142</td>\n",
       "      <td>D_108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>144</td>\n",
       "      <td>D_110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>147</td>\n",
       "      <td>D_112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>171</td>\n",
       "      <td>D_132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>191</td>\n",
       "      <td>D_64_O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index columns\n",
       "0       0     P_2\n",
       "1       2     B_1\n",
       "2       4     R_1\n",
       "3       5     S_3\n",
       "4       6    D_41\n",
       "5       7     B_3\n",
       "6       8    D_42\n",
       "7       9    D_43\n",
       "8      10    D_44\n",
       "9      11     B_4\n",
       "10     12    D_45\n",
       "11     13     B_5\n",
       "12     15    D_46\n",
       "13     17    D_48\n",
       "14     18    D_49\n",
       "15     23    D_51\n",
       "16     25     R_3\n",
       "17     26    D_52\n",
       "18     29    D_53\n",
       "19     39    D_56\n",
       "20     50    D_62\n",
       "21     53    B_17\n",
       "22     54    B_18\n",
       "23     56    D_66\n",
       "24     69    B_23\n",
       "25    107    D_88\n",
       "26    127    S_23\n",
       "27    128    S_24\n",
       "28    140    R_27\n",
       "29    141    B_38\n",
       "30    142   D_108\n",
       "31    144   D_110\n",
       "32    147   D_112\n",
       "33    171   D_132\n",
       "34    191  D_64_O"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp1.loc[feat_imp1['feat_imp'] > 0.005, 'columns'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>R_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>S_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>D_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>B_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>D_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>D_43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>D_44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>B_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>D_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>B_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>D_46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>D_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>D_49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>D_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>R_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>D_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>D_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>D_56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>D_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53</td>\n",
       "      <td>B_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54</td>\n",
       "      <td>B_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>56</td>\n",
       "      <td>D_66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>69</td>\n",
       "      <td>B_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107</td>\n",
       "      <td>D_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127</td>\n",
       "      <td>S_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>128</td>\n",
       "      <td>S_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>140</td>\n",
       "      <td>R_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>141</td>\n",
       "      <td>B_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>142</td>\n",
       "      <td>D_108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>144</td>\n",
       "      <td>D_110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>147</td>\n",
       "      <td>D_112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>171</td>\n",
       "      <td>D_132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>191</td>\n",
       "      <td>D_64_O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index columns\n",
       "0       0     P_2\n",
       "1       2     B_1\n",
       "2       4     R_1\n",
       "3       5     S_3\n",
       "4       6    D_41\n",
       "5       7     B_3\n",
       "6       8    D_42\n",
       "7       9    D_43\n",
       "8      10    D_44\n",
       "9      11     B_4\n",
       "10     12    D_45\n",
       "11     13     B_5\n",
       "12     15    D_46\n",
       "13     17    D_48\n",
       "14     18    D_49\n",
       "15     23    D_51\n",
       "16     25     R_3\n",
       "17     26    D_52\n",
       "18     29    D_53\n",
       "19     39    D_56\n",
       "20     50    D_62\n",
       "21     53    B_17\n",
       "22     54    B_18\n",
       "23     56    D_66\n",
       "24     69    B_23\n",
       "25    107    D_88\n",
       "26    127    S_23\n",
       "27    128    S_24\n",
       "28    140    R_27\n",
       "29    141    B_38\n",
       "30    142   D_108\n",
       "31    144   D_110\n",
       "32    147   D_112\n",
       "33    171   D_132\n",
       "34    191  D_64_O"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.loc[feat_imp1['feat_imp'] > 0.005, 'columns'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D_132', 'P_3', 'D_44', 'D_64_O', 'D_52', 'P_2', 'D_56', 'B_23', 'D_88', 'R_1', 'D_76', 'D_110', 'D_77', 'D_62', 'B_11', 'B_2', 'D_51', 'D_108', 'S_3', 'D_50', 'R_3', 'B_3', 'D_49', 'D_66', 'B_38', 'D_75', 'D_53', 'B_1', 'B_4', 'D_111', 'D_134', 'D_41', 'B_17', 'D_46', 'B_5', 'D_43', 'S_23', 'B_9', 'D_48', 'R_27', 'B_18', 'D_112', 'D_47', 'D_45', 'D_42', 'S_24']\n"
     ]
    }
   ],
   "source": [
    "col = list(set(feat_imp1.loc[feat_imp1['feat_imp'] > 0.005, 'columns'].to_list()).union(set(feat_imp.loc[feat_imp['feat_imp'] > 0.005, 'columns'].to_list())))\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 197)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_ID\n",
      "S_2\n",
      "P_2\n",
      "P_2\n",
      "D_39\n",
      "B_1\n",
      "B_2\n",
      "R_1\n",
      "S_3\n",
      "D_41\n",
      "B_3\n",
      "D_42\n",
      "D_43\n",
      "D_44\n",
      "B_4\n",
      "D_45\n",
      "B_5\n",
      "R_2\n",
      "D_46\n",
      "D_47\n",
      "D_48\n",
      "D_49\n",
      "B_6\n",
      "B_7\n",
      "B_8\n",
      "D_50\n",
      "D_51\n",
      "B_9\n",
      "R_3\n",
      "D_52\n",
      "P_3\n",
      "P_3\n",
      "B_10\n",
      "D_53\n",
      "S_5\n",
      "B_11\n",
      "S_6\n",
      "D_54\n",
      "R_4\n",
      "S_7\n",
      "B_12\n",
      "S_8\n",
      "D_55\n",
      "D_56\n",
      "B_13\n",
      "R_5\n",
      "D_58\n",
      "S_9\n",
      "B_14\n",
      "D_59\n",
      "D_60\n",
      "D_61\n",
      "B_15\n",
      "S_11\n",
      "D_62\n",
      "D_65\n",
      "B_16\n",
      "B_17\n",
      "B_18\n",
      "B_19\n",
      "D_66\n",
      "B_20\n",
      "D_68\n",
      "S_12\n",
      "R_6\n",
      "S_13\n",
      "B_21\n",
      "D_69\n",
      "B_22\n",
      "D_70\n",
      "D_71\n",
      "D_72\n",
      "S_15\n",
      "B_23\n",
      "D_73\n",
      "P_4\n",
      "P_4\n",
      "D_74\n",
      "D_75\n",
      "D_76\n",
      "B_24\n",
      "R_7\n",
      "D_77\n",
      "B_25\n",
      "B_26\n",
      "D_78\n",
      "D_79\n",
      "R_8\n",
      "R_9\n",
      "S_16\n",
      "D_80\n",
      "R_10\n",
      "R_11\n",
      "B_27\n",
      "D_81\n",
      "D_82\n",
      "S_17\n",
      "R_12\n",
      "B_28\n",
      "R_13\n",
      "D_83\n",
      "R_14\n",
      "R_15\n",
      "D_84\n",
      "R_16\n",
      "B_29\n",
      "B_30\n",
      "S_18\n",
      "D_86\n",
      "D_87\n",
      "R_17\n",
      "R_18\n",
      "D_88\n",
      "B_31\n",
      "S_19\n",
      "R_19\n",
      "B_32\n",
      "S_20\n",
      "R_20\n",
      "R_21\n",
      "B_33\n",
      "D_89\n",
      "R_22\n",
      "R_23\n",
      "D_91\n",
      "D_92\n",
      "D_93\n",
      "D_94\n",
      "R_24\n",
      "R_25\n",
      "D_96\n",
      "S_22\n",
      "S_23\n",
      "S_24\n",
      "S_25\n",
      "S_26\n",
      "D_102\n",
      "D_103\n",
      "D_104\n",
      "D_105\n",
      "D_106\n",
      "D_107\n",
      "B_36\n",
      "B_37\n",
      "R_26\n",
      "R_27\n",
      "B_38\n",
      "D_108\n",
      "D_109\n",
      "D_110\n",
      "D_111\n",
      "B_39\n",
      "D_112\n",
      "B_40\n",
      "S_27\n",
      "D_113\n",
      "D_114\n",
      "D_115\n",
      "D_116\n",
      "D_117\n",
      "D_118\n",
      "D_119\n",
      "D_120\n",
      "D_121\n",
      "D_122\n",
      "D_123\n",
      "D_124\n",
      "D_125\n",
      "D_126\n",
      "D_127\n",
      "D_128\n",
      "D_129\n",
      "B_41\n",
      "B_42\n",
      "D_130\n",
      "D_131\n",
      "D_132\n",
      "D_133\n",
      "R_28\n",
      "D_134\n",
      "D_135\n",
      "D_136\n",
      "D_137\n",
      "D_138\n",
      "D_139\n",
      "D_140\n",
      "D_141\n",
      "D_142\n",
      "D_143\n",
      "D_144\n",
      "D_145\n",
      "target\n",
      "D_63_CO\n",
      "D_63_CR\n",
      "D_63_XL\n",
      "D_63_XM\n",
      "D_63_XZ\n",
      "D_64_O\n",
      "D_64_R\n",
      "D_64_U\n",
      "D_132\n",
      "P_3\n",
      "P_3\n",
      "D_44\n",
      "D_64_O\n",
      "D_52\n",
      "P_2\n",
      "P_2\n",
      "D_56\n",
      "B_23\n",
      "D_88\n",
      "R_1\n",
      "D_76\n",
      "D_110\n",
      "D_77\n",
      "D_62\n",
      "B_11\n",
      "B_2\n",
      "D_51\n",
      "D_108\n",
      "S_3\n",
      "D_50\n",
      "R_3\n",
      "B_3\n",
      "D_49\n",
      "D_66\n",
      "B_38\n",
      "D_75\n",
      "D_53\n",
      "B_1\n",
      "B_4\n",
      "D_111\n",
      "D_134\n",
      "D_41\n",
      "B_17\n",
      "D_46\n",
      "B_5\n",
      "D_43\n",
      "S_23\n",
      "B_9\n",
      "D_48\n",
      "R_27\n",
      "B_18\n",
      "D_112\n",
      "D_47\n",
      "D_45\n",
      "D_42\n",
      "S_24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th># of Features</th>\n",
       "      <th># Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delinquency</td>\n",
       "      <td>103</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spend</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Payment</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balance</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Risk</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  # of Features  # Selected\n",
       "0  Delinquency            103          27\n",
       "1        Spend             22           3\n",
       "2      Payment              3           2\n",
       "3      Balance             40          11\n",
       "4         Risk             29           3"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(columns = ['Category', '# of Features', '# Selected'])\n",
    "features['Category'] = ['Delinquency', 'Spend', 'Payment', 'Balance', 'Risk']\n",
    "features['# of Features'] = 0 \n",
    "features['# Selected'] = 0 \n",
    "\n",
    "for i in df_new.columns:\n",
    "    print(i)\n",
    "    if 'P' in i: \n",
    "        print(i)\n",
    "        features.loc[features['Category'] == 'Payment', '# of Features'] += 1\n",
    "    elif 'S' in i: \n",
    "        features.loc[features['Category'] == 'Spend', '# of Features'] += 1\n",
    "    elif 'D' in i: \n",
    "        features.loc[features['Category'] == 'Delinquency', '# of Features'] += 1\n",
    "    elif 'B' in i: \n",
    "        features.loc[features['Category'] == 'Balance', '# of Features'] += 1\n",
    "    else: \n",
    "        features.loc[features['Category'] == 'Risk', '# of Features'] += 1\n",
    "        \n",
    "for i in col:\n",
    "    print(i)\n",
    "    if 'P' in i: \n",
    "        print(i)\n",
    "        features.loc[features['Category'] == 'Payment', '# Selected'] += 1\n",
    "    elif 'S' in i: \n",
    "        features.loc[features['Category'] == 'Spend', '# Selected'] += 1\n",
    "    elif 'D' in i: \n",
    "        features.loc[features['Category'] == 'Delinquency', '# Selected'] += 1\n",
    "    elif 'B' in i: \n",
    "        features.loc[features['Category'] == 'Balance', '# Selected'] += 1\n",
    "    else: \n",
    "        features.loc[features['Category'] == 'Risk', '# Selected'] += 1\n",
    "                \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th># of Features</th>\n",
       "      <th># Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delinquency</td>\n",
       "      <td>103</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spend</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Payment</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balance</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Risk</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  # of Features  # Selected\n",
       "0  Delinquency            103          27\n",
       "1        Spend             22           3\n",
       "2      Payment              3           2\n",
       "3      Balance             40          11\n",
       "4         Risk             29           3"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 46)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_new.loc[:, col]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308200, 197)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train_df[col]\n",
    "xtest1 = test1_df[col]\n",
    "xtest2 = test2_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = train_df['target']\n",
    "ytest1 = test1_df['target']\n",
    "ytest2 = test2_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.to_csv('xtrain.csv', index = False)\n",
    "xtest1.to_csv('xtest1.csv', index = False)\n",
    "xtest2.to_csv('xtest2.csv', index = False)\n",
    "ytest1.to_csv('ytest1.csv', index = False)\n",
    "ytest2.to_csv('ytest2.csv', index = False)\n",
    "ytrain.to_csv('ytrain.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_ID', 'S_2', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41',\n",
       "       'B_3',\n",
       "       ...\n",
       "       'D_145', 'target', 'D_63_CO', 'D_63_CR', 'D_63_XL', 'D_63_XM',\n",
       "       'D_63_XZ', 'D_64_O', 'D_64_R', 'D_64_U'],\n",
       "      dtype='object', length=197)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269243, 44)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269243,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "5585.973841905594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Trees</th>\n",
       "      <th>LR</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>%features</th>\n",
       "      <th>Default Weight</th>\n",
       "      <th>AUC Train</th>\n",
       "      <th>AUC Test1</th>\n",
       "      <th>AUC Test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930397</td>\n",
       "      <td>0.918615</td>\n",
       "      <td>0.933299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.928443</td>\n",
       "      <td>0.917089</td>\n",
       "      <td>0.93024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.914873</td>\n",
       "      <td>0.928382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925704</td>\n",
       "      <td>0.912868</td>\n",
       "      <td>0.92973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.923894</td>\n",
       "      <td>0.911928</td>\n",
       "      <td>0.92748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.955172</td>\n",
       "      <td>0.932711</td>\n",
       "      <td>0.94343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.953969</td>\n",
       "      <td>0.932288</td>\n",
       "      <td>0.943299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95728</td>\n",
       "      <td>0.933104</td>\n",
       "      <td>0.94379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.956434</td>\n",
       "      <td>0.933083</td>\n",
       "      <td>0.943606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.955314</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.942893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. of Trees    LR Subsample %features Default Weight AUC Train AUC Test1  \\\n",
       "0            50  0.01       0.5       0.5              1  0.930397  0.918615   \n",
       "1            50  0.01       0.5       0.5              5  0.928443  0.917089   \n",
       "2            50  0.01       0.5       0.5             10    0.9263  0.914873   \n",
       "3            50  0.01       0.5         1              1  0.925704  0.912868   \n",
       "4            50  0.01       0.5         1              5  0.923894  0.911928   \n",
       "..          ...   ...       ...       ...            ...       ...       ...   \n",
       "67          300   0.1       0.8       0.5              5  0.955172  0.932711   \n",
       "68          300   0.1       0.8       0.5             10  0.953969  0.932288   \n",
       "69          300   0.1       0.8         1              1   0.95728  0.933104   \n",
       "70          300   0.1       0.8         1              5  0.956434  0.933083   \n",
       "71          300   0.1       0.8         1             10  0.955314  0.932399   \n",
       "\n",
       "   AUC Test2  \n",
       "0   0.933299  \n",
       "1    0.93024  \n",
       "2   0.928382  \n",
       "3    0.92973  \n",
       "4    0.92748  \n",
       "..       ...  \n",
       "67   0.94343  \n",
       "68  0.943299  \n",
       "69   0.94379  \n",
       "70  0.943606  \n",
       "71  0.942893  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = t.time()\n",
    "grid_search = pd.DataFrame(columns = ['No. of Trees', 'LR', 'Subsample', '%features', 'Default Weight', 'AUC Train', 'AUC Test1', 'AUC Test2'])\n",
    "num_trees = [50, 100, 300]\n",
    "lr = [0.01, .1]\n",
    "subsample = [.5, .8]\n",
    "feat = [.5, 1]\n",
    "def_w = [1, 5, 10]\n",
    "\n",
    "row = 0\n",
    "for i in num_trees:\n",
    "    for j in lr:\n",
    "        for k in subsample:\n",
    "            for f in feat:\n",
    "                for d in def_w:\n",
    "                    xgb_inst = xgb.XGBClassifier(n_estimators = i, learning_rate = j, subsample = k, colsample_bytree = f, scale_pos_weight = d, random_state = 21)\n",
    "                    model = xgb_inst.fit(xtrain, ytrain)\n",
    "                    print(row)\n",
    "                    grid_search.loc[row, 'No. of Trees'] = i \n",
    "                    grid_search.loc[row, 'LR'] = j \n",
    "                    grid_search.loc[row, 'Subsample'] = k \n",
    "                    grid_search.loc[row, '%features'] = f \n",
    "                    grid_search.loc[row, 'Default Weight'] = d \n",
    "                    grid_search.loc[row,\"AUC Train\"] = roc_auc_score(ytrain, model.predict_proba(xtrain)[:,1])\n",
    "                    grid_search.loc[row,\"AUC Test1\"] = roc_auc_score(ytest1, model.predict_proba(xtest1)[:,1])\n",
    "                    grid_search.loc[row,\"AUC Test2\"] = roc_auc_score(ytest2, model.predict_proba(xtest2)[:,1])\n",
    "                    row += 1\n",
    "                    \n",
    "t2 = t.time()  \n",
    "print(t2-t1)\n",
    "grid_search\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.to_csv(\"grid_search.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Trees</th>\n",
       "      <th>LR</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>%features</th>\n",
       "      <th>Default Weight</th>\n",
       "      <th>AUC Train</th>\n",
       "      <th>AUC Test1</th>\n",
       "      <th>AUC Test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95728</td>\n",
       "      <td>0.933104</td>\n",
       "      <td>0.94379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956448</td>\n",
       "      <td>0.932729</td>\n",
       "      <td>0.943296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.956434</td>\n",
       "      <td>0.933083</td>\n",
       "      <td>0.943606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95546</td>\n",
       "      <td>0.932635</td>\n",
       "      <td>0.942838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.955314</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.942893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92457</td>\n",
       "      <td>0.912815</td>\n",
       "      <td>0.927678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.923894</td>\n",
       "      <td>0.911928</td>\n",
       "      <td>0.92748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.923329</td>\n",
       "      <td>0.911282</td>\n",
       "      <td>0.926616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.921244</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.925506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.920578</td>\n",
       "      <td>0.908623</td>\n",
       "      <td>0.924821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. of Trees    LR Subsample %features Default Weight AUC Train AUC Test1  \\\n",
       "69          300   0.1       0.8         1              1   0.95728  0.933104   \n",
       "63          300   0.1       0.5         1              1  0.956448  0.932729   \n",
       "70          300   0.1       0.8         1              5  0.956434  0.933083   \n",
       "64          300   0.1       0.5         1              5   0.95546  0.932635   \n",
       "71          300   0.1       0.8         1             10  0.955314  0.932399   \n",
       "..          ...   ...       ...       ...            ...       ...       ...   \n",
       "35          100  0.01       0.8         1             10   0.92457  0.912815   \n",
       "4            50  0.01       0.5         1              5  0.923894  0.911928   \n",
       "10           50  0.01       0.8         1              5  0.923329  0.911282   \n",
       "5            50  0.01       0.5         1             10  0.921244  0.909524   \n",
       "11           50  0.01       0.8         1             10  0.920578  0.908623   \n",
       "\n",
       "   AUC Test2  \n",
       "69   0.94379  \n",
       "63  0.943296  \n",
       "70  0.943606  \n",
       "64  0.942838  \n",
       "71  0.942893  \n",
       "..       ...  \n",
       "35  0.927678  \n",
       "4    0.92748  \n",
       "10  0.926616  \n",
       "5   0.925506  \n",
       "11  0.924821  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.sort_values(['AUC Train'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305782740137187"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.iloc[0, -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308200, 194)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_inst = xgb.XGBClassifier(n_estimators = 300, learning_rate = 0.1, subsample = 0.8, colsample_bytree = 1, scale_pos_weight = 1, random_state = 21)\n",
    "final_xgb = xgb_inst.fit(xtrain, ytrain)\n",
    "final_xgb.save_model(\"final_xgb.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest1 = pd.read_csv('xtest1.csv', index_col = False)\n",
    "xtest2 = pd.read_csv('xtest2.csv', index_col = False)\n",
    "ytest1 = pd.read_csv('ytest1.csv', index_col = False)\n",
    "ytest2 = pd.read_csv('ytest2.csv', index_col = False)\n",
    "ytrain = pd.read_csv('ytrain.csv', index_col = False)\n",
    "xtrain = pd.read_csv('xtrain.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb = xgb.XGBClassifier()\n",
    "final_xgb.load_model(\"final_xgb.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_xgb.predict_proba(xtrain)[:,1]\n",
    "ytest1_pred = final_xgb.predict_proba(xtest1)[:,1]\n",
    "ytest2_pred = final_xgb.predict_proba(xtest2)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00097135, 0.00388424, 0.002486  , ..., 0.003181  , 0.17033646,\n",
       "       0.00496028], dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308200, 1)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank Ordering\n",
    "perf_train_data = pd.DataFrame({\"Actual\": ytrain['target'], \"Prediction\": final_xgb.predict_proba(xtrain)[:,1]})\n",
    "quantiles = list(set(perf_train_data.Prediction.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])))\n",
    "quantiles.sort()\n",
    "quantiles.insert(0,0)\n",
    "quantiles.insert(len(quantiles),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.0013835063320584596,\n",
       " 0.002846248354762793,\n",
       " 0.0060503693297505375,\n",
       " 0.015027956664562227,\n",
       " 0.046310119330883026,\n",
       " 0.158120796084404,\n",
       " 0.3935984671115874,\n",
       " 0.6430687308311462,\n",
       " 0.8354373037815097,\n",
       " 1]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>Bad Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score Bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.00138]</th>\n",
       "      <td>3</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00138, 0.00285]</th>\n",
       "      <td>20</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00285, 0.00605]</th>\n",
       "      <td>61</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00605, 0.015]</th>\n",
       "      <td>146</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.004737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.015, 0.0463]</th>\n",
       "      <td>528</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.017132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0463, 0.158]</th>\n",
       "      <td>2244</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.072810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.158, 0.394]</th>\n",
       "      <td>7301</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.236892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.394, 0.643]</th>\n",
       "      <td>15907</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.516126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.643, 0.835]</th>\n",
       "      <td>24016</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.779234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.835, 1.0]</th>\n",
       "      <td>29385</td>\n",
       "      <td>30820</td>\n",
       "      <td>0.953439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sum  count  Bad Rate\n",
       "Score Bins                                \n",
       "(0.0, 0.00138]          3  30820  0.000097\n",
       "(0.00138, 0.00285]     20  30820  0.000649\n",
       "(0.00285, 0.00605]     61  30820  0.001979\n",
       "(0.00605, 0.015]      146  30820  0.004737\n",
       "(0.015, 0.0463]       528  30820  0.017132\n",
       "(0.0463, 0.158]      2244  30820  0.072810\n",
       "(0.158, 0.394]       7301  30820  0.236892\n",
       "(0.394, 0.643]      15907  30820  0.516126\n",
       "(0.643, 0.835]      24016  30820  0.779234\n",
       "(0.835, 1.0]        29385  30820  0.953439"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_train_data[\"Score Bins\"] = pd.cut(perf_train_data[\"Prediction\"], quantiles)\n",
    "stat = perf_train_data.groupby(\"Score Bins\")[\"Actual\"].agg([\"sum\", \"count\"])\n",
    "stat[\"Bad Rate\"] = stat[\"sum\"] / stat[\"count\"]\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Rectangle' object has no property 'fontdict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-a4b7aff17965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bad Rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_legend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_make_plot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m                 \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_width\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m                 rect = self._plot(\n\u001b[0m\u001b[1;32m   1476\u001b[0m                     \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0max_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(cls, ax, x, y, w, start, log, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Axes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2486\u001b[0m                 \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_nolegend_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m                 )\n\u001b[0;32m-> 2488\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2489\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vertical'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"set_{k}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[0m\u001b[1;32m    997\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[1;32m    998\u001b[0m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Rectangle' object has no property 'fontdict'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat.loc[:, 'Bad Rate'].plot(kind = 'bar', figsize=(15, 8), title = 'Train', fontdict = {'size': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py:405: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x = x[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f896aec8550>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(stat[\"Bad Rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>Bad Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score Bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.00138]</th>\n",
       "      <td>4</td>\n",
       "      <td>6349</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00138, 0.00285]</th>\n",
       "      <td>15</td>\n",
       "      <td>6488</td>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00285, 0.00605]</th>\n",
       "      <td>37</td>\n",
       "      <td>6618</td>\n",
       "      <td>0.005591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00605, 0.015]</th>\n",
       "      <td>53</td>\n",
       "      <td>6658</td>\n",
       "      <td>0.007960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.015, 0.0463]</th>\n",
       "      <td>225</td>\n",
       "      <td>6586</td>\n",
       "      <td>0.034163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0463, 0.158]</th>\n",
       "      <td>781</td>\n",
       "      <td>6484</td>\n",
       "      <td>0.120450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.158, 0.394]</th>\n",
       "      <td>1898</td>\n",
       "      <td>6253</td>\n",
       "      <td>0.303534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.394, 0.643]</th>\n",
       "      <td>3218</td>\n",
       "      <td>6072</td>\n",
       "      <td>0.529974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.643, 0.835]</th>\n",
       "      <td>4064</td>\n",
       "      <td>5640</td>\n",
       "      <td>0.720567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.835, 1.0]</th>\n",
       "      <td>4224</td>\n",
       "      <td>4815</td>\n",
       "      <td>0.877259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sum  count  Bad Rate\n",
       "Score Bins                               \n",
       "(0.0, 0.00138]         4   6349  0.000630\n",
       "(0.00138, 0.00285]    15   6488  0.002312\n",
       "(0.00285, 0.00605]    37   6618  0.005591\n",
       "(0.00605, 0.015]      53   6658  0.007960\n",
       "(0.015, 0.0463]      225   6586  0.034163\n",
       "(0.0463, 0.158]      781   6484  0.120450\n",
       "(0.158, 0.394]      1898   6253  0.303534\n",
       "(0.394, 0.643]      3218   6072  0.529974\n",
       "(0.643, 0.835]      4064   5640  0.720567\n",
       "(0.835, 1.0]        4224   4815  0.877259"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_test_data = pd.DataFrame({\"Actual\": ytest1['target'], \"Prediction\": final_xgb.predict_proba(xtest1)[:,1]})\n",
    "\n",
    "perf_test_data[\"Score Bins\"] = pd.cut(perf_test_data[\"Prediction\"], quantiles)\n",
    "stat1 = perf_test_data.groupby(\"Score Bins\")[\"Actual\"].agg([\"sum\", \"count\"])\n",
    "stat1[\"Bad Rate\"] = stat1[\"sum\"] / stat1[\"count\"]\n",
    "stat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test1'}, xlabel='Score Bins'>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat1.loc[:, 'Bad Rate'].plot(kind = 'bar', figsize=(15, 8), title = \"Test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>Bad Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score Bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.00138]</th>\n",
       "      <td>6</td>\n",
       "      <td>7647</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00138, 0.00285]</th>\n",
       "      <td>7</td>\n",
       "      <td>7964</td>\n",
       "      <td>0.000879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00285, 0.00605]</th>\n",
       "      <td>26</td>\n",
       "      <td>8337</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00605, 0.015]</th>\n",
       "      <td>65</td>\n",
       "      <td>8401</td>\n",
       "      <td>0.007737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.015, 0.0463]</th>\n",
       "      <td>190</td>\n",
       "      <td>8710</td>\n",
       "      <td>0.021814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0463, 0.158]</th>\n",
       "      <td>730</td>\n",
       "      <td>9023</td>\n",
       "      <td>0.080904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.158, 0.394]</th>\n",
       "      <td>2572</td>\n",
       "      <td>9773</td>\n",
       "      <td>0.263174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.394, 0.643]</th>\n",
       "      <td>5212</td>\n",
       "      <td>10012</td>\n",
       "      <td>0.520575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.643, 0.835]</th>\n",
       "      <td>6680</td>\n",
       "      <td>8983</td>\n",
       "      <td>0.743627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.835, 1.0]</th>\n",
       "      <td>9210</td>\n",
       "      <td>9900</td>\n",
       "      <td>0.930303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sum  count  Bad Rate\n",
       "Score Bins                               \n",
       "(0.0, 0.00138]         6   7647  0.000785\n",
       "(0.00138, 0.00285]     7   7964  0.000879\n",
       "(0.00285, 0.00605]    26   8337  0.003119\n",
       "(0.00605, 0.015]      65   8401  0.007737\n",
       "(0.015, 0.0463]      190   8710  0.021814\n",
       "(0.0463, 0.158]      730   9023  0.080904\n",
       "(0.158, 0.394]      2572   9773  0.263174\n",
       "(0.394, 0.643]      5212  10012  0.520575\n",
       "(0.643, 0.835]      6680   8983  0.743627\n",
       "(0.835, 1.0]        9210   9900  0.930303"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_test_data2 = pd.DataFrame({\"Actual\": ytest2['target'], \"Prediction\": final_xgb.predict_proba(xtest2)[:,1]})\n",
    "\n",
    "perf_test_data2[\"Score Bins\"] = pd.cut(perf_test_data2[\"Prediction\"], quantiles)\n",
    "stat2 = perf_test_data2.groupby(\"Score Bins\")[\"Actual\"].agg([\"sum\", \"count\"])\n",
    "stat2[\"Bad Rate\"] = stat2[\"sum\"] / stat2[\"count\"]\n",
    "stat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test2'}, xlabel='Score Bins'>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stat2.loc[:, 'Bad Rate'].plot(kind = 'bar', figsize=(15, 8), title = \"Test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest2_pred = final_xgb.predict_proba(xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0016039 , 0.00841289, 0.87515926, ..., 0.00989304, 0.47015622,\n",
       "       0.07696212], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest2_pred[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(xtrain)\n",
    "\n",
    "xtrain_n = sc.transform(xtrain)\n",
    "xtest1_n  = sc.transform(xtest1)\n",
    "xtest2_n  = sc.transform(xtest2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Pandas DF\n",
    "xtrain_n_df = pd.DataFrame(xtrain_n, columns=xtrain.columns)\n",
    "xtest1_n_df = pd.DataFrame(xtest1_n, columns=xtest1.columns)\n",
    "xtest2_n_df = pd.DataFrame(xtest2_n, columns=xtest2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D_50</th>\n",
       "      <td>124737.0</td>\n",
       "      <td>-1.228271e-17</td>\n",
       "      <td>1.000004</td>\n",
       "      <td>-9.430230</td>\n",
       "      <td>-0.289255</td>\n",
       "      <td>-0.112616</td>\n",
       "      <td>1.428428</td>\n",
       "      <td>172.617623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_27</th>\n",
       "      <td>264585.0</td>\n",
       "      <td>4.122765e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-2.855378</td>\n",
       "      <td>-2.790216</td>\n",
       "      <td>0.361637</td>\n",
       "      <td>0.379136</td>\n",
       "      <td>0.379502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_3</th>\n",
       "      <td>236579.0</td>\n",
       "      <td>-2.066155e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-4.015997</td>\n",
       "      <td>-1.145587</td>\n",
       "      <td>-0.324699</td>\n",
       "      <td>4.054131</td>\n",
       "      <td>24.229447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_17</th>\n",
       "      <td>147759.0</td>\n",
       "      <td>4.268301e-16</td>\n",
       "      <td>1.000003</td>\n",
       "      <td>-1.640992</td>\n",
       "      <td>-1.639907</td>\n",
       "      <td>0.621905</td>\n",
       "      <td>0.791418</td>\n",
       "      <td>0.792079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_39</th>\n",
       "      <td>2503.0</td>\n",
       "      <td>1.656242e-16</td>\n",
       "      <td>1.000200</td>\n",
       "      <td>-0.746401</td>\n",
       "      <td>-0.696336</td>\n",
       "      <td>-0.368080</td>\n",
       "      <td>2.817070</td>\n",
       "      <td>2.985179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_48</th>\n",
       "      <td>253023.0</td>\n",
       "      <td>7.741895e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.160430</td>\n",
       "      <td>-1.129802</td>\n",
       "      <td>-0.319232</td>\n",
       "      <td>1.946773</td>\n",
       "      <td>26.540482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_77</th>\n",
       "      <td>216167.0</td>\n",
       "      <td>5.944298e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.974985</td>\n",
       "      <td>-0.965012</td>\n",
       "      <td>-0.264866</td>\n",
       "      <td>3.484966</td>\n",
       "      <td>43.725639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_75</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.214469e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.764174</td>\n",
       "      <td>-0.762998</td>\n",
       "      <td>-0.429796</td>\n",
       "      <td>3.742757</td>\n",
       "      <td>18.425502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_53</th>\n",
       "      <td>87144.0</td>\n",
       "      <td>-1.492678e-16</td>\n",
       "      <td>1.000006</td>\n",
       "      <td>-0.388058</td>\n",
       "      <td>-0.386658</td>\n",
       "      <td>-0.313793</td>\n",
       "      <td>4.485733</td>\n",
       "      <td>32.173020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_132</th>\n",
       "      <td>36199.0</td>\n",
       "      <td>-8.290099e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-0.745469</td>\n",
       "      <td>-0.685771</td>\n",
       "      <td>-0.238933</td>\n",
       "      <td>3.287098</td>\n",
       "      <td>21.635304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_1</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.007709e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-5.466372</td>\n",
       "      <td>-0.584201</td>\n",
       "      <td>-0.433827</td>\n",
       "      <td>4.167729</td>\n",
       "      <td>5.718808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_3</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.666182e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.553299</td>\n",
       "      <td>-0.552210</td>\n",
       "      <td>-0.511214</td>\n",
       "      <td>3.774454</td>\n",
       "      <td>5.842307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_44</th>\n",
       "      <td>259328.0</td>\n",
       "      <td>5.339904e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.533721</td>\n",
       "      <td>-0.533010</td>\n",
       "      <td>-0.498338</td>\n",
       "      <td>4.111855</td>\n",
       "      <td>25.533236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_2</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-9.087920e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.567912</td>\n",
       "      <td>-1.559888</td>\n",
       "      <td>0.475482</td>\n",
       "      <td>0.965602</td>\n",
       "      <td>0.966403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_42</th>\n",
       "      <td>60938.0</td>\n",
       "      <td>7.801877e-17</td>\n",
       "      <td>1.000008</td>\n",
       "      <td>-0.808415</td>\n",
       "      <td>-0.795634</td>\n",
       "      <td>-0.281205</td>\n",
       "      <td>3.566699</td>\n",
       "      <td>17.928169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_9</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-4.007092e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.670728</td>\n",
       "      <td>-0.669902</td>\n",
       "      <td>-0.571899</td>\n",
       "      <td>2.892219</td>\n",
       "      <td>48.760105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_49</th>\n",
       "      <td>36201.0</td>\n",
       "      <td>1.970438e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-0.475747</td>\n",
       "      <td>-0.470654</td>\n",
       "      <td>-0.164321</td>\n",
       "      <td>2.069076</td>\n",
       "      <td>119.550970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_111</th>\n",
       "      <td>2490.0</td>\n",
       "      <td>-3.107287e-16</td>\n",
       "      <td>1.000201</td>\n",
       "      <td>-3.171411</td>\n",
       "      <td>-3.166442</td>\n",
       "      <td>0.489394</td>\n",
       "      <td>0.512104</td>\n",
       "      <td>0.512477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_45</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.468048e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.011677</td>\n",
       "      <td>-0.998456</td>\n",
       "      <td>-0.306474</td>\n",
       "      <td>3.119760</td>\n",
       "      <td>5.550233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_88</th>\n",
       "      <td>1474.0</td>\n",
       "      <td>-4.421309e-17</td>\n",
       "      <td>1.000339</td>\n",
       "      <td>-0.776357</td>\n",
       "      <td>-0.765906</td>\n",
       "      <td>-0.375006</td>\n",
       "      <td>3.925734</td>\n",
       "      <td>10.690209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_5</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>5.552847e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.208018</td>\n",
       "      <td>-0.206993</td>\n",
       "      <td>-0.170087</td>\n",
       "      <td>2.328823</td>\n",
       "      <td>174.364029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_66</th>\n",
       "      <td>35652.0</td>\n",
       "      <td>-6.083650e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-2.857453</td>\n",
       "      <td>-2.857453</td>\n",
       "      <td>0.349962</td>\n",
       "      <td>0.349962</td>\n",
       "      <td>0.349962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_38</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-3.676779e-15</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.063459</td>\n",
       "      <td>-1.063459</td>\n",
       "      <td>-0.428269</td>\n",
       "      <td>2.747680</td>\n",
       "      <td>2.747680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_23</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-4.064648e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-145.970357</td>\n",
       "      <td>-0.183939</td>\n",
       "      <td>-0.045241</td>\n",
       "      <td>0.893273</td>\n",
       "      <td>472.537014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_43</th>\n",
       "      <td>214617.0</td>\n",
       "      <td>1.177907e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.721432</td>\n",
       "      <td>-0.710796</td>\n",
       "      <td>-0.309885</td>\n",
       "      <td>4.004007</td>\n",
       "      <td>39.731568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_63_CO</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>3.263940e-15</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.725569</td>\n",
       "      <td>-1.725569</td>\n",
       "      <td>0.579519</td>\n",
       "      <td>0.579519</td>\n",
       "      <td>0.579519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_41</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.357435e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.290084</td>\n",
       "      <td>-0.289470</td>\n",
       "      <td>-0.258827</td>\n",
       "      <td>4.548496</td>\n",
       "      <td>39.006029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_51</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>4.921189e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.591602</td>\n",
       "      <td>-0.590990</td>\n",
       "      <td>-0.561482</td>\n",
       "      <td>3.610049</td>\n",
       "      <td>9.184363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2</th>\n",
       "      <td>268249.0</td>\n",
       "      <td>-2.692333e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-4.313322</td>\n",
       "      <td>-2.598543</td>\n",
       "      <td>0.133561</td>\n",
       "      <td>1.461844</td>\n",
       "      <td>1.479552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_7</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.922936e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.982954</td>\n",
       "      <td>-0.796955</td>\n",
       "      <td>-0.471069</td>\n",
       "      <td>3.589984</td>\n",
       "      <td>4.638065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_26</th>\n",
       "      <td>31519.0</td>\n",
       "      <td>5.791959e-17</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>-0.353103</td>\n",
       "      <td>-0.352225</td>\n",
       "      <td>-0.199697</td>\n",
       "      <td>3.917072</td>\n",
       "      <td>37.419402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_74</th>\n",
       "      <td>268647.0</td>\n",
       "      <td>1.277682e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.700596</td>\n",
       "      <td>-0.699554</td>\n",
       "      <td>-0.353288</td>\n",
       "      <td>3.896508</td>\n",
       "      <td>19.961062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_62</th>\n",
       "      <td>252487.0</td>\n",
       "      <td>8.399874e-18</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.825955</td>\n",
       "      <td>-0.800290</td>\n",
       "      <td>-0.414716</td>\n",
       "      <td>3.488945</td>\n",
       "      <td>46.489650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_4</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.468233e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.775337</td>\n",
       "      <td>-0.772012</td>\n",
       "      <td>-0.402600</td>\n",
       "      <td>3.743302</td>\n",
       "      <td>15.773923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_56</th>\n",
       "      <td>146288.0</td>\n",
       "      <td>-8.731486e-18</td>\n",
       "      <td>1.000003</td>\n",
       "      <td>-0.980765</td>\n",
       "      <td>-0.891895</td>\n",
       "      <td>-0.249096</td>\n",
       "      <td>3.622786</td>\n",
       "      <td>49.324881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_10</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.213469e-17</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.028583</td>\n",
       "      <td>-0.027792</td>\n",
       "      <td>-0.015344</td>\n",
       "      <td>0.092872</td>\n",
       "      <td>482.337760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_8</th>\n",
       "      <td>269122.0</td>\n",
       "      <td>1.713552e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.931920</td>\n",
       "      <td>-0.931550</td>\n",
       "      <td>-0.913367</td>\n",
       "      <td>1.094237</td>\n",
       "      <td>1.099733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_46</th>\n",
       "      <td>231193.0</td>\n",
       "      <td>-4.899444e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-44.316236</td>\n",
       "      <td>-2.679903</td>\n",
       "      <td>-0.095763</td>\n",
       "      <td>3.051949</td>\n",
       "      <td>94.786342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_76</th>\n",
       "      <td>33375.0</td>\n",
       "      <td>1.038553e-16</td>\n",
       "      <td>1.000015</td>\n",
       "      <td>-0.495821</td>\n",
       "      <td>-0.492486</td>\n",
       "      <td>-0.288948</td>\n",
       "      <td>2.959534</td>\n",
       "      <td>53.600699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_110</th>\n",
       "      <td>2490.0</td>\n",
       "      <td>-7.003768e-16</td>\n",
       "      <td>1.000201</td>\n",
       "      <td>-2.485500</td>\n",
       "      <td>-2.401776</td>\n",
       "      <td>0.441997</td>\n",
       "      <td>0.877978</td>\n",
       "      <td>0.879036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_3</th>\n",
       "      <td>266694.0</td>\n",
       "      <td>2.737592e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-10.213218</td>\n",
       "      <td>-3.447915</td>\n",
       "      <td>0.103782</td>\n",
       "      <td>2.361980</td>\n",
       "      <td>8.681701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_64_O</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.700895e-15</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.075936</td>\n",
       "      <td>-1.075936</td>\n",
       "      <td>0.929423</td>\n",
       "      <td>0.929423</td>\n",
       "      <td>0.929423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_7</th>\n",
       "      <td>236579.0</td>\n",
       "      <td>-2.687110e-16</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-3.041295</td>\n",
       "      <td>-1.060333</td>\n",
       "      <td>-0.386645</td>\n",
       "      <td>3.810535</td>\n",
       "      <td>16.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-2.057626e-18</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-0.344761</td>\n",
       "      <td>-0.344241</td>\n",
       "      <td>-0.318500</td>\n",
       "      <td>4.239192</td>\n",
       "      <td>12.179966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean       std         min        1%       50%  \\\n",
       "D_50     124737.0 -1.228271e-17  1.000004   -9.430230 -0.289255 -0.112616   \n",
       "R_27     264585.0  4.122765e-16  1.000002   -2.855378 -2.790216  0.361637   \n",
       "S_3      236579.0 -2.066155e-17  1.000002   -4.015997 -1.145587 -0.324699   \n",
       "B_17     147759.0  4.268301e-16  1.000003   -1.640992 -1.639907  0.621905   \n",
       "B_39       2503.0  1.656242e-16  1.000200   -0.746401 -0.696336 -0.368080   \n",
       "D_48     253023.0  7.741895e-17  1.000002   -1.160430 -1.129802 -0.319232   \n",
       "D_77     216167.0  5.944298e-17  1.000002   -0.974985 -0.965012 -0.264866   \n",
       "D_75     269243.0  1.214469e-16  1.000002   -0.764174 -0.762998 -0.429796   \n",
       "D_53      87144.0 -1.492678e-16  1.000006   -0.388058 -0.386658 -0.313793   \n",
       "D_132     36199.0 -8.290099e-17  1.000014   -0.745469 -0.685771 -0.238933   \n",
       "B_1      269243.0  1.007709e-16  1.000002   -5.466372 -0.584201 -0.433827   \n",
       "B_3      269243.0  1.666182e-17  1.000002   -0.553299 -0.552210 -0.511214   \n",
       "D_44     259328.0  5.339904e-17  1.000002   -0.533721 -0.533010 -0.498338   \n",
       "B_2      269243.0 -9.087920e-17  1.000002   -1.567912 -1.559888  0.475482   \n",
       "D_42      60938.0  7.801877e-17  1.000008   -0.808415 -0.795634 -0.281205   \n",
       "B_9      269243.0 -4.007092e-17  1.000002   -0.670728 -0.669902 -0.571899   \n",
       "D_49      36201.0  1.970438e-17  1.000014   -0.475747 -0.470654 -0.164321   \n",
       "D_111      2490.0 -3.107287e-16  1.000201   -3.171411 -3.166442  0.489394   \n",
       "D_45     269243.0  1.468048e-16  1.000002   -1.011677 -0.998456 -0.306474   \n",
       "D_88       1474.0 -4.421309e-17  1.000339   -0.776357 -0.765906 -0.375006   \n",
       "B_5      269243.0  5.552847e-17  1.000002   -0.208018 -0.206993 -0.170087   \n",
       "D_66      35652.0 -6.083650e-16  1.000014   -2.857453 -2.857453  0.349962   \n",
       "B_38     269243.0 -3.676779e-15  1.000002   -1.063459 -1.063459 -0.428269   \n",
       "S_23     269243.0 -4.064648e-17  1.000002 -145.970357 -0.183939 -0.045241   \n",
       "D_43     214617.0  1.177907e-16  1.000002   -0.721432 -0.710796 -0.309885   \n",
       "D_63_CO  269243.0  3.263940e-15  1.000002   -1.725569 -1.725569  0.579519   \n",
       "D_41     269243.0  1.357435e-17  1.000002   -0.290084 -0.289470 -0.258827   \n",
       "D_51     269243.0  4.921189e-17  1.000002   -0.591602 -0.590990 -0.561482   \n",
       "P_2      268249.0 -2.692333e-16  1.000002   -4.313322 -2.598543  0.133561   \n",
       "B_7      269243.0  1.922936e-16  1.000002   -1.982954 -0.796955 -0.471069   \n",
       "R_26      31519.0  5.791959e-17  1.000016   -0.353103 -0.352225 -0.199697   \n",
       "D_74     268647.0  1.277682e-16  1.000002   -0.700596 -0.699554 -0.353288   \n",
       "D_62     252487.0  8.399874e-18  1.000002   -0.825955 -0.800290 -0.414716   \n",
       "B_4      269243.0  1.468233e-16  1.000002   -0.775337 -0.772012 -0.402600   \n",
       "D_56     146288.0 -8.731486e-18  1.000003   -0.980765 -0.891895 -0.249096   \n",
       "B_10     269243.0  1.213469e-17  1.000002   -0.028583 -0.027792 -0.015344   \n",
       "B_8      269122.0  1.713552e-16  1.000002   -0.931920 -0.931550 -0.913367   \n",
       "D_46     231193.0 -4.899444e-16  1.000002  -44.316236 -2.679903 -0.095763   \n",
       "D_76      33375.0  1.038553e-16  1.000015   -0.495821 -0.492486 -0.288948   \n",
       "D_110      2490.0 -7.003768e-16  1.000201   -2.485500 -2.401776  0.441997   \n",
       "P_3      266694.0  2.737592e-16  1.000002  -10.213218 -3.447915  0.103782   \n",
       "D_64_O   269243.0  1.700895e-15  1.000002   -1.075936 -1.075936  0.929423   \n",
       "S_7      236579.0 -2.687110e-16  1.000002   -3.041295 -1.060333 -0.386645   \n",
       "R_1      269243.0 -2.057626e-18  1.000002   -0.344761 -0.344241 -0.318500   \n",
       "\n",
       "              99%         max  \n",
       "D_50     1.428428  172.617623  \n",
       "R_27     0.379136    0.379502  \n",
       "S_3      4.054131   24.229447  \n",
       "B_17     0.791418    0.792079  \n",
       "B_39     2.817070    2.985179  \n",
       "D_48     1.946773   26.540482  \n",
       "D_77     3.484966   43.725639  \n",
       "D_75     3.742757   18.425502  \n",
       "D_53     4.485733   32.173020  \n",
       "D_132    3.287098   21.635304  \n",
       "B_1      4.167729    5.718808  \n",
       "B_3      3.774454    5.842307  \n",
       "D_44     4.111855   25.533236  \n",
       "B_2      0.965602    0.966403  \n",
       "D_42     3.566699   17.928169  \n",
       "B_9      2.892219   48.760105  \n",
       "D_49     2.069076  119.550970  \n",
       "D_111    0.512104    0.512477  \n",
       "D_45     3.119760    5.550233  \n",
       "D_88     3.925734   10.690209  \n",
       "B_5      2.328823  174.364029  \n",
       "D_66     0.349962    0.349962  \n",
       "B_38     2.747680    2.747680  \n",
       "S_23     0.893273  472.537014  \n",
       "D_43     4.004007   39.731568  \n",
       "D_63_CO  0.579519    0.579519  \n",
       "D_41     4.548496   39.006029  \n",
       "D_51     3.610049    9.184363  \n",
       "P_2      1.461844    1.479552  \n",
       "B_7      3.589984    4.638065  \n",
       "R_26     3.917072   37.419402  \n",
       "D_74     3.896508   19.961062  \n",
       "D_62     3.488945   46.489650  \n",
       "B_4      3.743302   15.773923  \n",
       "D_56     3.622786   49.324881  \n",
       "B_10     0.092872  482.337760  \n",
       "B_8      1.094237    1.099733  \n",
       "D_46     3.051949   94.786342  \n",
       "D_76     2.959534   53.600699  \n",
       "D_110    0.877978    0.879036  \n",
       "P_3      2.361980    8.681701  \n",
       "D_64_O   0.929423    0.929423  \n",
       "S_7      3.810535   16.085300  \n",
       "R_1      4.239192   12.179966  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_n_df.describe(percentiles = [.01, .99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D_50       1.428428\n",
       "R_27       0.379136\n",
       "S_3        4.054131\n",
       "B_17       0.791418\n",
       "B_39       2.817070\n",
       "D_48       1.946773\n",
       "D_77       3.484966\n",
       "D_75       3.742757\n",
       "D_53       4.485733\n",
       "D_132      3.287098\n",
       "B_1        4.167729\n",
       "B_3        3.774454\n",
       "D_44       4.111855\n",
       "B_2        0.965602\n",
       "D_42       3.566699\n",
       "B_9        2.892219\n",
       "D_49       2.069076\n",
       "D_111      0.512104\n",
       "D_45       3.119760\n",
       "D_88       3.925734\n",
       "B_5        2.328823\n",
       "D_66       0.349962\n",
       "B_38       2.747680\n",
       "S_23       0.893273\n",
       "D_43       4.004007\n",
       "D_63_CO    0.579519\n",
       "D_41       4.548496\n",
       "D_51       3.610049\n",
       "P_2        1.461844\n",
       "B_7        3.589984\n",
       "R_26       3.917072\n",
       "D_74       3.896508\n",
       "D_62       3.488945\n",
       "B_4        3.743302\n",
       "D_56       3.622786\n",
       "B_10       0.092872\n",
       "B_8        1.094237\n",
       "D_46       3.051949\n",
       "D_76       2.959534\n",
       "D_110      0.877978\n",
       "P_3        2.361980\n",
       "D_64_O     0.929423\n",
       "S_7        3.810535\n",
       "R_1        4.239192\n",
       "Name: 0.99, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_n_df.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xtrain_n_df.columns:\n",
    "    xtrain_n_df[i] = np.where(xtrain_n_df[i] > xtrain_n_df[i].quantile(0.99), xtrain_n_df[i].quantile(0.99), xtrain_n_df[i] )\n",
    "    xtrain_n_df[i] = np.where(xtrain_n_df[i] < xtrain_n_df[i].quantile(0.01), xtrain_n_df[i].quantile(0.01), xtrain_n_df[i] )\n",
    "\n",
    "for i in xtest1_n_df.columns:\n",
    "    xtest1_n_df[i] = np.where(xtest1_n_df[i] > xtest1_n_df[i].quantile(0.99), xtest1_n_df[i].quantile(0.99), xtest1_n_df[i] )\n",
    "    xtest1_n_df[i] = np.where(xtest1_n_df[i] < xtest1_n_df[i].quantile(0.01), xtest1_n_df[i].quantile(0.01), xtest1_n_df[i] )\n",
    "\n",
    "for i in xtest2_n_df.columns:\n",
    "    xtest2_n_df[i] = np.where(xtest2_n_df[i] > xtest2_n_df[i].quantile(0.99), xtest2_n_df[i].quantile(0.99), xtest2_n_df[i] )\n",
    "    xtest2_n_df[i] = np.where(xtest2_n_df[i] < xtest2_n_df[i].quantile(0.01), xtest2_n_df[i].quantile(0.01), xtest2_n_df[i] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D_50</th>\n",
       "      <td>124737.0</td>\n",
       "      <td>-3.359599e-02</td>\n",
       "      <td>0.266379</td>\n",
       "      <td>-0.289253</td>\n",
       "      <td>-0.289253</td>\n",
       "      <td>-0.112616</td>\n",
       "      <td>1.428200</td>\n",
       "      <td>1.428246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_27</th>\n",
       "      <td>264585.0</td>\n",
       "      <td>1.332669e-04</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>-2.790215</td>\n",
       "      <td>-2.790215</td>\n",
       "      <td>0.361637</td>\n",
       "      <td>0.379136</td>\n",
       "      <td>0.379136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_3</th>\n",
       "      <td>236579.0</td>\n",
       "      <td>-1.165025e-02</td>\n",
       "      <td>0.917373</td>\n",
       "      <td>-1.145561</td>\n",
       "      <td>-1.145555</td>\n",
       "      <td>-0.324699</td>\n",
       "      <td>4.054081</td>\n",
       "      <td>4.054083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_17</th>\n",
       "      <td>147759.0</td>\n",
       "      <td>2.010826e-06</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>-1.639907</td>\n",
       "      <td>-1.639907</td>\n",
       "      <td>0.621905</td>\n",
       "      <td>0.791418</td>\n",
       "      <td>0.791418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_39</th>\n",
       "      <td>2503.0</td>\n",
       "      <td>-5.255874e-05</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>-0.696269</td>\n",
       "      <td>-0.696204</td>\n",
       "      <td>-0.368080</td>\n",
       "      <td>2.817063</td>\n",
       "      <td>2.817065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_48</th>\n",
       "      <td>253023.0</td>\n",
       "      <td>-3.080700e-03</td>\n",
       "      <td>0.990448</td>\n",
       "      <td>-1.129801</td>\n",
       "      <td>-1.129801</td>\n",
       "      <td>-0.319232</td>\n",
       "      <td>1.946748</td>\n",
       "      <td>1.946755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_77</th>\n",
       "      <td>216167.0</td>\n",
       "      <td>-1.075533e-02</td>\n",
       "      <td>0.922959</td>\n",
       "      <td>-0.965011</td>\n",
       "      <td>-0.965011</td>\n",
       "      <td>-0.264866</td>\n",
       "      <td>3.484958</td>\n",
       "      <td>3.484959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_75</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-1.114791e-02</td>\n",
       "      <td>0.942911</td>\n",
       "      <td>-0.762998</td>\n",
       "      <td>-0.762997</td>\n",
       "      <td>-0.429796</td>\n",
       "      <td>3.742752</td>\n",
       "      <td>3.742753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_53</th>\n",
       "      <td>87144.0</td>\n",
       "      <td>-2.712624e-02</td>\n",
       "      <td>0.772094</td>\n",
       "      <td>-0.386657</td>\n",
       "      <td>-0.386657</td>\n",
       "      <td>-0.313793</td>\n",
       "      <td>4.485345</td>\n",
       "      <td>4.485412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_132</th>\n",
       "      <td>36199.0</td>\n",
       "      <td>-3.862500e-02</td>\n",
       "      <td>0.671473</td>\n",
       "      <td>-0.685769</td>\n",
       "      <td>-0.685769</td>\n",
       "      <td>-0.238933</td>\n",
       "      <td>3.286209</td>\n",
       "      <td>3.286209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_1</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-7.792966e-03</td>\n",
       "      <td>0.961037</td>\n",
       "      <td>-0.584201</td>\n",
       "      <td>-0.584201</td>\n",
       "      <td>-0.433827</td>\n",
       "      <td>4.167397</td>\n",
       "      <td>4.167455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_3</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-4.516973e-03</td>\n",
       "      <td>0.981033</td>\n",
       "      <td>-0.552210</td>\n",
       "      <td>-0.552210</td>\n",
       "      <td>-0.511214</td>\n",
       "      <td>3.774397</td>\n",
       "      <td>3.774407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_44</th>\n",
       "      <td>259328.0</td>\n",
       "      <td>-1.236873e-02</td>\n",
       "      <td>0.928618</td>\n",
       "      <td>-0.533010</td>\n",
       "      <td>-0.533010</td>\n",
       "      <td>-0.498338</td>\n",
       "      <td>4.111839</td>\n",
       "      <td>4.111843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_2</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>3.542756e-05</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>-1.559888</td>\n",
       "      <td>-1.559888</td>\n",
       "      <td>0.475482</td>\n",
       "      <td>0.965602</td>\n",
       "      <td>0.965602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_42</th>\n",
       "      <td>60938.0</td>\n",
       "      <td>-2.246981e-02</td>\n",
       "      <td>0.845448</td>\n",
       "      <td>-0.795634</td>\n",
       "      <td>-0.795634</td>\n",
       "      <td>-0.281205</td>\n",
       "      <td>3.565633</td>\n",
       "      <td>3.565842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_9</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-1.635841e-02</td>\n",
       "      <td>0.894535</td>\n",
       "      <td>-0.669902</td>\n",
       "      <td>-0.669902</td>\n",
       "      <td>-0.571899</td>\n",
       "      <td>2.892113</td>\n",
       "      <td>2.892131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_49</th>\n",
       "      <td>36201.0</td>\n",
       "      <td>-1.945576e-02</td>\n",
       "      <td>0.462374</td>\n",
       "      <td>-0.470654</td>\n",
       "      <td>-0.470654</td>\n",
       "      <td>-0.164321</td>\n",
       "      <td>2.069076</td>\n",
       "      <td>2.069076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_111</th>\n",
       "      <td>2490.0</td>\n",
       "      <td>2.620843e-05</td>\n",
       "      <td>1.000110</td>\n",
       "      <td>-3.166416</td>\n",
       "      <td>-3.166414</td>\n",
       "      <td>0.489394</td>\n",
       "      <td>0.512103</td>\n",
       "      <td>0.512103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_45</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-5.620888e-03</td>\n",
       "      <td>0.979267</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.998455</td>\n",
       "      <td>-0.306474</td>\n",
       "      <td>3.119599</td>\n",
       "      <td>3.119627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_88</th>\n",
       "      <td>1474.0</td>\n",
       "      <td>-1.265449e-02</td>\n",
       "      <td>0.924114</td>\n",
       "      <td>-0.765802</td>\n",
       "      <td>-0.765774</td>\n",
       "      <td>-0.375006</td>\n",
       "      <td>3.916522</td>\n",
       "      <td>3.917022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_5</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-3.136146e-02</td>\n",
       "      <td>0.386433</td>\n",
       "      <td>-0.206993</td>\n",
       "      <td>-0.206993</td>\n",
       "      <td>-0.170087</td>\n",
       "      <td>2.328652</td>\n",
       "      <td>2.328682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_66</th>\n",
       "      <td>35652.0</td>\n",
       "      <td>-6.083650e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-2.857453</td>\n",
       "      <td>-2.857453</td>\n",
       "      <td>0.349962</td>\n",
       "      <td>0.349962</td>\n",
       "      <td>0.349962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_38</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-3.676779e-15</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.063459</td>\n",
       "      <td>-1.063459</td>\n",
       "      <td>-0.428269</td>\n",
       "      <td>2.747680</td>\n",
       "      <td>2.747680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_23</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-5.710081e-03</td>\n",
       "      <td>0.161572</td>\n",
       "      <td>-0.183921</td>\n",
       "      <td>-0.183910</td>\n",
       "      <td>-0.045241</td>\n",
       "      <td>0.893242</td>\n",
       "      <td>0.893248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_43</th>\n",
       "      <td>214617.0</td>\n",
       "      <td>-2.196067e-02</td>\n",
       "      <td>0.833648</td>\n",
       "      <td>-0.710795</td>\n",
       "      <td>-0.710794</td>\n",
       "      <td>-0.309885</td>\n",
       "      <td>4.003878</td>\n",
       "      <td>4.003914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_63_CO</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>3.263940e-15</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.725569</td>\n",
       "      <td>-1.725569</td>\n",
       "      <td>0.579519</td>\n",
       "      <td>0.579519</td>\n",
       "      <td>0.579519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_41</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-2.518205e-02</td>\n",
       "      <td>0.786899</td>\n",
       "      <td>-0.289470</td>\n",
       "      <td>-0.289470</td>\n",
       "      <td>-0.258827</td>\n",
       "      <td>4.548401</td>\n",
       "      <td>4.548418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_51</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-8.114810e-03</td>\n",
       "      <td>0.961968</td>\n",
       "      <td>-0.590990</td>\n",
       "      <td>-0.590990</td>\n",
       "      <td>-0.561482</td>\n",
       "      <td>3.610042</td>\n",
       "      <td>3.610043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_2</th>\n",
       "      <td>268249.0</td>\n",
       "      <td>3.558498e-03</td>\n",
       "      <td>0.989264</td>\n",
       "      <td>-2.598478</td>\n",
       "      <td>-2.598444</td>\n",
       "      <td>0.133561</td>\n",
       "      <td>1.461843</td>\n",
       "      <td>1.461843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_7</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-6.155197e-03</td>\n",
       "      <td>0.974367</td>\n",
       "      <td>-0.796954</td>\n",
       "      <td>-0.796954</td>\n",
       "      <td>-0.471069</td>\n",
       "      <td>3.589740</td>\n",
       "      <td>3.589783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_26</th>\n",
       "      <td>31519.0</td>\n",
       "      <td>-3.603536e-02</td>\n",
       "      <td>0.628743</td>\n",
       "      <td>-0.352224</td>\n",
       "      <td>-0.352224</td>\n",
       "      <td>-0.199697</td>\n",
       "      <td>3.916462</td>\n",
       "      <td>3.916627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_74</th>\n",
       "      <td>268647.0</td>\n",
       "      <td>-1.194080e-02</td>\n",
       "      <td>0.935430</td>\n",
       "      <td>-0.699554</td>\n",
       "      <td>-0.699554</td>\n",
       "      <td>-0.353288</td>\n",
       "      <td>3.896463</td>\n",
       "      <td>3.896470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_62</th>\n",
       "      <td>252487.0</td>\n",
       "      <td>-1.262478e-02</td>\n",
       "      <td>0.913615</td>\n",
       "      <td>-0.800290</td>\n",
       "      <td>-0.800290</td>\n",
       "      <td>-0.414716</td>\n",
       "      <td>3.488749</td>\n",
       "      <td>3.488752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_4</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-1.204802e-02</td>\n",
       "      <td>0.937080</td>\n",
       "      <td>-0.772012</td>\n",
       "      <td>-0.772012</td>\n",
       "      <td>-0.402600</td>\n",
       "      <td>3.743054</td>\n",
       "      <td>3.743098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_56</th>\n",
       "      <td>146288.0</td>\n",
       "      <td>-2.313205e-02</td>\n",
       "      <td>0.787734</td>\n",
       "      <td>-0.891892</td>\n",
       "      <td>-0.891892</td>\n",
       "      <td>-0.249096</td>\n",
       "      <td>3.622754</td>\n",
       "      <td>3.622755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_10</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-8.840488e-03</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>-0.027792</td>\n",
       "      <td>-0.027792</td>\n",
       "      <td>-0.015344</td>\n",
       "      <td>0.092859</td>\n",
       "      <td>0.092862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_8</th>\n",
       "      <td>269122.0</td>\n",
       "      <td>-7.067683e-07</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>-0.931550</td>\n",
       "      <td>-0.931550</td>\n",
       "      <td>-0.913367</td>\n",
       "      <td>1.094237</td>\n",
       "      <td>1.094237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_46</th>\n",
       "      <td>231193.0</td>\n",
       "      <td>-1.422383e-03</td>\n",
       "      <td>0.779626</td>\n",
       "      <td>-2.679872</td>\n",
       "      <td>-2.679869</td>\n",
       "      <td>-0.095763</td>\n",
       "      <td>3.051888</td>\n",
       "      <td>3.051888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_76</th>\n",
       "      <td>33375.0</td>\n",
       "      <td>-3.321497e-02</td>\n",
       "      <td>0.657227</td>\n",
       "      <td>-0.492485</td>\n",
       "      <td>-0.492485</td>\n",
       "      <td>-0.288948</td>\n",
       "      <td>2.959337</td>\n",
       "      <td>2.959347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_110</th>\n",
       "      <td>2490.0</td>\n",
       "      <td>5.968010e-04</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>-2.401527</td>\n",
       "      <td>-2.401499</td>\n",
       "      <td>0.441997</td>\n",
       "      <td>0.877978</td>\n",
       "      <td>0.877978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P_3</th>\n",
       "      <td>266694.0</td>\n",
       "      <td>3.429047e-03</td>\n",
       "      <td>0.926010</td>\n",
       "      <td>-3.447882</td>\n",
       "      <td>-3.447880</td>\n",
       "      <td>0.103782</td>\n",
       "      <td>2.361960</td>\n",
       "      <td>2.361960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_64_O</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>1.700895e-15</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>-1.075936</td>\n",
       "      <td>-1.075936</td>\n",
       "      <td>0.929423</td>\n",
       "      <td>0.929423</td>\n",
       "      <td>0.929423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_7</th>\n",
       "      <td>236579.0</td>\n",
       "      <td>-9.482247e-03</td>\n",
       "      <td>0.942375</td>\n",
       "      <td>-1.060306</td>\n",
       "      <td>-1.060300</td>\n",
       "      <td>-0.386645</td>\n",
       "      <td>3.810519</td>\n",
       "      <td>3.810519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_1</th>\n",
       "      <td>269243.0</td>\n",
       "      <td>-1.775392e-02</td>\n",
       "      <td>0.895098</td>\n",
       "      <td>-0.344241</td>\n",
       "      <td>-0.344241</td>\n",
       "      <td>-0.318500</td>\n",
       "      <td>4.239188</td>\n",
       "      <td>4.239189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean       std       min        1%       50%  \\\n",
       "D_50     124737.0 -3.359599e-02  0.266379 -0.289253 -0.289253 -0.112616   \n",
       "R_27     264585.0  1.332669e-04  0.999623 -2.790215 -2.790215  0.361637   \n",
       "S_3      236579.0 -1.165025e-02  0.917373 -1.145561 -1.145555 -0.324699   \n",
       "B_17     147759.0  2.010826e-06  0.999992 -1.639907 -1.639907  0.621905   \n",
       "B_39       2503.0 -5.255874e-05  0.999375 -0.696269 -0.696204 -0.368080   \n",
       "D_48     253023.0 -3.080700e-03  0.990448 -1.129801 -1.129801 -0.319232   \n",
       "D_77     216167.0 -1.075533e-02  0.922959 -0.965011 -0.965011 -0.264866   \n",
       "D_75     269243.0 -1.114791e-02  0.942911 -0.762998 -0.762997 -0.429796   \n",
       "D_53      87144.0 -2.712624e-02  0.772094 -0.386657 -0.386657 -0.313793   \n",
       "D_132     36199.0 -3.862500e-02  0.671473 -0.685769 -0.685769 -0.238933   \n",
       "B_1      269243.0 -7.792966e-03  0.961037 -0.584201 -0.584201 -0.433827   \n",
       "B_3      269243.0 -4.516973e-03  0.981033 -0.552210 -0.552210 -0.511214   \n",
       "D_44     259328.0 -1.236873e-02  0.928618 -0.533010 -0.533010 -0.498338   \n",
       "B_2      269243.0  3.542756e-05  0.999936 -1.559888 -1.559888  0.475482   \n",
       "D_42      60938.0 -2.246981e-02  0.845448 -0.795634 -0.795634 -0.281205   \n",
       "B_9      269243.0 -1.635841e-02  0.894535 -0.669902 -0.669902 -0.571899   \n",
       "D_49      36201.0 -1.945576e-02  0.462374 -0.470654 -0.470654 -0.164321   \n",
       "D_111      2490.0  2.620843e-05  1.000110 -3.166416 -3.166414  0.489394   \n",
       "D_45     269243.0 -5.620888e-03  0.979267 -0.998455 -0.998455 -0.306474   \n",
       "D_88       1474.0 -1.265449e-02  0.924114 -0.765802 -0.765774 -0.375006   \n",
       "B_5      269243.0 -3.136146e-02  0.386433 -0.206993 -0.206993 -0.170087   \n",
       "D_66      35652.0 -6.083650e-16  1.000014 -2.857453 -2.857453  0.349962   \n",
       "B_38     269243.0 -3.676779e-15  1.000002 -1.063459 -1.063459 -0.428269   \n",
       "S_23     269243.0 -5.710081e-03  0.161572 -0.183921 -0.183910 -0.045241   \n",
       "D_43     214617.0 -2.196067e-02  0.833648 -0.710795 -0.710794 -0.309885   \n",
       "D_63_CO  269243.0  3.263940e-15  1.000002 -1.725569 -1.725569  0.579519   \n",
       "D_41     269243.0 -2.518205e-02  0.786899 -0.289470 -0.289470 -0.258827   \n",
       "D_51     269243.0 -8.114810e-03  0.961968 -0.590990 -0.590990 -0.561482   \n",
       "P_2      268249.0  3.558498e-03  0.989264 -2.598478 -2.598444  0.133561   \n",
       "B_7      269243.0 -6.155197e-03  0.974367 -0.796954 -0.796954 -0.471069   \n",
       "R_26      31519.0 -3.603536e-02  0.628743 -0.352224 -0.352224 -0.199697   \n",
       "D_74     268647.0 -1.194080e-02  0.935430 -0.699554 -0.699554 -0.353288   \n",
       "D_62     252487.0 -1.262478e-02  0.913615 -0.800290 -0.800290 -0.414716   \n",
       "B_4      269243.0 -1.204802e-02  0.937080 -0.772012 -0.772012 -0.402600   \n",
       "D_56     146288.0 -2.313205e-02  0.787734 -0.891892 -0.891892 -0.249096   \n",
       "B_10     269243.0 -8.840488e-03  0.019231 -0.027792 -0.027792 -0.015344   \n",
       "B_8      269122.0 -7.067683e-07  0.999997 -0.931550 -0.931550 -0.913367   \n",
       "D_46     231193.0 -1.422383e-03  0.779626 -2.679872 -2.679869 -0.095763   \n",
       "D_76      33375.0 -3.321497e-02  0.657227 -0.492485 -0.492485 -0.288948   \n",
       "D_110      2490.0  5.968010e-04  0.998728 -2.401527 -2.401499  0.441997   \n",
       "P_3      266694.0  3.429047e-03  0.926010 -3.447882 -3.447880  0.103782   \n",
       "D_64_O   269243.0  1.700895e-15  1.000002 -1.075936 -1.075936  0.929423   \n",
       "S_7      236579.0 -9.482247e-03  0.942375 -1.060306 -1.060300 -0.386645   \n",
       "R_1      269243.0 -1.775392e-02  0.895098 -0.344241 -0.344241 -0.318500   \n",
       "\n",
       "              99%       max  \n",
       "D_50     1.428200  1.428246  \n",
       "R_27     0.379136  0.379136  \n",
       "S_3      4.054081  4.054083  \n",
       "B_17     0.791418  0.791418  \n",
       "B_39     2.817063  2.817065  \n",
       "D_48     1.946748  1.946755  \n",
       "D_77     3.484958  3.484959  \n",
       "D_75     3.742752  3.742753  \n",
       "D_53     4.485345  4.485412  \n",
       "D_132    3.286209  3.286209  \n",
       "B_1      4.167397  4.167455  \n",
       "B_3      3.774397  3.774407  \n",
       "D_44     4.111839  4.111843  \n",
       "B_2      0.965602  0.965602  \n",
       "D_42     3.565633  3.565842  \n",
       "B_9      2.892113  2.892131  \n",
       "D_49     2.069076  2.069076  \n",
       "D_111    0.512103  0.512103  \n",
       "D_45     3.119599  3.119627  \n",
       "D_88     3.916522  3.917022  \n",
       "B_5      2.328652  2.328682  \n",
       "D_66     0.349962  0.349962  \n",
       "B_38     2.747680  2.747680  \n",
       "S_23     0.893242  0.893248  \n",
       "D_43     4.003878  4.003914  \n",
       "D_63_CO  0.579519  0.579519  \n",
       "D_41     4.548401  4.548418  \n",
       "D_51     3.610042  3.610043  \n",
       "P_2      1.461843  1.461843  \n",
       "B_7      3.589740  3.589783  \n",
       "R_26     3.916462  3.916627  \n",
       "D_74     3.896463  3.896470  \n",
       "D_62     3.488749  3.488752  \n",
       "B_4      3.743054  3.743098  \n",
       "D_56     3.622754  3.622755  \n",
       "B_10     0.092859  0.092862  \n",
       "B_8      1.094237  1.094237  \n",
       "D_46     3.051888  3.051888  \n",
       "D_76     2.959337  2.959347  \n",
       "D_110    0.877978  0.877978  \n",
       "P_3      2.361960  2.361960  \n",
       "D_64_O   0.929423  0.929423  \n",
       "S_7      3.810519  3.810519  \n",
       "R_1      4.239188  4.239189  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_n_df.describe(percentiles = [.01, .99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_n_df.fillna(0,inplace=True)\n",
    "xtest1_n_df.fillna(0,inplace=True)\n",
    "xtest2_n_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy(x, actual, pred, threshold, balance = 'B_2', spend = 'S_3'):\n",
    "  ydf = pd.DataFrame({'actual': actual, 'pred': pred})\n",
    "  df = pd.concat([x, ydf], axis = 1)\n",
    "  total = df.loc[df['pred'] < threshold].shape[0]\n",
    "  default = df.loc[df['pred'] < threshold, 'actual'].mean()\n",
    "\n",
    "  df['revenue'] = df.apply(lambda x: x[balance]*0.02 + x[spend]*.001 if x['actual'] != 1 else 0, axis = 1)\n",
    "\n",
    "  revenue = df.loc[df['pred'] < threshold, 'revenue'].sum()\n",
    "\n",
    "  return [total, default, revenue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_sum(xdf, actual, pred, balance = 'B_2', spend = 'S_3'):\n",
    "    summary = pd.DataFrame(columns = ['Threshold', '#Total', 'Default Rate', 'Revenue'])\n",
    "    summary['Threshold'] = [(i+1)*0.1 for i in range(10)]\n",
    "    for i in range(10):\n",
    "        summary.iloc[i, 1:] = strategy(xdf, actual, pred, summary.iloc[i, 0] , balance = 'B_2', spend = 'S_3')\n",
    "    \n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "iloc cannot enlarge its target object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-72ae20690a5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_setitem_indexer\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iloc cannot enlarge its target object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iloc cannot enlarge its target object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: iloc cannot enlarge its target object"
     ]
    }
   ],
   "source": [
    "summary = pd.DataFrame(columns = ['Threshold', '#Total', 'Default Rate', 'Revenue'])\n",
    "for i in range(10):\n",
    "    threshold =  (i+1)*0.1\n",
    "    print(threshold)\n",
    "    summary.iloc[i, 0] = threshold\n",
    "    summary.iloc[i, 1:] = [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>#Total</th>\n",
       "      <th>Default Rate</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3903.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold #Total Default Rate Revenue\n",
       "0     3903.0      2            3       4\n",
       "1        0.2    NaN          NaN     NaN\n",
       "2        0.3    NaN          NaN     NaN\n",
       "3        0.4    NaN          NaN     NaN\n",
       "4        0.5    NaN          NaN     NaN\n",
       "5        0.6    NaN          NaN     NaN\n",
       "6        0.7    NaN          NaN     NaN\n",
       "7        0.8    NaN          NaN     NaN\n",
       "8        0.9    NaN          NaN     NaN\n",
       "9        1.0    NaN          NaN     NaN"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.iloc[0, 0] = 3903\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>#Total</th>\n",
       "      <th>Default Rate</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>172995</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>2370.581897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>191455</td>\n",
       "      <td>0.020887</td>\n",
       "      <td>2528.340628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>204573</td>\n",
       "      <td>0.033367</td>\n",
       "      <td>2614.341308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>216506</td>\n",
       "      <td>0.048867</td>\n",
       "      <td>2676.874763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>228384</td>\n",
       "      <td>0.068901</td>\n",
       "      <td>2724.775644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>240891</td>\n",
       "      <td>0.09376</td>\n",
       "      <td>2763.614149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>254848</td>\n",
       "      <td>0.12531</td>\n",
       "      <td>2791.002869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>271002</td>\n",
       "      <td>0.164929</td>\n",
       "      <td>2809.460402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>290154</td>\n",
       "      <td>0.213418</td>\n",
       "      <td>2818.459241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>308200</td>\n",
       "      <td>0.25831</td>\n",
       "      <td>2819.650544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  #Total Default Rate      Revenue\n",
       "0        0.1  172995     0.009989  2370.581897\n",
       "1        0.2  191455     0.020887  2528.340628\n",
       "2        0.3  204573     0.033367  2614.341308\n",
       "3        0.4  216506     0.048867  2676.874763\n",
       "4        0.5  228384     0.068901  2724.775644\n",
       "5        0.6  240891      0.09376  2763.614149\n",
       "6        0.7  254848      0.12531  2791.002869\n",
       "7        0.8  271002     0.164929  2809.460402\n",
       "8        0.9  290154     0.213418  2818.459241\n",
       "9        1.0  308200      0.25831  2819.650544"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ = ex_sum(xtrain, ytrain['target'], y_pred, balance = 'B_2', spend = 'S_3')\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>#Total</th>\n",
       "      <th>Default Rate</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>36684</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>495.792901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>40481</td>\n",
       "      <td>0.03409</td>\n",
       "      <td>527.187021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>43201</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>542.971991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>45593</td>\n",
       "      <td>0.067664</td>\n",
       "      <td>554.82373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>47995</td>\n",
       "      <td>0.086905</td>\n",
       "      <td>564.420393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>50440</td>\n",
       "      <td>0.110607</td>\n",
       "      <td>571.342882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>53052</td>\n",
       "      <td>0.136658</td>\n",
       "      <td>577.175083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>56007</td>\n",
       "      <td>0.167818</td>\n",
       "      <td>582.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>59264</td>\n",
       "      <td>0.203817</td>\n",
       "      <td>585.543222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61963</td>\n",
       "      <td>0.234317</td>\n",
       "      <td>586.974128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold #Total Default Rate     Revenue\n",
       "0        0.1  36684     0.019436  495.792901\n",
       "1        0.2  40481      0.03409  527.187021\n",
       "2        0.3  43201     0.050323  542.971991\n",
       "3        0.4  45593     0.067664   554.82373\n",
       "4        0.5  47995     0.086905  564.420393\n",
       "5        0.6  50440     0.110607  571.342882\n",
       "6        0.7  53052     0.136658  577.175083\n",
       "7        0.8  56007     0.167818  582.004945\n",
       "8        0.9  59264     0.203817  585.543222\n",
       "9        1.0  61963     0.234317  586.974128"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ1 = ex_sum(xtest1, ytest1['target'], ytest1_pred, balance = 'B_2', spend = 'S_3')\n",
    "summ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>#Total</th>\n",
       "      <th>Default Rate</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>46549</td>\n",
       "      <td>0.01304</td>\n",
       "      <td>629.339495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>52125</td>\n",
       "      <td>0.026456</td>\n",
       "      <td>676.621066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>56268</td>\n",
       "      <td>0.042458</td>\n",
       "      <td>705.157641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>60104</td>\n",
       "      <td>0.061427</td>\n",
       "      <td>726.074571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63954</td>\n",
       "      <td>0.084905</td>\n",
       "      <td>741.99929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>68082</td>\n",
       "      <td>0.113569</td>\n",
       "      <td>754.773909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>72316</td>\n",
       "      <td>0.144519</td>\n",
       "      <td>764.144276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>77042</td>\n",
       "      <td>0.181745</td>\n",
       "      <td>770.911223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>82638</td>\n",
       "      <td>0.227789</td>\n",
       "      <td>774.733769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>88750</td>\n",
       "      <td>0.278287</td>\n",
       "      <td>775.683408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold #Total Default Rate     Revenue\n",
       "0        0.1  46549      0.01304  629.339495\n",
       "1        0.2  52125     0.026456  676.621066\n",
       "2        0.3  56268     0.042458  705.157641\n",
       "3        0.4  60104     0.061427  726.074571\n",
       "4        0.5  63954     0.084905   741.99929\n",
       "5        0.6  68082     0.113569  754.773909\n",
       "6        0.7  72316     0.144519  764.144276\n",
       "7        0.8  77042     0.181745  770.911223\n",
       "8        0.9  82638     0.227789  774.733769\n",
       "9        1.0  88750     0.278287  775.683408"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ2 = ex_sum(xtest2, ytest2['target'], ytest2_pred, balance = 'B_2', spend = 'S_3')\n",
    "summ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>#Total</th>\n",
       "      <th>Default Rate</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>256228</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>3495.714294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>284061</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>3732.148715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>304042</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>3862.47094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>322203</td>\n",
       "      <td>0.05387</td>\n",
       "      <td>3957.773064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>340333</td>\n",
       "      <td>0.074448</td>\n",
       "      <td>4031.195327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>359413</td>\n",
       "      <td>0.099877</td>\n",
       "      <td>4089.730941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>380216</td>\n",
       "      <td>0.130547</td>\n",
       "      <td>4132.322228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>404051</td>\n",
       "      <td>0.168536</td>\n",
       "      <td>4162.376569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>432056</td>\n",
       "      <td>0.214849</td>\n",
       "      <td>4178.736232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>458913</td>\n",
       "      <td>0.258934</td>\n",
       "      <td>4182.30808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  #Total Default Rate      Revenue\n",
       "0        0.1  256228     0.011896  3495.714294\n",
       "1        0.2  284061     0.023791  3732.148715\n",
       "2        0.3  304042     0.037459   3862.47094\n",
       "3        0.4  322203      0.05387  3957.773064\n",
       "4        0.5  340333     0.074448  4031.195327\n",
       "5        0.6  359413     0.099877  4089.730941\n",
       "6        0.7  380216     0.130547  4132.322228\n",
       "7        0.8  404051     0.168536  4162.376569\n",
       "8        0.9  432056     0.214849  4178.736232\n",
       "9        1.0  458913     0.258934   4182.30808"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.concat([xtest1, xtrain, xtest2], axis = 0)\n",
    "y = pd.concat([ytest1, ytrain, ytest2], axis = 0)\n",
    "yhat = np.concatenate((ytest1_pred , y_pred, ytest2_pred), axis = 0)\n",
    "\n",
    "overall = ex_sum(x, y['target'], yhat, balance = 'B_2', spend = 'S_3')\n",
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function merge in module pandas.core.reshape.merge:\n",
      "\n",
      "merge(left, right, how: str = 'inner', on=None, left_on=None, right_on=None, left_index: bool = False, right_index: bool = False, sort: bool = False, suffixes=('_x', '_y'), copy: bool = True, indicator: bool = False, validate=None) -> 'DataFrame'\n",
      "    Merge DataFrame or named Series objects with a database-style join.\n",
      "    \n",
      "    The join is done on columns or indexes. If joining columns on\n",
      "    columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      "    on indexes or indexes on a column or columns, the index will be passed on.\n",
      "    When performing a cross merge, no column specifications to merge on are\n",
      "    allowed.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    left : DataFrame\n",
      "    right : DataFrame or named Series\n",
      "        Object to merge with.\n",
      "    how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      "        Type of merge to be performed.\n",
      "    \n",
      "        * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "          preserve key order.\n",
      "        * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "          preserve key order.\n",
      "        * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "          join; sort keys lexicographically.\n",
      "        * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "          join; preserve the order of the left keys.\n",
      "        * cross: creates the cartesian product from both frames, preserves the order\n",
      "          of the left keys.\n",
      "    \n",
      "          .. versionadded:: 1.2.0\n",
      "    \n",
      "    on : label or list\n",
      "        Column or index level names to join on. These must be found in both\n",
      "        DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      "        to the intersection of the columns in both DataFrames.\n",
      "    left_on : label or list, or array-like\n",
      "        Column or index level names to join on in the left DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the left DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    right_on : label or list, or array-like\n",
      "        Column or index level names to join on in the right DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the right DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    left_index : bool, default False\n",
      "        Use the index from the left DataFrame as the join key(s). If it is a\n",
      "        MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "        or a number of columns) must match the number of levels.\n",
      "    right_index : bool, default False\n",
      "        Use the index from the right DataFrame as the join key. Same caveats as\n",
      "        left_index.\n",
      "    sort : bool, default False\n",
      "        Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "        the order of the join keys depends on the join type (how keyword).\n",
      "    suffixes : list-like, default is (\"_x\", \"_y\")\n",
      "        A length-2 sequence where each element is optionally a string\n",
      "        indicating the suffix to add to overlapping column names in\n",
      "        `left` and `right` respectively. Pass a value of `None` instead\n",
      "        of a string to indicate that the column name from `left` or\n",
      "        `right` should be left as-is, with no suffix. At least one of the\n",
      "        values must not be None.\n",
      "    copy : bool, default True\n",
      "        If False, avoid copy if possible.\n",
      "    indicator : bool or str, default False\n",
      "        If True, adds a column to the output DataFrame called \"_merge\" with\n",
      "        information on the source of each row. The column can be given a different\n",
      "        name by providing a string argument. The column will have a Categorical\n",
      "        type with the value of \"left_only\" for observations whose merge key only\n",
      "        appears in the left DataFrame, \"right_only\" for observations\n",
      "        whose merge key only appears in the right DataFrame, and \"both\"\n",
      "        if the observation's merge key is found in both DataFrames.\n",
      "    \n",
      "    validate : str, optional\n",
      "        If specified, checks if merge is of specified type.\n",
      "    \n",
      "        * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "          left and right datasets.\n",
      "        * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "          dataset.\n",
      "        * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "          dataset.\n",
      "        * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        A DataFrame of the two merged objects.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    merge_ordered : Merge with optional filling/interpolation.\n",
      "    merge_asof : Merge on nearest keys.\n",
      "    DataFrame.join : Similar method using indices.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Support for specifying index levels as the `on`, `left_on`, and\n",
      "    `right_on` parameters was added in version 0.23.0\n",
      "    Support for merging named Series objects was added in version 0.24.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [1, 2, 3, 5]})\n",
      "    >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [5, 6, 7, 8]})\n",
      "    >>> df1\n",
      "        lkey value\n",
      "    0   foo      1\n",
      "    1   bar      2\n",
      "    2   baz      3\n",
      "    3   foo      5\n",
      "    >>> df2\n",
      "        rkey value\n",
      "    0   foo      5\n",
      "    1   bar      6\n",
      "    2   baz      7\n",
      "    3   foo      8\n",
      "    \n",
      "    Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      "    the default suffixes, _x and _y, appended.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      "      lkey  value_x rkey  value_y\n",
      "    0  foo        1  foo        5\n",
      "    1  foo        1  foo        8\n",
      "    2  foo        5  foo        5\n",
      "    3  foo        5  foo        8\n",
      "    4  bar        2  bar        6\n",
      "    5  baz        3  baz        7\n",
      "    \n",
      "    Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      "    appended to any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      "    ...           suffixes=('_left', '_right'))\n",
      "      lkey  value_left rkey  value_right\n",
      "    0  foo           1  foo            5\n",
      "    1  foo           1  foo            8\n",
      "    2  foo           5  foo            5\n",
      "    3  foo           5  foo            8\n",
      "    4  bar           2  bar            6\n",
      "    5  baz           3  baz            7\n",
      "    \n",
      "    Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      "    any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: columns overlap but no suffix specified:\n",
      "        Index(['value'], dtype='object')\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      "    >>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      "    >>> df1\n",
      "          a  b\n",
      "    0   foo  1\n",
      "    1   bar  2\n",
      "    >>> df2\n",
      "          a  c\n",
      "    0   foo  3\n",
      "    1   baz  4\n",
      "    \n",
      "    >>> df1.merge(df2, how='inner', on='a')\n",
      "          a  b  c\n",
      "    0   foo  1  3\n",
      "    \n",
      "    >>> df1.merge(df2, how='left', on='a')\n",
      "          a  b  c\n",
      "    0   foo  1  3.0\n",
      "    1   bar  2  NaN\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      "    >>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      "    >>> df1\n",
      "        left\n",
      "    0   foo\n",
      "    1   bar\n",
      "    >>> df2\n",
      "        right\n",
      "    0   7\n",
      "    1   8\n",
      "    \n",
      "    >>> df1.merge(df2, how='cross')\n",
      "       left  right\n",
      "    0   foo      7\n",
      "    1   foo      8\n",
      "    2   bar      7\n",
      "    3   bar      8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ.merge(summ1, on = 'Threshold', suffixes=('_', ''), how = 'left' ).merge(summ2, on = 'Threshold', how = 'left').merge(overall, on = 'Threshold', how = 'left').to_csv('strategy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[234490, 0.08058765832231651, 2745.1238495846824]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy(xtrain, ytrain['target'], y_pred, 0.55, balance = 'B_2', spend = 'S_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex1(xdf, actual, pred, c, a, balance = 'B_2', spend = 'S_3'):\n",
    "    summary = pd.DataFrame(columns = ['#Total', 'Default Rate', 'Revenue'], index = ['Conservative', 'Aggressive'])\n",
    "    summary.loc['Conservative', :] = strategy(xdf, actual, pred, c, balance = 'B_2', spend = 'S_3')\n",
    "    summary.loc['Aggressive', :] = strategy(xdf, actual, pred, a, balance = 'B_2', spend = 'S_3')\n",
    "    return summary\n",
    "\n",
    "exsum = ex1(xtrain, ytrain['target'], y_pred, 0.5, 0.3, balance = 'B_2', spend = 'S_3')\n",
    "exsum1 = ex1(xtest1, ytest1['target'], ytest1_pred, 0.5, 0.3, balance = 'B_2', spend = 'S_3')\n",
    "exsum2 = ex1(xtest2, ytest2['target'], ytest2_pred, 0.5, 0.3, balance = 'B_2', spend = 'S_3')\n",
    "ex_ov = ex1(x, y['target'], yhat, 0.55, 0.4, balance = 'B_2', spend = 'S_3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method join in module pandas.core.frame:\n",
      "\n",
      "join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False) -> 'DataFrame' method of pandas.core.frame.DataFrame instance\n",
      "    Join columns of another DataFrame.\n",
      "    \n",
      "    Join columns with `other` DataFrame either on index or on a key\n",
      "    column. Efficiently join multiple DataFrame objects by index at once by\n",
      "    passing a list.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : DataFrame, Series, or list of DataFrame\n",
      "        Index should be similar to one of the columns in this one. If a\n",
      "        Series is passed, its name attribute must be set, and that will be\n",
      "        used as the column name in the resulting joined DataFrame.\n",
      "    on : str, list of str, or array-like, optional\n",
      "        Column or index level name(s) in the caller to join on the index\n",
      "        in `other`, otherwise joins index-on-index. If multiple\n",
      "        values given, the `other` DataFrame must have a MultiIndex. Can\n",
      "        pass an array as the join key if it is not already contained in\n",
      "        the calling DataFrame. Like an Excel VLOOKUP operation.\n",
      "    how : {'left', 'right', 'outer', 'inner'}, default 'left'\n",
      "        How to handle the operation of the two objects.\n",
      "    \n",
      "        * left: use calling frame's index (or column if on is specified)\n",
      "        * right: use `other`'s index.\n",
      "        * outer: form union of calling frame's index (or column if on is\n",
      "          specified) with `other`'s index, and sort it.\n",
      "          lexicographically.\n",
      "        * inner: form intersection of calling frame's index (or column if\n",
      "          on is specified) with `other`'s index, preserving the order\n",
      "          of the calling's one.\n",
      "    lsuffix : str, default ''\n",
      "        Suffix to use from left frame's overlapping columns.\n",
      "    rsuffix : str, default ''\n",
      "        Suffix to use from right frame's overlapping columns.\n",
      "    sort : bool, default False\n",
      "        Order result DataFrame lexicographically by the join key. If False,\n",
      "        the order of the join key depends on the join type (how keyword).\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        A dataframe containing columns from both the caller and `other`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.merge : For column(s)-on-column(s) operations.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n",
      "    passing a list of `DataFrame` objects.\n",
      "    \n",
      "    Support for specifying index levels as the `on` parameter was added\n",
      "    in version 0.23.0.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      "    ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      "    \n",
      "    >>> df\n",
      "      key   A\n",
      "    0  K0  A0\n",
      "    1  K1  A1\n",
      "    2  K2  A2\n",
      "    3  K3  A3\n",
      "    4  K4  A4\n",
      "    5  K5  A5\n",
      "    \n",
      "    >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      "    ...                       'B': ['B0', 'B1', 'B2']})\n",
      "    \n",
      "    >>> other\n",
      "      key   B\n",
      "    0  K0  B0\n",
      "    1  K1  B1\n",
      "    2  K2  B2\n",
      "    \n",
      "    Join DataFrames using their indexes.\n",
      "    \n",
      "    >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n",
      "      key_caller   A key_other    B\n",
      "    0         K0  A0        K0   B0\n",
      "    1         K1  A1        K1   B1\n",
      "    2         K2  A2        K2   B2\n",
      "    3         K3  A3       NaN  NaN\n",
      "    4         K4  A4       NaN  NaN\n",
      "    5         K5  A5       NaN  NaN\n",
      "    \n",
      "    If we want to join using the key columns, we need to set key to be\n",
      "    the index in both `df` and `other`. The joined DataFrame will have\n",
      "    key as its index.\n",
      "    \n",
      "    >>> df.set_index('key').join(other.set_index('key'))\n",
      "          A    B\n",
      "    key\n",
      "    K0   A0   B0\n",
      "    K1   A1   B1\n",
      "    K2   A2   B2\n",
      "    K3   A3  NaN\n",
      "    K4   A4  NaN\n",
      "    K5   A5  NaN\n",
      "    \n",
      "    Another option to join using the key columns is to use the `on`\n",
      "    parameter. DataFrame.join always uses `other`'s index but we can use\n",
      "    any column in `df`. This method preserves the original DataFrame's\n",
      "    index in the result.\n",
      "    \n",
      "    >>> df.join(other.set_index('key'), on='key')\n",
      "      key   A    B\n",
      "    0  K0  A0   B0\n",
      "    1  K1  A1   B1\n",
      "    2  K2  A2   B2\n",
      "    3  K3  A3  NaN\n",
      "    4  K4  A4  NaN\n",
      "    5  K5  A5  NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "exsum.join(exsum1, rsuffix='_1').join(exsum2, rsuffix = '_2').join(ex_ov, rsuffix = '_').to_excel('ex_strategy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
